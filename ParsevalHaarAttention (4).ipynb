{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed9e26f",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/falseywinchnet/PicoGPT/blob/main/ParsevalHaarAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73bbf857-246b-46e3-a124-4812cb4a2dfe",
   "metadata": {
    "id": "73bbf857-246b-46e3-a124-4812cb4a2dfe"
   },
   "outputs": [],
   "source": [
    "#copyright joshuah.rainstar@gmail.com 2025\n",
    "#MIT with attribution\n",
    "\n",
    "import math\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# ----------------------------\n",
    "# Layers\n",
    "# ----------------------------\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, ndim: int, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.use_bias = bias\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(ndim))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b =self.bias if self.use_bias else None\n",
    "        return F.layer_norm(x, self.weight.shape, self.weight, b, 1e-5)\n",
    "\n",
    "\n",
    "\n",
    "class ParsevalRotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim: int, max_seq_len: int = 2048, theta_base: float = 10000.0):\n",
    "        \"\"\"\n",
    "        dim: embedding dimension (must be even).\n",
    "        max_seq_len: maximum sequence length for which to precompute sines/cosines.\n",
    "        theta_base: base for frequency schedule (as in RoPE).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert dim % 2 == 0, \"dim must be even for pairing\"\n",
    "        self.dim = dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        # compute frequency for each pair\n",
    "        half = dim // 2\n",
    "        inv_freq = 1.0 / (theta_base ** (torch.arange(0, half, 1, dtype=torch.float32) / half))\n",
    "\n",
    "        # position indices\n",
    "        pos = torch.arange(max_seq_len, dtype=torch.float32).unsqueeze(1)  # (max_seq_len,1)\n",
    "        # angles (max_seq_len x half) = pos * inv_freq\n",
    "        angles = pos * inv_freq.unsqueeze(0)  # broadcast\n",
    "        # compute cos and sin matrices for each pos and each half-dim\n",
    "        self.register_buffer(\"cos\", angles.cos().unsqueeze(0).unsqueeze(0))  # (1,1,max_seq_len,half)\n",
    "        self.register_buffer(\"sin\", angles.sin().unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, seq_pos: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: shape (B, H, T, D) or (B, T, H, D)\n",
    "        seq_pos: tensor of positions indices shape (T,) or (B,T)\n",
    "        Returns: same shape x but positionally encoded via orthogonal rotations.\n",
    "        \"\"\"\n",
    "        # assume shape (B, H, T, D)\n",
    "        B, H, T, D = x.shape\n",
    "        half = D // 2\n",
    "        # get cos/sin for positions\n",
    "        # pos angles shape (1,1,T,half)\n",
    "        cos_t = self.cos[:, :, seq_pos, :]  # broadcast\n",
    "        sin_t = self.sin[:, :, seq_pos, :]\n",
    "\n",
    "        x1 = x[..., :half]\n",
    "        x2 = x[..., half:]\n",
    "\n",
    "        # apply rotation: [x1'; x2'] = [x1*cos - x2*sin, x1*sin + x2*cos]\n",
    "        x1_rot = x1 * cos_t - x2 * sin_t\n",
    "        x2_rot = x1 * sin_t + x2 * cos_t\n",
    "\n",
    "        x_rot = torch.cat([x1_rot, x2_rot], dim=-1)\n",
    "        return x_rot\n",
    "\n",
    "\n",
    "\n",
    "def l2_normalize(x, dim=-1, eps=1e-8):\n",
    "    return x / (x.norm(dim=dim, keepdim=True) + eps)\n",
    "\n",
    "def build_haar_wavelet_basis(T, levels, device=None, dtype=torch.float32):\n",
    "    \"\"\"\n",
    "    Build a Haar‚Äêwavelet basis matrix W of shape (T, Bcoef).\n",
    "    T: sequence length (must be divisible by 2^levels for full structure, but we will allow slicing).\n",
    "    levels: number of levels of decomposition.\n",
    "    \"\"\"\n",
    "    W_list = []\n",
    "    for j in range(levels):\n",
    "        block_count = 2**j\n",
    "        block_size = T // block_count\n",
    "        half = block_size // 2\n",
    "        for k in range(block_count):\n",
    "            vec = torch.zeros(T, dtype=dtype, device=device)\n",
    "            start = k * block_size\n",
    "            mid   = start + half\n",
    "            end   = start + block_size\n",
    "            if half > 0:\n",
    "                vec[start:mid] =  1.0 / math.sqrt(half)\n",
    "                vec[mid:end]  = -1.0 / math.sqrt(half)\n",
    "            W_list.append(vec)\n",
    "    W = torch.stack(W_list, dim=1)  # shape (T, Bcoef)\n",
    "    return W\n",
    "\n",
    "def variance_scaled_softmax(scores, dim: int = -1, eps: float = 1e-6):\n",
    "    # scores may contain -inf from masking\n",
    "    finite = torch.isfinite(scores)\n",
    "    m = finite.to(scores.dtype)                     # 1 where valid, 0 where masked\n",
    "    n = m.sum(dim=dim, keepdim=True).clamp_min(1)  # count of valid entries per row\n",
    "\n",
    "    # mean/var over valid entries only (population var)\n",
    "    safe_scores = torch.where(finite, scores, torch.zeros_like(scores))\n",
    "    mean = (safe_scores * m).sum(dim=dim, keepdim=True) / n\n",
    "    var  = ((safe_scores - mean)**2 * m).sum(dim=dim, keepdim=True) / n\n",
    "    std  = var.clamp_min(eps).sqrt()\n",
    "\n",
    "    scaled = (safe_scores - mean) / std\n",
    "    scaled = torch.where(finite, scaled, float('-inf'))  # restore mask\n",
    "    out = torch.softmax(scaled, dim=dim)\n",
    "    out = torch.where(n == 0, torch.zeros_like(out), out)  # fully-masked rows -> zeros\n",
    "    return out\n",
    "\n",
    "class DirectionalWedgeBias(nn.Module):\n",
    "    def __init__(self, dim, heads, gamma=1.0):\n",
    "        super().__init__()\n",
    "        self.n_head = heads\n",
    "        self.head_dim = dim // heads\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # A -> The generator of the Symplectic Form S\n",
    "        # We learn A per head to allow different heads to track different \n",
    "        # kinds of curvature (e.g., short-term twists vs long-term arcs).\n",
    "        self.A = nn.Parameter(torch.empty(heads, self.head_dim, self.head_dim))\n",
    "        \n",
    "        # Initialization: Orthogonal ensures distinct, non-collapsing flows.\n",
    "        # We scale by 0.1 to start with a subtle but firm geometric bias.\n",
    "        nn.init.orthogonal_(self.A, gain=0.1)\n",
    "        \n",
    "        # Learnable decay rate for the influence of this bias over distance\n",
    "        # (Soft locality)\n",
    "        self.log_tau = nn.Parameter(torch.zeros(heads)) \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Input vectors (B, T, D) - serves as the 'tangent' vector for the wedge.\n",
    "        Returns: (B, H, T, T) bias tensor.\n",
    "        \"\"\"\n",
    "        B, T, D = x.shape\n",
    "        H, Dh = self.n_head, self.head_dim\n",
    "        \n",
    "        # Reshape to heads: (B, T, H, Dh) -> (B, H, T, Dh)\n",
    "        # We normalize x here to ensure the wedge measures purely geometry (angle/area),\n",
    "        # not magnitude.\n",
    "        v = x.view(B, T, H, Dh).transpose(1, 2)\n",
    "        v = F.normalize(v, dim=-1) \n",
    "        \n",
    "        # Skew-Symmetric Form: S = A - A^T\n",
    "        # S_ij = -S_ji. This is the definition of a symplectic form.\n",
    "        S = self.A - self.A.transpose(-1, -2) # (H, Dh, Dh)\n",
    "        \n",
    "        # Compute the Wedge Product: v_i^T S v_j\n",
    "        # 1. Apply S to v: (B, H, T, Dh) @ (H, Dh, Dh) -> (B, H, T, Dh)\n",
    "        Sv = torch.matmul(v, S) \n",
    "        \n",
    "        # 2. Dot product with v (broadcast over T):\n",
    "        # We want output (B, H, T, T).\n",
    "        # (B, H, T, Dh) @ (B, H, Dh, T) -> (B, H, T, T)\n",
    "        wedge = torch.matmul(Sv, v.transpose(-1, -2))\n",
    "        \n",
    "        # Apply Distance Decay (Optional but recommended for stability)\n",
    "        # We use a simplified decay based on simple index distance to damp\n",
    "        # the symplectic term at extreme ranges, preventing exploding gradients.\n",
    "        # However, since we replaced RoPE, we might want this to be the ONLY\n",
    "        # position info, so we keep it fairly global.\n",
    "        \n",
    "        tau = F.softplus(self.log_tau).view(1, H, 1, 1) + 1e-4\n",
    "        idx = torch.arange(T, device=x.device)\n",
    "        dist = (idx[None, :] - idx[:, None]).abs().view(1, 1, T, T)\n",
    "        decay = torch.exp(-dist * 0.01 / tau) \n",
    "\n",
    "        return self.gamma * wedge * decay\n",
    "        \n",
    "\n",
    "class ParsevalWaveletAttention(nn.Module):\n",
    "    def __init__(self, config, near_window=64):\n",
    "        super().__init__()\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.head_dim = self.n_embd // self.n_head\n",
    "        \n",
    "        assert self.head_dim * self.n_head == self.n_embd, \"n_embd must be divisible by n_head\"\n",
    "\n",
    "        # Null Vector Parameters (The Sink)\n",
    "        # One unique sink per head to allow independent \"voting\"\n",
    "        self.k_null = nn.Parameter(torch.randn(1, 1, self.n_head, self.head_dim) * 0.02)\n",
    "        self.register_buffer(\"v_null\", torch.zeros(1, 1, self.n_head, self.head_dim))\n",
    "        self.W_Q = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "        self.W_K = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "        self.W_V = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "        self.W_O = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "        \n",
    "        self.ln = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        \n",
    "        # Auto-tune levels\n",
    "        target_block = near_window * 2\n",
    "        min_blocks = config.block_size / target_block\n",
    "        self.wavelet_levels = max(3, int(math.ceil(math.log2(min_blocks))) + 1)\n",
    "        \n",
    "        self.near_window = near_window\n",
    "        self.block_size = config.block_size\n",
    "        \n",
    "        W_haar_full = build_haar_wavelet_basis(self.block_size,\n",
    "                                               self.wavelet_levels,\n",
    "                                               device='cpu')\n",
    "        W_haar_full = l2_normalize(W_haar_full, dim=0)\n",
    "        self.register_buffer(\"W_haar_full\", W_haar_full)\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                 .view(1, 1, config.block_size, config.block_size)\n",
    "        )\n",
    "        self.pos_encoder = ParsevalRotaryEmbedding(dim=self.head_dim, max_seq_len=config.block_size)\n",
    "        self.wedge_bias = DirectionalWedgeBias(self.n_embd, self.n_head, gamma=0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        H = self.n_head\n",
    "        D = self.head_dim\n",
    "        geo_bias = self.wedge_bias(x) # (B, H, T, T)\n",
    "        # Project and split heads\n",
    "        q = self.W_Q(x).view(B, T, H, D).transpose(1, 2) # (B, H, T, D)\n",
    "        k = self.W_K(x).view(B, T, H, D).transpose(1, 2)\n",
    "        v = self.W_V(self.ln(x)).view(B, T, H, D).transpose(1, 2)\n",
    "\n",
    "        # Rotary Positional Embedding\n",
    "        idx = torch.arange(T, device=x.device)\n",
    "        #q = self.pos_encoder(q, idx)\n",
    "        #k = self.pos_encoder(k, idx)\n",
    "\n",
    "        # L2 Normalize (Hyperspherical Manifold)\n",
    "        q = l2_normalize(q, dim=-1)\n",
    "        k = l2_normalize(k, dim=-1)\n",
    "        k_null_norm = l2_normalize(self.k_null, dim=-1) # Normalize sink too\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # 1. Compute Sequence Attention (Near + Far)\n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Near Field (Standard)\n",
    "        near_mask = (idx.view(1,-1) - idx.view(-1,1)).abs() <= self.near_window\n",
    "        # Expand mask for heads: (1, 1, T, T)\n",
    "        near_mask = near_mask.view(1, 1, T, T)\n",
    "        \n",
    "        att_near = (q @ k.transpose(-2, -1)) # (B, H, T, T)\n",
    "        att_near = att_near + geo_bias\n",
    "        att_near = att_near.masked_fill(~near_mask, float('-inf'))\n",
    "\n",
    "        # Far Field (Wavelet Projected)\n",
    "        W_h = self.W_haar_full[:T, :].to(x.device)\n",
    "        \n",
    "        # Flatten heads for projection: (B*H, T, D)\n",
    "        q_flat = q.reshape(B * H, T, D)\n",
    "        k_flat = k.reshape(B * H, T, D)\n",
    "        \n",
    "        q_far = W_h.T @ q_flat # (B*H, Bcoef, D)\n",
    "        k_far = W_h.T @ k_flat\n",
    "        \n",
    "        # Compressed Attention\n",
    "        att_far_comp = (q_far @ k_far.transpose(-2,-1)) # (B*H, Bcoef, Bcoef)\n",
    "        \n",
    "        # Reconstruct\n",
    "        att_far_exp = (W_h @ att_far_comp) @ W_h.T\n",
    "        att_far_exp = att_far_exp.view(B, H, T, T)\n",
    "        \n",
    "        # Combine\n",
    "        att_seq = torch.where(near_mask, att_near, att_far_exp)\n",
    "        att_seq = att_seq.masked_fill(self.mask[:, :, :T, :T] == 0, float('-inf'))\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        # 2. Incorporate Null Vector (The Sink)\n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Calculate score against Null Vector\n",
    "        # q: (B, H, T, D)\n",
    "        # k_null: (1, 1, H, D) -> broadcast to (B, H, 1, D)\n",
    "        k_null_ex = k_null_norm.expand(B, -1, -1, -1).transpose(1, 2) # (B, H, 1, D)\n",
    "        \n",
    "        # null_scores: (B, H, T, 1)\n",
    "        null_scores = q @ k_null_ex.transpose(-2, -1)\n",
    "        \n",
    "        # Concatenate scores: Sequence Scores + Null Score\n",
    "        # att_full: (B, H, T, T+1)\n",
    "        att_full = torch.cat([att_seq, null_scores], dim=-1)\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        # 3. Variance Scaled Softmax\n",
    "        # ---------------------------------------------------------\n",
    "        att_full = variance_scaled_softmax(att_full, dim=-1)\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        # 4. Weighted Sum\n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Split attention weights back into sequence and null\n",
    "        attn_seq_probs = att_full[..., :T]   # (B, H, T, T)\n",
    "        attn_null_probs = att_full[..., T:]  # (B, H, T, 1)\n",
    "        \n",
    "        # Sequence contribution\n",
    "        y_seq = attn_seq_probs @ v # (B, H, T, D)\n",
    "        \n",
    "        # Null contribution\n",
    "        # v_null is broadcastable. If v_null is zero, this adds nothing.\n",
    "        # If v_null is learned, it adds the bias.\n",
    "        y_null = attn_null_probs * self.v_null.expand(B, T, H, D).transpose(1, 2)\n",
    "        \n",
    "        y = y_seq + y_null\n",
    "        \n",
    "        # Reassemble heads\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, self.n_embd)\n",
    "        \n",
    "        return self.W_O(y)\n",
    "\n",
    "\n",
    "\n",
    "class CausalDiscreteLaplacian(nn.Module):\n",
    "    \"\"\"\n",
    "    Computes the discrete 1D Laplacian (Diffusion term) CAUSALLY.\n",
    "    Kernel: [1, -2, 1]\n",
    "    Padding: (2, 0) -> Left padding only.\n",
    "    \n",
    "    Output at t depends on [t-2, t-1, t].\n",
    "    \"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        # Fixed Laplacian kernel [1, -2, 1]\n",
    "        # This approximates the second derivative (curvature).\n",
    "        weight = torch.tensor([1.0, -2.0, 1.0]).view(1, 1, 3)\n",
    "        self.register_buffer(\"weight\", weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C)\n",
    "        x_p = x.permute(0, 2, 1)\n",
    "        \n",
    "        # [FIX] Causal Padding: (2, 0)\n",
    "        # We pad 2 steps on the left (past) and 0 on the right (future).\n",
    "        # This shifts the window so the kernel [1, -2, 1] at output position t\n",
    "        # sees input indices [t-2, t-1, t].\n",
    "        x_padded = F.pad(x_p, (2, 0), mode='replicate')\n",
    "        \n",
    "        diff = F.conv1d(x_padded, self.weight.expand(self.channels, 1, 3), groups=self.channels)\n",
    "        \n",
    "        return diff.permute(0, 2, 1)\n",
    "\n",
    "class MaxwellNavierBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        \n",
    "        # Replaced RoPE with Symplectic Wedge in the Attention class\n",
    "        self.attn = ParsevalWaveletAttention(config) \n",
    "        \n",
    "        # [FIX] Use Causal Laplacian\n",
    "        self.diffusion_op = CausalDiscreteLaplacian(config.n_embd)\n",
    "        \n",
    "        self.eta = nn.Parameter(torch.tensor(0.01)) # Start with low resistivity\n",
    "        self.dt = nn.Parameter(torch.tensor(0.1))   # Smaller time step for stability\n",
    "        \n",
    "        self.mlp = MLP(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "\n",
    "    def forward(self, B_field):\n",
    "        # 1. Advection (Attention) - \"Stretching\"\n",
    "        # Note: Attention masks (tril) prevent future leaks here.\n",
    "        advection_term = self.attn(self.ln_1(B_field))\n",
    "        \n",
    "        # 2. Diffusion (Laplacian) - \"Smoothing\"\n",
    "        # Now strictly causal.\n",
    "        diffusion_term = self.diffusion_op(B_field)\n",
    "        \n",
    "        # 3. Induction Update\n",
    "        delta_B = advection_term + (self.eta * diffusion_term)\n",
    "        B_new = B_field + self.dt * delta_B\n",
    "        \n",
    "        # 4. Reaction (MLP)\n",
    "        B_final = B_new + self.mlp(self.ln_2(B_new))\n",
    "        \n",
    "        return B_final\n",
    "# ----------------------------\n",
    "# Transformer Block\n",
    "# ----------------------------\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear( config.n_embd,4* config.n_embd, bias=config.bias)\n",
    "        self.scale = math.pi / math.sqrt(3.0)\n",
    "\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = x * torch.sigmoid(self.scale * x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.attn = WaveletAttention(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 768\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([MaxwellNavierBlock(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
    "        ))\n",
    "\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        # with weight tying when using torch.compile() some warnings get generated:\n",
    "        # \"UserWarning: functional_call was passed multiple values for tied weights.\n",
    "        # This behavior is deprecated and will be an error in future versions\"\n",
    "        # not 100% sure what this is, so far seems to be harmless. TODO investigate\n",
    "        # init all weights\n",
    "        self.apply(self._init_weights)\n",
    "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "\n",
    "        # report number of parameters\n",
    "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
    "\n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        \"\"\"\n",
    "        Return the number of parameters in the model.\n",
    "        For non-embedding count (default), the position embeddings get subtracted.\n",
    "        The token embeddings would too, except due to the parameter sharing these\n",
    "        params are actually used as weights in the final layer, so we include them.\n",
    "        \"\"\"\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        return n_params\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, T = idx.size()\n",
    "\n",
    "        # forward the GPT model itself\n",
    "        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
    "\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            # if we are given some desired targets also calculate the loss\n",
    "            logits = self.lm_head(x)\n",
    "           \n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "\n",
    "        else:\n",
    "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
    "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc40ec9f-1475-4836-a1e7-ee97b37adad9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc40ec9f-1475-4836-a1e7-ee97b37adad9",
    "outputId": "57b2be6a-8789-4a4b-83c7-a264fe26aa97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading aochildes.txt...\n",
      "üì• Downloading cbt.txt...\n",
      "üì• Downloading children_stories.txt...\n",
      "üì• Downloading gutenberg.txt...\n",
      "üì• Downloading qed.txt...\n",
      "üì• Downloading simple_wikipedia.txt...\n",
      "üì• Downloading switchboard.txt...\n",
      "üì• Downloading wikipedia.txt...\n",
      "üì• Downloading shakespeare.txt...\n",
      "‚úÖ Done. Files saved to ./babylm_10m_cleaned\n"
     ]
    }
   ],
   "source": [
    "import requests, os\n",
    "\n",
    "base_url = \"https://huggingface.co/datasets/cambridge-climb/BabyLM/resolve/main/clean/10M/\"\n",
    "target_dir = \"./babylm_10m_cleaned\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "file_names = [\n",
    "    \"aochildes.txt\",\n",
    "    \"cbt.txt\",\n",
    "    \"children_stories.txt\",\n",
    "    \"gutenberg.txt\",\n",
    "    \"qed.txt\",\n",
    "    \"simple_wikipedia.txt\",\n",
    "    \"switchboard.txt\",\n",
    "    \"wikipedia.txt\"\n",
    "]\n",
    "\n",
    "# Optional addition: Shakespeare from another dataset\n",
    "shakespeare_url = \"https://drive.google.com/uc?export=download&id=1_aiQyJTgcCBq26QssgIWHZFx_eVzm8uz\"\n",
    "shakespeare_fname = \"shakespeare.txt\"\n",
    "\n",
    "# Combined download logic\n",
    "all_files = [(base_url + fname, fname) for fname in file_names]\n",
    "all_files.append((shakespeare_url, shakespeare_fname))  # Add Shakespeare\n",
    "\n",
    "\n",
    "# Download loop\n",
    "for url, fname in all_files:\n",
    "    out_path = os.path.join(target_dir, fname)\n",
    "    print(f\"üì• Downloading {fname}...\")\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(resp.text)\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to download {fname} ({resp.status_code})\")\n",
    "\n",
    "print(f\"‚úÖ Done. Files saved to {target_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9648818a-ba26-4737-9a20-0da0bd3090db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9648818a-ba26-4737-9a20-0da0bd3090db",
    "outputId": "b80213fe-ae68-4960-f665-7624b03b3516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Char tokenizer finalized.\n",
      "üßæ Train tokens: 1016242 | Val tokens: 99152\n",
      "üî§ Vocab size: 66\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# === Paths ===\n",
    "source_dir = \"./babylm_10m_cleaned\"\n",
    "out_dir    = \"./babylm_char_tokenized\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "file_names = [\n",
    "    \"shakespeare.txt\"#,\"aochildes.txt\", \"cbt.txt\", \"children_stories.txt\", \"gutenberg.txt\",\n",
    "    #\"qed.txt\", \"simple_wikipedia.txt\", \"switchboard.txt\", \"wikipedia.txt\"\n",
    "]\n",
    "\n",
    "# === Load and split ===\n",
    "train_texts, val_texts = [], []\n",
    "char_set = set()\n",
    "\n",
    "for fname in file_names:\n",
    "    with open(os.path.join(source_dir, fname), encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        n = len(lines)\n",
    "        split = int(0.9 * n)\n",
    "        train_part = \"\".join(lines[:split])\n",
    "        val_part   = \"\".join(lines[split:])\n",
    "        train_texts.append(train_part)\n",
    "        val_texts.append(val_part)\n",
    "        char_set.update(train_part)\n",
    "        char_set.update(val_part)\n",
    "\n",
    "full_train = \"\\n\".join(train_texts)\n",
    "full_val   = \"\\n\".join(val_texts)\n",
    "\n",
    "# === Final vocab ===\n",
    "char_set = sorted(set(char_set))\n",
    "vocab_chars = [\"<unk>\"] + [c for c in char_set if c != \"<unk>\"]\n",
    "\n",
    "stoi = {ch: i for i, ch in enumerate(vocab_chars)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "\n",
    "# === Encode function ===\n",
    "def encode(text):\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "train_ids = np.array(encode(full_train), dtype=np.uint16)\n",
    "val_ids   = np.array(encode(full_val),   dtype=np.uint16)\n",
    "\n",
    "# === Save ===\n",
    "train_ids.tofile(os.path.join(out_dir, \"train.bin\"))\n",
    "val_ids.tofile(os.path.join(out_dir, \"val.bin\"))\n",
    "\n",
    "with open(os.path.join(out_dir, \"meta.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"vocab_size\": len(stoi),\n",
    "        \"stoi\": stoi,\n",
    "        \"itos\": itos\n",
    "    }, f)\n",
    "\n",
    "print(f\"‚úÖ Char tokenizer finalized.\")\n",
    "print(f\"üßæ Train tokens: {len(train_ids)} | Val tokens: {len(val_ids)}\")\n",
    "print(f\"üî§ Vocab size: {len(stoi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70cb41e0-48cb-4b78-811e-8bde12e7abfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70cb41e0-48cb-4b78-811e-8bde12e7abfa",
    "outputId": "9061f4f7-b1de-4506-ef28-9fc5aa5b2a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.88M\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# === Config ===\n",
    "data_dir = \"./babylm_char_tokenized\"  # <- char-tokenized data\n",
    "block_size = 1024\n",
    "batch_size = 8\n",
    "\n",
    "# === Load tokenizer metadata ===\n",
    "with open(os.path.join(data_dir, 'meta.pkl'), 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "vocab_size = meta['vocab_size']\n",
    "\n",
    "# === Load mmap edata (char-level tokens, uint16) ===\n",
    "train_ids = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n",
    "val_ids   = np.memmap(os.path.join(data_dir, 'val.bin'),   dtype=np.uint16, mode='r')\n",
    "\n",
    "# === Efficient GPU Batch Sampler ===\n",
    "class GPUBatchDataset(Dataset):\n",
    "    def __init__(self, mmap_file, block_size, batch_size, device, jitter=63, p_aligned=0.5, pad_len=0):\n",
    "        self.data = mmap_file\n",
    "        self.block_size = block_size\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.pad_len = int(pad_len)\n",
    "        self.sample_len = self.block_size + self.pad_len  # X length\n",
    "        self.total = len(self.data) - self.sample_len - 1\n",
    "        self.n_blocks = self.total // self.sample_len\n",
    "        self.jitter = int(jitter)          # small random offset added to aligned start\n",
    "        self.p_aligned = float(p_aligned)  # mix aligned and jittered\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = np.empty((self.batch_size, self.sample_len), dtype=np.int64)\n",
    "        Y = np.empty((self.batch_size, self.block_size), dtype=np.int64)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            # choose a base aligned block\n",
    "            base_block = np.random.randint(0, self.n_blocks)\n",
    "            start = base_block * self.sample_len\n",
    "\n",
    "            # with probability, add a small jitter (keeps cache-friendly contiguous reads)\n",
    "            if np.random.rand() > self.p_aligned:\n",
    "                j = np.random.randint(0, self.jitter + 1)\n",
    "                start = min(start + j, self.total)  # stay in range\n",
    "\n",
    "            X[i] = self.data[start : start + self.sample_len]\n",
    "            # targets correspond to the final block_size visible steps\n",
    "            Y[i] = self.data[start + 1 + self.pad_len : start + 1 + self.pad_len + self.block_size]\n",
    "\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(X).to(self.device, non_blocking=True),\n",
    "            torch.from_numpy(Y).to(self.device, non_blocking=True)\n",
    "        )\n",
    "\n",
    "\n",
    "config = GPTConfig(\n",
    "    vocab_size=len(stoi),\n",
    "    n_layer=4,\n",
    "    n_embd=128,\n",
    "    n_head = 1,\n",
    "\n",
    "    block_size=block_size,\n",
    ")\n",
    "train_dataset = GPUBatchDataset(train_ids, block_size, batch_size, device, pad_len=0)\n",
    "# === DataLoader ===\n",
    "train_loader  = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "model = GPT(config)\n",
    "#model= torch.compile(model)\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25f0ccf0-9d48-4e0f-8908-c94adf497969",
   "metadata": {
    "id": "25f0ccf0-9d48-4e0f-8908-c94adf497969",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
    "losses = []\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "          xb, yb = xb[0], yb[0]  # unwrap batch dimension\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          logits, loss = model(xb, yb)\n",
    "          loss.backward()\n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "          optimizer.step()\n",
    "          total_loss += loss.item()\n",
    "          losses.append(loss.item())\n",
    "          dashboard.update(yb, logits, loss.item())\n",
    "    return total_loss / len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hpJ-yb4P4sCe",
   "metadata": {
    "id": "hpJ-yb4P4sCe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626abfe14231423c9e2beee9263f51bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'', height='680', width='2050'),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import io\n",
    "import math\n",
    "import time\n",
    "\n",
    "class MatrixDashboard:\n",
    "    def __init__(self, batch_size, seq_len, itos=None):\n",
    "        \"\"\"\n",
    "        High-Performance Dashboard (PIL + ipywidgets).\n",
    "        Features:\n",
    "        - 'Life' animation (fading/persistence)\n",
    "        - Color-coded confidence (Green=Correct, Orange=Incorrect)\n",
    "        - Fallback to Target glyph if Prediction is OOV.\n",
    "        \"\"\"\n",
    "        self.target_cells = batch_size * seq_len\n",
    "        self.itos_map = itos if itos is not None else {}\n",
    "\n",
    "        # --- 1. Geometry & Font Setup ---\n",
    "        # Cinematic aspect ratio logic (approx 2.5:1)\n",
    "        self.rows = int(math.sqrt(self.target_cells / 5))\n",
    "        self.cols = int(np.ceil(self.target_cells / self.rows))\n",
    "        self.n_cells = self.rows * self.cols\n",
    "\n",
    "        # Visual constants\n",
    "        self.cell_w = 10  # pixel width per char\n",
    "        self.cell_h = 16  # pixel height per char\n",
    "        self.width = self.cols * self.cell_w\n",
    "        self.height = self.rows * self.cell_h + 40 # +40 for stats bar\n",
    "\n",
    "        # Load Font (Robust Fallback)\n",
    "        try:\n",
    "            self.font = ImageFont.truetype(\"DejaVuSansMono.ttf\", 11)\n",
    "        except:\n",
    "            try:\n",
    "                self.font = ImageFont.truetype(\"Courier New.ttf\", 11)\n",
    "            except:\n",
    "                self.font = ImageFont.load_default()\n",
    "\n",
    "        # --- 2. Decoder ---\n",
    "        if itos is not None:\n",
    "            def safe_decode(x):\n",
    "                c = itos.get(x, \"?\")\n",
    "                if c == \"\\n\": return \"¬∂\"\n",
    "                if c == \"\\t\": return \"‚Üí\"\n",
    "                if c == \" \": return \"¬∑\"\n",
    "                return c\n",
    "            self.decode = safe_decode\n",
    "        else:\n",
    "            self.decode = lambda x: chr(x) if 32 <= x <= 126 else \"?\"\n",
    "\n",
    "        # --- 3. Simulation State ---\n",
    "        self.display_chars = [\"¬∑\"] * self.n_cells\n",
    "        self.display_colors = [(40, 40, 40)] * self.n_cells\n",
    "        self.freshness = np.zeros(self.n_cells, dtype=np.float32)\n",
    "        self.ewma_loss = None\n",
    "        self.step = 0\n",
    "\n",
    "        # --- 4. Widget Setup ---\n",
    "        self.out_widget = widgets.Image(format='png', width=self.width, height=self.height)\n",
    "        self.layout = widgets.VBox([self.out_widget])\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Display the widget in the notebook.\"\"\"\n",
    "        display(self.layout)\n",
    "\n",
    "    def update(self, yb, logits, loss_val):\n",
    "        \"\"\"\n",
    "        Update grid.\n",
    "        Logic:\n",
    "        - If Predicted Token is NOT in itos, display Target Token.\n",
    "        - Colors: Green (Correct), Orange (Incorrect).\n",
    "        \"\"\"\n",
    "        self.step += 1\n",
    "\n",
    "        # --- 1. Tensor Ops ---\n",
    "        with torch.no_grad():\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            p_max, preds = torch.max(probs, dim=-1)\n",
    "\n",
    "            p_max = p_max.cpu().numpy().flatten()\n",
    "            preds = preds.cpu().numpy().flatten()\n",
    "            targets = yb.cpu().numpy().flatten()\n",
    "\n",
    "        # Limit to grid size\n",
    "        limit = min(len(p_max), self.n_cells)\n",
    "\n",
    "        # --- 2. Life/Freshness Simulation ---\n",
    "        is_correct = (preds[:limit] == targets[:limit]).astype(np.float32)\n",
    "        self.freshness *= 0.92 # Decay global freshness\n",
    "\n",
    "        # Update Rule: Update if New Confidence > Old Freshness OR Old Freshness < 0.10 (faded)\n",
    "        current_freshness = self.freshness[:limit]\n",
    "        update_mask = (p_max[:limit] > current_freshness) | (current_freshness < 0.10)\n",
    "\n",
    "        # Apply updates to freshness buffer\n",
    "        self.freshness[:limit] = np.where(update_mask, p_max[:limit], current_freshness)\n",
    "\n",
    "        # --- 3. Color Calculation (Vectorized) ---\n",
    "        # Only calculate for updated cells\n",
    "        update_indices = np.where(update_mask)[0]\n",
    "\n",
    "        if len(update_indices) > 0:\n",
    "            # Get subset of values\n",
    "            vals = p_max[:limit][update_indices] * 255.0\n",
    "            vals = np.maximum(50.0, vals) # Minimum brightness so nothing is invisible\n",
    "            corrects = is_correct[update_indices]\n",
    "\n",
    "            # RGB Logic\n",
    "            # Correct (Greenish): R=0.5v, G=1.0v, B=0.25v\n",
    "            # Incorrect (Orange): R=1.0v, G=0.5v, B=0.0v\n",
    "            r = (corrects * (vals * 0.5) + (1 - corrects) * vals).astype(np.int32)\n",
    "            g = (corrects * vals + (1 - corrects) * (vals * 0.5)).astype(np.int32)\n",
    "            b = (corrects * (vals * 0.25)).astype(np.int32)\n",
    "\n",
    "            # --- 4. Update State Lists (The Loop) ---\n",
    "            # We iterate only the changed indices\n",
    "            for i, idx in enumerate(update_indices):\n",
    "                token_id = preds[idx]\n",
    "                target_id = targets[idx]\n",
    "\n",
    "                # PATCH: Fallback to Target if Prediction is OOV\n",
    "                if self.itos_map and (token_id not in self.itos_map):\n",
    "                    token_id = target_id\n",
    "\n",
    "                self.display_chars[idx] = self.decode(token_id)\n",
    "                self.display_colors[idx] = (r[i], g[i], b[i])\n",
    "\n",
    "        # --- 5. Rendering (PIL) ---\n",
    "        img = Image.new(\"RGB\", (self.width, self.height), (10, 10, 10))\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        # Optimization: Local variable references for loop speed\n",
    "        d_text = draw.text\n",
    "        fnt = self.font\n",
    "        cw, ch = self.cell_w, self.cell_h\n",
    "        cols = self.cols\n",
    "        chars = self.display_chars\n",
    "        colors = self.display_colors\n",
    "\n",
    "        for i in range(self.n_cells):\n",
    "            y_row = i // cols\n",
    "            x_col = i % cols\n",
    "\n",
    "            px = x_col * cw\n",
    "            py = y_row * ch + 40 # Offset for stats bar\n",
    "\n",
    "            d_text((px, py), chars[i], font=fnt, fill=colors[i])\n",
    "\n",
    "        # --- 6. Stats Bar ---\n",
    "        if self.ewma_loss is None: self.ewma_loss = loss_val\n",
    "        else: self.ewma_loss = 0.95 * self.ewma_loss + 0.05 * loss_val\n",
    "\n",
    "        acc = np.mean(is_correct)\n",
    "\n",
    "        # Stats Background\n",
    "        draw.rectangle([0, 0, self.width, 35], fill=(20, 20, 20))\n",
    "\n",
    "        # Stats Text\n",
    "        draw.text((10, 10), f\"STEP: {self.step}\", font=fnt, fill=(200, 200, 200))\n",
    "        draw.text((100, 10), f\"LOSS: {loss_val:.4f}\", font=fnt, fill=(255, 100, 100))\n",
    "        draw.text((220, 10), f\"EWMA: {self.ewma_loss:.4f}\", font=fnt, fill=(255, 255, 0))\n",
    "        draw.text((340, 10), f\"ACC: {acc:.1%}\", font=fnt, fill=(0, 255, 0))\n",
    "\n",
    "        # --- 7. Push to Widget ---\n",
    "        with io.BytesIO() as output:\n",
    "            img.save(output, format=\"PNG\")\n",
    "            self.out_widget.value = output.getvalue()\n",
    "\n",
    "# Usage\n",
    "dashboard = MatrixDashboard(batch_size, block_size, itos=itos)\n",
    "dashboard.render()\n",
    "#dashboard.update(yb, logits, loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8noLSyVFBppW",
   "metadata": {
    "id": "8noLSyVFBppW"
   },
   "source": [
    "\n",
    "*   https://youtu.be/MnA4ZpA0IC4\n",
    "*   https://www.youtube.com/watch?v=rWfqjmd7NaA\n",
    "*   https://youtu.be/09X7yzffmME\n",
    "*   https://www.youtube.com/watch?v=6HNiJQKRiWg\n",
    "\n",
    "to listen while you train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "DwnSFzKVrlBZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "DwnSFzKVrlBZ",
    "outputId": "d7cb05e4-31f3-4f57-ec43-408702dd1b7e",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m num_epochs = \u001b[32m10\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m2d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Train loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m xb, yb = xb[\u001b[32m0\u001b[39m], yb[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# unwrap batch dimension\u001b[39;00m\n\u001b[32m      9\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m logits, loss = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m loss.backward()\n\u001b[32m     13\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 509\u001b[39m, in \u001b[36mGPT.forward\u001b[39m\u001b[34m(self, idx, targets)\u001b[39m\n\u001b[32m    506\u001b[39m x = \u001b[38;5;28mself\u001b[39m.transformer.wte(idx) \u001b[38;5;66;03m# token embeddings of shape (b, t, n_embd)\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transformer.h:\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m     x = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    510\u001b[39m x = \u001b[38;5;28mself\u001b[39m.transformer.ln_f(x)\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    513\u001b[39m     \u001b[38;5;66;03m# if we are given some desired targets also calculate the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 405\u001b[39m, in \u001b[36mMaxwellNavierBlock.forward\u001b[39m\u001b[34m(self, B_field)\u001b[39m\n\u001b[32m    400\u001b[39m B_new = B_field + \u001b[38;5;28mself\u001b[39m.dt * delta_B\n\u001b[32m    402\u001b[39m \u001b[38;5;66;03m# 4. MLP (Source Term / Reaction)\u001b[39;00m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# In NS/MHD, this would be external forcing. \u001b[39;00m\n\u001b[32m    404\u001b[39m \u001b[38;5;66;03m# In Transformers, it's point-wise processing.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m B_final = B_new + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mln_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB_new\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m B_final\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 424\u001b[39m, in \u001b[36mMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    423\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mc_fc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m     x = x * torch.sigmoid(\u001b[38;5;28mself\u001b[39m.scale * x)\n\u001b[32m    426\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.c_proj(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# === Run Training ===\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch()\n",
    "    print(f\"Epoch {epoch:2d} | Train loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "771f480f-211b-4f34-94dd-375d31a44a18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "771f480f-211b-4f34-94dd-375d31a44a18",
    "outputId": "0985dd00-10c5-4c03-bff3-ff648eb641b2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Training Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss over Steps\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bPAnSm2UigIW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bPAnSm2UigIW",
    "outputId": "a3408333-62ac-4ea1-d35e-32585efc6791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss (avg over 50 batches): 1.7104\n",
      "Validation perplexity (approx): 5.5312\n"
     ]
    }
   ],
   "source": [
    "# === Validation dataset + loader ===\n",
    "val_batch_size = 8     # tune: how many samples on GPU at once (dataset returns batch-shaped tensors)\n",
    "val_block_size = block_size\n",
    "val_dataset = GPUBatchDataset(val_ids, val_block_size, val_batch_size, device, pad_len=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0)  # dataset already returns batch-shaped tensors\n",
    "\n",
    "# === Eval function ===\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def evaluate_model(model, val_loader, eval_iters=None, device=device):\n",
    "    \"\"\"\n",
    "    Evaluate model over `eval_iters` batches from val_loader (if None: full val loader).\n",
    "    Returns average loss (float).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "\n",
    "          logits, loss = model(xb[0], yb[0])\n",
    "          losses.append(float(loss.item()))\n",
    "\n",
    "          if eval_iters is not None and len(losses) >= eval_iters:\n",
    "              break\n",
    "\n",
    "    model.train()\n",
    "    if len(losses) == 0:\n",
    "        return float('nan')\n",
    "    return float(sum(losses) / len(losses))\n",
    "\n",
    "# === Run validation ===\n",
    "# Quick eval over e.g. 50 validation batches (adjust as desired)\n",
    "val_loss = evaluate_model(model, val_loader, eval_iters=50)\n",
    "print(f\"Validation loss (avg over 50 batches): {val_loss:.4f}\")\n",
    "\n",
    "# Or run over the entire val set (slower)\n",
    "# val_loss_full = evaluate_model(model, val_loader, eval_iters=None)\n",
    "# print(f\"Validation loss (full val set): {val_loss_full:.4f}\")\n",
    "\n",
    "# Optionally compute perplexity\n",
    "val_ppl = math.exp(val_loss) if not math.isinf(val_loss) else float('inf')\n",
    "print(f\"Validation perplexity (approx): {val_ppl:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de2df560-2ff1-441c-a178-228ec4ed13b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de2df560-2ff1-441c-a178-228ec4ed13b5",
    "outputId": "764e6675-ef17-405b-8cdf-e7992ea338d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEOOOOOOLLLLLLLLDDDDDDDDDDDDeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeenooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooAAAAAAAAAiiiiinssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssrsssssssssssssssssssssssssssssssss\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def decode_chars(token_ids, itos):\n",
    "    \"\"\"\n",
    "    Decodes a list of character token IDs into a string.\n",
    "    \"\"\"\n",
    "    return ''.join([itos[i] for i in token_ids])\n",
    "\n",
    "def encode_chars(text, stoi):\n",
    "    \"\"\"\n",
    "    Encodes a string into a list of token IDs, one per character.\n",
    "    \"\"\"\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "\n",
    "def decode_sequence_char(\n",
    "    model, stoi, itos, prompt, max_new_tokens=100, block_size=256,\n",
    "    use_fenchel=False, tau=1.0, fenchel_iters=3, temperature=1.0\n",
    "):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    max_ctx = int(block_size)\n",
    "\n",
    "    # ?1 assume space token exists; fallback to 0 if missing\n",
    "    space_id = stoi.get(' ', 0)\n",
    "\n",
    "    # encode prompt\n",
    "    start_ids = torch.tensor([encode_chars(prompt, stoi)], dtype=torch.long, device=device)\n",
    "\n",
    "    # prepend the pad once; from now on the window just slides\n",
    "\n",
    "    idx = start_ids\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        context = idx[:, -max_ctx:]  # rotating buffer: last pad_len+block_size tokens\n",
    "        logits, _ = model(context)\n",
    "        last_logits = logits[:, -1, :]\n",
    "        probs = torch.softmax(last_logits / temperature, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_token], dim=1)\n",
    "\n",
    "    # drop the initial pad when returning the string\n",
    "    out_tokens = idx[0].tolist()\n",
    "    return decode_chars(out_tokens, itos)\n",
    "with open(\"./babylm_char_tokenized/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi = meta[\"stoi\"]\n",
    "itos = meta[\"itos\"]\n",
    "\n",
    "prompt = \"ROMEO\"\n",
    "generated = decode_sequence_char(\n",
    "    model=model,\n",
    "    stoi=stoi,\n",
    "    itos=itos,\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=512,\n",
    "    block_size=1024,\n",
    "    use_fenchel=False,\n",
    "    tau=1.5,\n",
    "    fenchel_iters=2,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "MzIJQ5lGy0DB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzIJQ5lGy0DB",
    "outputId": "4738acd9-d278-44cb-940d-3faa49264ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "I that the say the say the said the sea the straint\n",
      "A man the straint the straint the shall the straint\n",
      "And the shall the straint the shall the strain\n",
      "And the shall the shall the shall the strain\n",
      "And the shall the shall the shall the strain\n",
      "And the shall the shall the shall the stands the shall the shall the shall the shall the shall the shall the stands\n",
      "And the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the stands the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the stands\n",
      "That the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shan the shan the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the laughted the late the shan the shan the shall the shall the shall the shall the shall the shall the shall the shall the stands\n",
      "That \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def decode_chars(token_ids, itos):\n",
    "    \"\"\"\n",
    "    Decodes a list of character token IDs into a string.\n",
    "    \"\"\"\n",
    "    return ''.join([itos[i] for i in token_ids])\n",
    "\n",
    "def encode_chars(text, stoi):\n",
    "    \"\"\"\n",
    "    Encodes a string into a list of token IDs, one per character.\n",
    "    \"\"\"\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "\n",
    "def decode_sequence_char(\n",
    "    model, stoi, itos, prompt, max_new_tokens=100, block_size=256,\n",
    "    use_fenchel=False, tau=1.0, fenchel_iters=3, temperature=1.0\n",
    "):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    max_ctx = int(block_size)\n",
    "\n",
    "    # ?1 assume space token exists; fallback to 0 if missing\n",
    "    space_id = stoi.get(' ', 0)\n",
    "\n",
    "    # encode prompt\n",
    "    start_ids = torch.tensor([encode_chars(prompt, stoi)], dtype=torch.long, device=device)\n",
    "\n",
    "    # prepend the pad once; from now on the window just slides\n",
    "\n",
    "    idx = start_ids\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        context = idx[:, -max_ctx:]  # rotating buffer: last pad_len+block_size tokens\n",
    "        logits, _ = model(context)\n",
    "        last_logits = logits[:, -1, :]\n",
    "        probs = torch.softmax(last_logits / temperature, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_token], dim=1)\n",
    "\n",
    "    # drop the initial pad when returning the string\n",
    "    out_tokens = idx[0].tolist()\n",
    "    return decode_chars(out_tokens, itos)\n",
    "with open(\"./babylm_char_tokenized/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi = meta[\"stoi\"]\n",
    "itos = meta[\"itos\"]\n",
    "\n",
    "prompt = \"ROMEO\"\n",
    "generated = decode_sequence_char(\n",
    "    model=model,\n",
    "    stoi=stoi,\n",
    "    itos=itos,\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=1024,\n",
    "    block_size=1024,\n",
    "    use_fenchel=False,\n",
    "    tau=1.5,\n",
    "    fenchel_iters=2,\n",
    "    temperature=0.0001\n",
    ")\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aiy3pndLy2-i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aiy3pndLy2-i",
    "outputId": "81176d17-32b2-46a4-ccfb-247c5b47872f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "\n",
      "nvJYsorDforselon Pafnwo?mys' undel;\n",
      "Ghwed\n",
      "'Re him\n",
      "\n",
      "Atilbs,\n",
      "-ask RBOIO, I'e. Lo;tsputradio'nners:\n",
      "E snocnqames axI\n",
      "PuityAunrongs'ss-dia!.\n",
      "Fuckmodgscie esi, ay'tex;;\n",
      "XevysuedDickfomivpb'd! Eyec? AertN oute;\n",
      "And? RwegirntuRold.'Troh, nyt n?\n",
      "Worths,\n",
      "I zroy'sp Vettoin\n",
      "Pumni' wwife yours it: ecred, wou\n",
      "Adial swnia, shogse: oirfeir urn Idad art it jwet:\n",
      "neaw?Jouss 'n bOnmf.\n",
      "\n",
      "Eit nyack!\n",
      "Ic:ur's Q'owny: 'mord; frai Ae'k deep phcl we, him curVomndaue\n",
      "-\n",
      "bOsrmy wef?jiles.-On<unk>uber Lack:;\n",
      "ahchysmulm sshapisJlin\n",
      "Nl ctoyvit my;ca Pl-I's choniw,y brot;\n",
      "Fit clotg'Fr'nstGroonX:' c!\n",
      "T3WUKIUCZQiHT:Ute; hobnerwhadwit whn\n",
      "PrpaubWrplcout botock\n",
      "TAndil, tme dzbb\n",
      "Fy;; and hic\n",
      "Hinkle  getssenswatie, daypth'onlosn,\n",
      "Noqt,oe.I\n",
      "BOKMAlSic:Bu,,,' wemainaureyes afwn,\n",
      "Ox k? Vicwarddbds.\n",
      "sict braoth. asjucty? sceak:\n",
      "SLYcurl-corkint: gavoes:hy, in'zing?\n",
      "O, TomTuch!' Genyious'fer:.roff iMEftelt.\n",
      "At;egroIa$Piluy!So is,: is yeiW? mort f a fuechPE,uq's!'\n",
      "CoFta\n",
      "Mn'dPoomle'u low't.!euly: mortJUlrfadswel;'Bumdr two.\n",
      "N- gay,,week.\n",
      "Butteo'm, so his lur\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def decode_chars(token_ids, itos):\n",
    "    \"\"\"\n",
    "    Decodes a list of character token IDs into a string.\n",
    "    \"\"\"\n",
    "    return ''.join([itos[i] for i in token_ids])\n",
    "\n",
    "def encode_chars(text, stoi):\n",
    "    \"\"\"\n",
    "    Encodes a string into a list of token IDs, one per character.\n",
    "    \"\"\"\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "\n",
    "def decode_sequence_char(\n",
    "    model, stoi, itos, prompt, max_new_tokens=100, block_size=256,\n",
    "    use_fenchel=False, tau=1.0, fenchel_iters=3, temperature=1.0\n",
    "):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    max_ctx = int(block_size)\n",
    "\n",
    "    # ?1 assume space token exists; fallback to 0 if missing\n",
    "    space_id = stoi.get(' ', 0)\n",
    "\n",
    "    # encode prompt\n",
    "    start_ids = torch.tensor([encode_chars(prompt, stoi)], dtype=torch.long, device=device)\n",
    "\n",
    "    # prepend the pad once; from now on the window just slides\n",
    "\n",
    "    idx = start_ids\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        context = idx[:, -max_ctx:]  # rotating buffer: last pad_len+block_size tokens\n",
    "        logits, _ = model(context)\n",
    "        last_logits = logits[:, -1, :]\n",
    "        probs = torch.softmax(last_logits / temperature, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_token], dim=1)\n",
    "\n",
    "    # drop the initial pad when returning the string\n",
    "    out_tokens = idx[0].tolist()\n",
    "    return decode_chars(out_tokens, itos)\n",
    "with open(\"./babylm_char_tokenized/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi = meta[\"stoi\"]\n",
    "itos = meta[\"itos\"]\n",
    "\n",
    "prompt = \"ROMEO:\"\n",
    "generated = decode_sequence_char(\n",
    "    model=model,\n",
    "    stoi=stoi,\n",
    "    itos=itos,\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=1024,\n",
    "    block_size=1024,\n",
    "    use_fenchel=False,\n",
    "    tau=1.5,\n",
    "    fenchel_iters=2,\n",
    "    temperature=2.5\n",
    ")\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7qRpAz81DsJ9",
   "metadata": {
    "id": "7qRpAz81DsJ9"
   },
   "outputs": [],
   "source": [
    "torch.save(model,\"model.pth\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
