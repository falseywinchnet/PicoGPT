{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed9e26f",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/falseywinchnet/PicoGPT/blob/main/ParsevalHaarAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73bbf857-246b-46e3-a124-4812cb4a2dfe",
   "metadata": {
    "id": "73bbf857-246b-46e3-a124-4812cb4a2dfe"
   },
   "outputs": [],
   "source": [
    "#copyright joshuah.rainstar@gmail.com 2025\n",
    "#MIT with attribution\n",
    "\n",
    "import math\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# ----------------------------\n",
    "# Layers\n",
    "# ----------------------------\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, ndim: int, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.use_bias = bias\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(ndim))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b =self.bias if self.use_bias else None\n",
    "        return F.layer_norm(x, self.weight.shape, self.weight, b, 1e-5)\n",
    "\n",
    "\n",
    "\n",
    "class ParsevalRotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim: int, max_seq_len: int = 2048, theta_base: float = 10000.0):\n",
    "        \"\"\"\n",
    "        dim: embedding dimension (must be even).\n",
    "        max_seq_len: maximum sequence length for which to precompute sines/cosines.\n",
    "        theta_base: base for frequency schedule (as in RoPE).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert dim % 2 == 0, \"dim must be even for pairing\"\n",
    "        self.dim = dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        # compute frequency for each pair\n",
    "        half = dim // 2\n",
    "        inv_freq = 1.0 / (theta_base ** (torch.arange(0, half, 1, dtype=torch.float32) / half))\n",
    "\n",
    "        # position indices\n",
    "        pos = torch.arange(max_seq_len, dtype=torch.float32).unsqueeze(1)  # (max_seq_len,1)\n",
    "        # angles (max_seq_len x half) = pos * inv_freq\n",
    "        angles = pos * inv_freq.unsqueeze(0)  # broadcast\n",
    "        # compute cos and sin matrices for each pos and each half-dim\n",
    "        self.register_buffer(\"cos\", angles.cos().unsqueeze(0).unsqueeze(0))  # (1,1,max_seq_len,half)\n",
    "        self.register_buffer(\"sin\", angles.sin().unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, seq_pos: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: shape (B, H, T, D) or (B, T, H, D)\n",
    "        seq_pos: tensor of positions indices shape (T,) or (B,T)\n",
    "        Returns: same shape x but positionally encoded via orthogonal rotations.\n",
    "        \"\"\"\n",
    "        # assume shape (B, H, T, D)\n",
    "        B, H, T, D = x.shape\n",
    "        half = D // 2\n",
    "        # get cos/sin for positions\n",
    "        # pos angles shape (1,1,T,half)\n",
    "        cos_t = self.cos[:, :, seq_pos, :]  # broadcast\n",
    "        sin_t = self.sin[:, :, seq_pos, :]\n",
    "\n",
    "        x1 = x[..., :half]\n",
    "        x2 = x[..., half:]\n",
    "\n",
    "        # apply rotation: [x1'; x2'] = [x1*cos - x2*sin, x1*sin + x2*cos]\n",
    "        x1_rot = x1 * cos_t - x2 * sin_t\n",
    "        x2_rot = x1 * sin_t + x2 * cos_t\n",
    "\n",
    "        x_rot = torch.cat([x1_rot, x2_rot], dim=-1)\n",
    "        return x_rot\n",
    "\n",
    "\n",
    "\n",
    "def l2_normalize(x, dim=-1, eps=1e-8):\n",
    "    return x / (x.norm(dim=dim, keepdim=True) + eps)\n",
    "\n",
    "def build_haar_wavelet_basis(T, levels, device=None, dtype=torch.float32):\n",
    "    \"\"\"\n",
    "    Build a Haar‚Äêwavelet basis matrix W of shape (T, Bcoef).\n",
    "    T: sequence length (must be divisible by 2^levels for full structure, but we will allow slicing).\n",
    "    levels: number of levels of decomposition.\n",
    "    \"\"\"\n",
    "    W_list = []\n",
    "    for j in range(levels):\n",
    "        block_count = 2**j\n",
    "        block_size = T // block_count\n",
    "        half = block_size // 2\n",
    "        for k in range(block_count):\n",
    "            vec = torch.zeros(T, dtype=dtype, device=device)\n",
    "            start = k * block_size\n",
    "            mid   = start + half\n",
    "            end   = start + block_size\n",
    "            if half > 0:\n",
    "                vec[start:mid] =  1.0 / math.sqrt(half)\n",
    "                vec[mid:end]  = -1.0 / math.sqrt(half)\n",
    "            W_list.append(vec)\n",
    "    W = torch.stack(W_list, dim=1)  # shape (T, Bcoef)\n",
    "    return W\n",
    "\n",
    "def variance_scaled_softmax(scores, dim: int = -1, eps: float = 1e-6):\n",
    "    # scores may contain -inf from masking\n",
    "    finite = torch.isfinite(scores)\n",
    "    m = finite.to(scores.dtype)                     # 1 where valid, 0 where masked\n",
    "    n = m.sum(dim=dim, keepdim=True).clamp_min(1)  # count of valid entries per row\n",
    "\n",
    "    # mean/var over valid entries only (population var)\n",
    "    safe_scores = torch.where(finite, scores, torch.zeros_like(scores))\n",
    "    mean = (safe_scores * m).sum(dim=dim, keepdim=True) / n\n",
    "    var  = ((safe_scores - mean)**2 * m).sum(dim=dim, keepdim=True) / n\n",
    "    std  = var.clamp_min(eps).sqrt()\n",
    "\n",
    "    scaled = (safe_scores - mean) / std\n",
    "    scaled = torch.where(finite, scaled, float('-inf'))  # restore mask\n",
    "    out = torch.softmax(scaled, dim=dim)\n",
    "    out = torch.where(n == 0, torch.zeros_like(out), out)  # fully-masked rows -> zeros\n",
    "    return out\n",
    "\n",
    "class DirectionalWedgeBias(nn.Module):\n",
    "    def __init__(self, dim, heads, gamma=1.0):\n",
    "        super().__init__()\n",
    "        self.n_head = heads\n",
    "        self.head_dim = dim // heads\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # A -> The generator of the Symplectic Form S\n",
    "        # We learn A per head to allow different heads to track different \n",
    "        # kinds of curvature (e.g., short-term twists vs long-term arcs).\n",
    "        self.A = nn.Parameter(torch.empty(heads, self.head_dim, self.head_dim))\n",
    "        \n",
    "        # Initialization: Orthogonal ensures distinct, non-collapsing flows.\n",
    "        # We scale by 0.1 to start with a subtle but firm geometric bias.\n",
    "        nn.init.orthogonal_(self.A, gain=0.1)\n",
    "        \n",
    "        # Learnable decay rate for the influence of this bias over distance\n",
    "        # (Soft locality)\n",
    "        self.log_tau = nn.Parameter(torch.zeros(heads)) \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Input vectors (B, T, D) - serves as the 'tangent' vector for the wedge.\n",
    "        Returns: (B, H, T, T) bias tensor.\n",
    "        \"\"\"\n",
    "        B, T, D = x.shape\n",
    "        H, Dh = self.n_head, self.head_dim\n",
    "        \n",
    "        # Reshape to heads: (B, T, H, Dh) -> (B, H, T, Dh)\n",
    "        # We normalize x here to ensure the wedge measures purely geometry (angle/area),\n",
    "        # not magnitude.\n",
    "        v = x.view(B, T, H, Dh).transpose(1, 2)\n",
    "        v = F.normalize(v, dim=-1) \n",
    "        \n",
    "        # Skew-Symmetric Form: S = A - A^T\n",
    "        # S_ij = -S_ji. This is the definition of a symplectic form.\n",
    "        S = self.A - self.A.transpose(-1, -2) # (H, Dh, Dh)\n",
    "        \n",
    "        # Compute the Wedge Product: v_i^T S v_j\n",
    "        # 1. Apply S to v: (B, H, T, Dh) @ (H, Dh, Dh) -> (B, H, T, Dh)\n",
    "        Sv = torch.matmul(v, S) \n",
    "        \n",
    "        # 2. Dot product with v (broadcast over T):\n",
    "        # We want output (B, H, T, T).\n",
    "        # (B, H, T, Dh) @ (B, H, Dh, T) -> (B, H, T, T)\n",
    "        wedge = torch.matmul(Sv, v.transpose(-1, -2))\n",
    "        \n",
    "        # Apply Distance Decay (Optional but recommended for stability)\n",
    "        # We use a simplified decay based on simple index distance to damp\n",
    "        # the symplectic term at extreme ranges, preventing exploding gradients.\n",
    "        # However, since we replaced RoPE, we might want this to be the ONLY\n",
    "        # position info, so we keep it fairly global.\n",
    "        \n",
    "        tau = F.softplus(self.log_tau).view(1, H, 1, 1) + 1e-4\n",
    "        idx = torch.arange(T, device=x.device)\n",
    "        dist = (idx[None, :] - idx[:, None]).abs().view(1, 1, T, T)\n",
    "        decay = torch.exp(-dist * 0.01 / tau) \n",
    "\n",
    "        return self.gamma * wedge * decay\n",
    "        \n",
    "\n",
    "class ParsevalWaveletAttention(nn.Module):\n",
    "    def __init__(self, config, near_window=64):\n",
    "        super().__init__()\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.head_dim = self.n_embd // self.n_head\n",
    "        \n",
    "        assert self.head_dim * self.n_head == self.n_embd, \"n_embd must be divisible by n_head\"\n",
    "\n",
    "        # Null Vector Parameters (The Sink)\n",
    "        # One unique sink per head to allow independent \"voting\"\n",
    "        self.k_null = nn.Parameter(torch.randn(1, 1, self.n_head, self.head_dim) * 0.02)\n",
    "        self.register_buffer(\"v_null\", torch.zeros(1, 1, self.n_head, self.head_dim))\n",
    "        self.W_Q = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "        self.W_K = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "        self.W_V = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "        self.W_O = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "        \n",
    "        self.ln = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        \n",
    "        # Auto-tune levels\n",
    "        target_block = near_window * 2\n",
    "        min_blocks = config.block_size / target_block\n",
    "        self.wavelet_levels = max(3, int(math.ceil(math.log2(min_blocks))) + 1)\n",
    "        \n",
    "        self.near_window = near_window\n",
    "        self.block_size = config.block_size\n",
    "        \n",
    "        W_haar_full = build_haar_wavelet_basis(self.block_size,\n",
    "                                               self.wavelet_levels,\n",
    "                                               device='cpu')\n",
    "        W_haar_full = l2_normalize(W_haar_full, dim=0)\n",
    "        self.register_buffer(\"W_haar_full\", W_haar_full)\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                 .view(1, 1, config.block_size, config.block_size)\n",
    "        )\n",
    "        self.pos_encoder = ParsevalRotaryEmbedding(dim=self.head_dim, max_seq_len=config.block_size)\n",
    "        self.wedge_bias = DirectionalWedgeBias(self.n_embd, self.n_head, gamma=0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        H = self.n_head\n",
    "        D = self.head_dim\n",
    "        geo_bias = self.wedge_bias(x) # (B, H, T, T)\n",
    "        # Project and split heads\n",
    "        q = self.W_Q(x).view(B, T, H, D).transpose(1, 2) # (B, H, T, D)\n",
    "        k = self.W_K(x).view(B, T, H, D).transpose(1, 2)\n",
    "        v = self.W_V(self.ln(x)).view(B, T, H, D).transpose(1, 2)\n",
    "\n",
    "        # Rotary Positional Embedding\n",
    "        idx = torch.arange(T, device=x.device)\n",
    "        #q = self.pos_encoder(q, idx)\n",
    "        #k = self.pos_encoder(k, idx)\n",
    "\n",
    "        # L2 Normalize (Hyperspherical Manifold)\n",
    "        q = l2_normalize(q, dim=-1)\n",
    "        k = l2_normalize(k, dim=-1)\n",
    "        k_null_norm = l2_normalize(self.k_null, dim=-1) # Normalize sink too\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # 1. Compute Sequence Attention (Near + Far)\n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Near Field (Standard)\n",
    "        near_mask = (idx.view(1,-1) - idx.view(-1,1)).abs() <= self.near_window\n",
    "        # Expand mask for heads: (1, 1, T, T)\n",
    "        near_mask = near_mask.view(1, 1, T, T)\n",
    "        \n",
    "        att_near = (q @ k.transpose(-2, -1)) # (B, H, T, T)\n",
    "        att_near = att_near + geo_bias\n",
    "        att_near = att_near.masked_fill(~near_mask, float('-inf'))\n",
    "\n",
    "        # Far Field (Wavelet Projected)\n",
    "        W_h = self.W_haar_full[:T, :].to(x.device)\n",
    "        \n",
    "        # Flatten heads for projection: (B*H, T, D)\n",
    "        q_flat = q.reshape(B * H, T, D)\n",
    "        k_flat = k.reshape(B * H, T, D)\n",
    "        \n",
    "        q_far = W_h.T @ q_flat # (B*H, Bcoef, D)\n",
    "        k_far = W_h.T @ k_flat\n",
    "        \n",
    "        # Compressed Attention\n",
    "        att_far_comp = (q_far @ k_far.transpose(-2,-1)) # (B*H, Bcoef, Bcoef)\n",
    "        \n",
    "        # Reconstruct\n",
    "        att_far_exp = (W_h @ att_far_comp) @ W_h.T\n",
    "        att_far_exp = att_far_exp.view(B, H, T, T)\n",
    "        \n",
    "        # Combine\n",
    "        att_seq = torch.where(near_mask, att_near, att_far_exp)\n",
    "        att_seq = att_seq.masked_fill(self.mask[:, :, :T, :T] == 0, float('-inf'))\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        # 2. Incorporate Null Vector (The Sink)\n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Calculate score against Null Vector\n",
    "        # q: (B, H, T, D)\n",
    "        # k_null: (1, 1, H, D) -> broadcast to (B, H, 1, D)\n",
    "        k_null_ex = k_null_norm.expand(B, -1, -1, -1).transpose(1, 2) # (B, H, 1, D)\n",
    "        \n",
    "        # null_scores: (B, H, T, 1)\n",
    "        null_scores = q @ k_null_ex.transpose(-2, -1)\n",
    "        \n",
    "        # Concatenate scores: Sequence Scores + Null Score\n",
    "        # att_full: (B, H, T, T+1)\n",
    "        att_full = torch.cat([att_seq, null_scores], dim=-1)\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        # 3. Variance Scaled Softmax\n",
    "        # ---------------------------------------------------------\n",
    "        att_full = variance_scaled_softmax(att_full, dim=-1)\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        # 4. Weighted Sum\n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        # Split attention weights back into sequence and null\n",
    "        attn_seq_probs = att_full[..., :T]   # (B, H, T, T)\n",
    "        attn_null_probs = att_full[..., T:]  # (B, H, T, 1)\n",
    "        \n",
    "        # Sequence contribution\n",
    "        y = attn_seq_probs @ v # (B, H, T, D)\n",
    "        \n",
    "        # Reassemble heads\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, self.n_embd)\n",
    "        \n",
    "        return self.W_O(y)\n",
    "\n",
    "# ----------------------------\n",
    "# Transformer Block\n",
    "# ----------------------------\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear( config.n_embd,4* config.n_embd, bias=config.bias)\n",
    "        self.scale = math.pi / math.sqrt(3.0)\n",
    "\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = x * torch.sigmoid(self.scale * x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.attn = ParsevalWaveletAttention(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 768\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
    "        ))\n",
    "\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        # with weight tying when using torch.compile() some warnings get generated:\n",
    "        # \"UserWarning: functional_call was passed multiple values for tied weights.\n",
    "        # This behavior is deprecated and will be an error in future versions\"\n",
    "        # not 100% sure what this is, so far seems to be harmless. TODO investigate\n",
    "        # init all weights\n",
    "        self.apply(self._init_weights)\n",
    "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "\n",
    "        # report number of parameters\n",
    "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
    "\n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        \"\"\"\n",
    "        Return the number of parameters in the model.\n",
    "        For non-embedding count (default), the position embeddings get subtracted.\n",
    "        The token embeddings would too, except due to the parameter sharing these\n",
    "        params are actually used as weights in the final layer, so we include them.\n",
    "        \"\"\"\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        return n_params\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, T = idx.size()\n",
    "\n",
    "        # forward the GPT model itself\n",
    "        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
    "\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            # if we are given some desired targets also calculate the loss\n",
    "            logits = self.lm_head(x)\n",
    "           \n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "\n",
    "        else:\n",
    "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
    "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc40ec9f-1475-4836-a1e7-ee97b37adad9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc40ec9f-1475-4836-a1e7-ee97b37adad9",
    "outputId": "57b2be6a-8789-4a4b-83c7-a264fe26aa97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading aochildes.txt...\n",
      "üì• Downloading cbt.txt...\n",
      "üì• Downloading children_stories.txt...\n",
      "üì• Downloading gutenberg.txt...\n",
      "üì• Downloading qed.txt...\n",
      "üì• Downloading simple_wikipedia.txt...\n",
      "üì• Downloading switchboard.txt...\n",
      "üì• Downloading wikipedia.txt...\n",
      "üì• Downloading shakespeare.txt...\n",
      "‚úÖ Done. Files saved to ./babylm_10m_cleaned\n"
     ]
    }
   ],
   "source": [
    "import requests, os\n",
    "\n",
    "base_url = \"https://huggingface.co/datasets/cambridge-climb/BabyLM/resolve/main/clean/10M/\"\n",
    "target_dir = \"./babylm_10m_cleaned\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "file_names = [\n",
    "    \"aochildes.txt\",\n",
    "    \"cbt.txt\",\n",
    "    \"children_stories.txt\",\n",
    "    \"gutenberg.txt\",\n",
    "    \"qed.txt\",\n",
    "    \"simple_wikipedia.txt\",\n",
    "    \"switchboard.txt\",\n",
    "    \"wikipedia.txt\"\n",
    "]\n",
    "\n",
    "# Optional addition: Shakespeare from another dataset\n",
    "shakespeare_url = \"https://drive.google.com/uc?export=download&id=1_aiQyJTgcCBq26QssgIWHZFx_eVzm8uz\"\n",
    "shakespeare_fname = \"shakespeare.txt\"\n",
    "\n",
    "# Combined download logic\n",
    "all_files = [(base_url + fname, fname) for fname in file_names]\n",
    "all_files.append((shakespeare_url, shakespeare_fname))  # Add Shakespeare\n",
    "\n",
    "\n",
    "# Download loop\n",
    "for url, fname in all_files:\n",
    "    out_path = os.path.join(target_dir, fname)\n",
    "    print(f\"üì• Downloading {fname}...\")\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(resp.text)\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to download {fname} ({resp.status_code})\")\n",
    "\n",
    "print(f\"‚úÖ Done. Files saved to {target_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9648818a-ba26-4737-9a20-0da0bd3090db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9648818a-ba26-4737-9a20-0da0bd3090db",
    "outputId": "b80213fe-ae68-4960-f665-7624b03b3516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Char tokenizer finalized.\n",
      "üßæ Train tokens: 1016242 | Val tokens: 99152\n",
      "üî§ Vocab size: 66\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# === Paths ===\n",
    "source_dir = \"./babylm_10m_cleaned\"\n",
    "out_dir    = \"./babylm_char_tokenized\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "file_names = [\n",
    "    \"shakespeare.txt\"#,\"aochildes.txt\", \"cbt.txt\", \"children_stories.txt\", \"gutenberg.txt\",\n",
    "    #\"qed.txt\", \"simple_wikipedia.txt\", \"switchboard.txt\", \"wikipedia.txt\"\n",
    "]\n",
    "\n",
    "# === Load and split ===\n",
    "train_texts, val_texts = [], []\n",
    "char_set = set()\n",
    "\n",
    "for fname in file_names:\n",
    "    with open(os.path.join(source_dir, fname), encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        n = len(lines)\n",
    "        split = int(0.9 * n)\n",
    "        train_part = \"\".join(lines[:split])\n",
    "        val_part   = \"\".join(lines[split:])\n",
    "        train_texts.append(train_part)\n",
    "        val_texts.append(val_part)\n",
    "        char_set.update(train_part)\n",
    "        char_set.update(val_part)\n",
    "\n",
    "full_train = \"\\n\".join(train_texts)\n",
    "full_val   = \"\\n\".join(val_texts)\n",
    "\n",
    "# === Final vocab ===\n",
    "char_set = sorted(set(char_set))\n",
    "vocab_chars = [\"<unk>\"] + [c for c in char_set if c != \"<unk>\"]\n",
    "\n",
    "stoi = {ch: i for i, ch in enumerate(vocab_chars)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "\n",
    "# === Encode function ===\n",
    "def encode(text):\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "train_ids = np.array(encode(full_train), dtype=np.uint16)\n",
    "val_ids   = np.array(encode(full_val),   dtype=np.uint16)\n",
    "\n",
    "# === Save ===\n",
    "train_ids.tofile(os.path.join(out_dir, \"train.bin\"))\n",
    "val_ids.tofile(os.path.join(out_dir, \"val.bin\"))\n",
    "\n",
    "with open(os.path.join(out_dir, \"meta.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"vocab_size\": len(stoi),\n",
    "        \"stoi\": stoi,\n",
    "        \"itos\": itos\n",
    "    }, f)\n",
    "\n",
    "print(f\"‚úÖ Char tokenizer finalized.\")\n",
    "print(f\"üßæ Train tokens: {len(train_ids)} | Val tokens: {len(val_ids)}\")\n",
    "print(f\"üî§ Vocab size: {len(stoi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70cb41e0-48cb-4b78-811e-8bde12e7abfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70cb41e0-48cb-4b78-811e-8bde12e7abfa",
    "outputId": "9061f4f7-b1de-4506-ef28-9fc5aa5b2a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.83M\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# === Config ===\n",
    "data_dir = \"./babylm_char_tokenized\"  # <- char-tokenized data\n",
    "block_size = 1024\n",
    "batch_size = 8\n",
    "\n",
    "# === Load tokenizer metadata ===\n",
    "with open(os.path.join(data_dir, 'meta.pkl'), 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "vocab_size = meta['vocab_size']\n",
    "\n",
    "# === Load mmap edata (char-level tokens, uint16) ===\n",
    "train_ids = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n",
    "val_ids   = np.memmap(os.path.join(data_dir, 'val.bin'),   dtype=np.uint16, mode='r')\n",
    "\n",
    "# === Efficient GPU Batch Sampler ===\n",
    "class GPUBatchDataset(Dataset):\n",
    "    def __init__(self, mmap_file, block_size, batch_size, device, jitter=63, p_aligned=0.5, pad_len=0):\n",
    "        self.data = mmap_file\n",
    "        self.block_size = block_size\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.pad_len = int(pad_len)\n",
    "        self.sample_len = self.block_size + self.pad_len  # X length\n",
    "        self.total = len(self.data) - self.sample_len - 1\n",
    "        self.n_blocks = self.total // self.sample_len\n",
    "        self.jitter = int(jitter)          # small random offset added to aligned start\n",
    "        self.p_aligned = float(p_aligned)  # mix aligned and jittered\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = np.empty((self.batch_size, self.sample_len), dtype=np.int64)\n",
    "        Y = np.empty((self.batch_size, self.block_size), dtype=np.int64)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            # choose a base aligned block\n",
    "            base_block = np.random.randint(0, self.n_blocks)\n",
    "            start = base_block * self.sample_len\n",
    "\n",
    "            # with probability, add a small jitter (keeps cache-friendly contiguous reads)\n",
    "            if np.random.rand() > self.p_aligned:\n",
    "                j = np.random.randint(0, self.jitter + 1)\n",
    "                start = min(start + j, self.total)  # stay in range\n",
    "\n",
    "            X[i] = self.data[start : start + self.sample_len]\n",
    "            # targets correspond to the final block_size visible steps\n",
    "            Y[i] = self.data[start + 1 + self.pad_len : start + 1 + self.pad_len + self.block_size]\n",
    "\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(X).to(self.device, non_blocking=True),\n",
    "            torch.from_numpy(Y).to(self.device, non_blocking=True)\n",
    "        )\n",
    "\n",
    "\n",
    "config = GPTConfig(\n",
    "    vocab_size=len(stoi),\n",
    "    n_layer=4,\n",
    "    n_embd=128,\n",
    "    n_head = 4,\n",
    "\n",
    "    block_size=block_size,\n",
    ")\n",
    "train_dataset = GPUBatchDataset(train_ids, block_size, batch_size, device, pad_len=0)\n",
    "# === DataLoader ===\n",
    "train_loader  = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "model = GPT(config)\n",
    "#model= torch.compile(model)\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f0ccf0-9d48-4e0f-8908-c94adf497969",
   "metadata": {
    "id": "25f0ccf0-9d48-4e0f-8908-c94adf497969",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
    "losses = []\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "          xb, yb = xb[0], yb[0]  # unwrap batch dimension\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          logits, loss = model(xb, yb)\n",
    "          loss.backward()\n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "          optimizer.step()\n",
    "          total_loss += loss.item()\n",
    "          losses.append(loss.item())\n",
    "          dashboard.update(yb, logits, loss.item())\n",
    "    return total_loss / len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hpJ-yb4P4sCe",
   "metadata": {
    "id": "hpJ-yb4P4sCe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81bf706a1c74b5686c676cc65f9d458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'', height='680', width='2050'),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import io\n",
    "import math\n",
    "import time\n",
    "\n",
    "class MatrixDashboard:\n",
    "    def __init__(self, batch_size, seq_len, itos=None):\n",
    "        \"\"\"\n",
    "        High-Performance Dashboard (PIL + ipywidgets).\n",
    "        Features:\n",
    "        - 'Life' animation (fading/persistence)\n",
    "        - Color-coded confidence (Green=Correct, Orange=Incorrect)\n",
    "        - Fallback to Target glyph if Prediction is OOV.\n",
    "        \"\"\"\n",
    "        self.target_cells = batch_size * seq_len\n",
    "        self.itos_map = itos if itos is not None else {}\n",
    "\n",
    "        # --- 1. Geometry & Font Setup ---\n",
    "        # Cinematic aspect ratio logic (approx 2.5:1)\n",
    "        self.rows = int(math.sqrt(self.target_cells / 5))\n",
    "        self.cols = int(np.ceil(self.target_cells / self.rows))\n",
    "        self.n_cells = self.rows * self.cols\n",
    "\n",
    "        # Visual constants\n",
    "        self.cell_w = 10  # pixel width per char\n",
    "        self.cell_h = 16  # pixel height per char\n",
    "        self.width = self.cols * self.cell_w\n",
    "        self.height = self.rows * self.cell_h + 40 # +40 for stats bar\n",
    "\n",
    "        # Load Font (Robust Fallback)\n",
    "        try:\n",
    "            self.font = ImageFont.truetype(\"DejaVuSansMono.ttf\", 11)\n",
    "        except:\n",
    "            try:\n",
    "                self.font = ImageFont.truetype(\"Courier New.ttf\", 11)\n",
    "            except:\n",
    "                self.font = ImageFont.load_default()\n",
    "\n",
    "        # --- 2. Decoder ---\n",
    "        if itos is not None:\n",
    "            def safe_decode(x):\n",
    "                c = itos.get(x, \"?\")\n",
    "                if c == \"\\n\": return \"¬∂\"\n",
    "                if c == \"\\t\": return \"‚Üí\"\n",
    "                if c == \" \": return \"¬∑\"\n",
    "                return c\n",
    "            self.decode = safe_decode\n",
    "        else:\n",
    "            self.decode = lambda x: chr(x) if 32 <= x <= 126 else \"?\"\n",
    "\n",
    "        # --- 3. Simulation State ---\n",
    "        self.display_chars = [\"¬∑\"] * self.n_cells\n",
    "        self.display_colors = [(40, 40, 40)] * self.n_cells\n",
    "        self.freshness = np.zeros(self.n_cells, dtype=np.float32)\n",
    "        self.ewma_loss = None\n",
    "        self.step = 0\n",
    "\n",
    "        # --- 4. Widget Setup ---\n",
    "        self.out_widget = widgets.Image(format='png', width=self.width, height=self.height)\n",
    "        self.layout = widgets.VBox([self.out_widget])\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Display the widget in the notebook.\"\"\"\n",
    "        display(self.layout)\n",
    "\n",
    "    def update(self, yb, logits, loss_val):\n",
    "        \"\"\"\n",
    "        Update grid.\n",
    "        Logic:\n",
    "        - If Predicted Token is NOT in itos, display Target Token.\n",
    "        - Colors: Green (Correct), Orange (Incorrect).\n",
    "        \"\"\"\n",
    "        self.step += 1\n",
    "\n",
    "        # --- 1. Tensor Ops ---\n",
    "        with torch.no_grad():\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            p_max, preds = torch.max(probs, dim=-1)\n",
    "\n",
    "            p_max = p_max.cpu().numpy().flatten()\n",
    "            preds = preds.cpu().numpy().flatten()\n",
    "            targets = yb.cpu().numpy().flatten()\n",
    "\n",
    "        # Limit to grid size\n",
    "        limit = min(len(p_max), self.n_cells)\n",
    "\n",
    "        # --- 2. Life/Freshness Simulation ---\n",
    "        is_correct = (preds[:limit] == targets[:limit]).astype(np.float32)\n",
    "        self.freshness *= 0.92 # Decay global freshness\n",
    "\n",
    "        # Update Rule: Update if New Confidence > Old Freshness OR Old Freshness < 0.10 (faded)\n",
    "        current_freshness = self.freshness[:limit]\n",
    "        update_mask = (p_max[:limit] > current_freshness) | (current_freshness < 0.10)\n",
    "\n",
    "        # Apply updates to freshness buffer\n",
    "        self.freshness[:limit] = np.where(update_mask, p_max[:limit], current_freshness)\n",
    "\n",
    "        # --- 3. Color Calculation (Vectorized) ---\n",
    "        # Only calculate for updated cells\n",
    "        update_indices = np.where(update_mask)[0]\n",
    "\n",
    "        if len(update_indices) > 0:\n",
    "            # Get subset of values\n",
    "            vals = p_max[:limit][update_indices] * 255.0\n",
    "            vals = np.maximum(50.0, vals) # Minimum brightness so nothing is invisible\n",
    "            corrects = is_correct[update_indices]\n",
    "\n",
    "            # RGB Logic\n",
    "            # Correct (Greenish): R=0.5v, G=1.0v, B=0.25v\n",
    "            # Incorrect (Orange): R=1.0v, G=0.5v, B=0.0v\n",
    "            r = (corrects * (vals * 0.5) + (1 - corrects) * vals).astype(np.int32)\n",
    "            g = (corrects * vals + (1 - corrects) * (vals * 0.5)).astype(np.int32)\n",
    "            b = (corrects * (vals * 0.25)).astype(np.int32)\n",
    "\n",
    "            # --- 4. Update State Lists (The Loop) ---\n",
    "            # We iterate only the changed indices\n",
    "            for i, idx in enumerate(update_indices):\n",
    "                token_id = preds[idx]\n",
    "                target_id = targets[idx]\n",
    "\n",
    "                # PATCH: Fallback to Target if Prediction is OOV\n",
    "                if self.itos_map and (token_id not in self.itos_map):\n",
    "                    token_id = target_id\n",
    "\n",
    "                self.display_chars[idx] = self.decode(token_id)\n",
    "                self.display_colors[idx] = (r[i], g[i], b[i])\n",
    "\n",
    "        # --- 5. Rendering (PIL) ---\n",
    "        img = Image.new(\"RGB\", (self.width, self.height), (10, 10, 10))\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        # Optimization: Local variable references for loop speed\n",
    "        d_text = draw.text\n",
    "        fnt = self.font\n",
    "        cw, ch = self.cell_w, self.cell_h\n",
    "        cols = self.cols\n",
    "        chars = self.display_chars\n",
    "        colors = self.display_colors\n",
    "\n",
    "        for i in range(self.n_cells):\n",
    "            y_row = i // cols\n",
    "            x_col = i % cols\n",
    "\n",
    "            px = x_col * cw\n",
    "            py = y_row * ch + 40 # Offset for stats bar\n",
    "\n",
    "            d_text((px, py), chars[i], font=fnt, fill=colors[i])\n",
    "\n",
    "        # --- 6. Stats Bar ---\n",
    "        if self.ewma_loss is None: self.ewma_loss = loss_val\n",
    "        else: self.ewma_loss = 0.95 * self.ewma_loss + 0.05 * loss_val\n",
    "\n",
    "        acc = np.mean(is_correct)\n",
    "\n",
    "        # Stats Background\n",
    "        draw.rectangle([0, 0, self.width, 35], fill=(20, 20, 20))\n",
    "\n",
    "        # Stats Text\n",
    "        draw.text((10, 10), f\"STEP: {self.step}\", font=fnt, fill=(200, 200, 200))\n",
    "        draw.text((100, 10), f\"LOSS: {loss_val:.4f}\", font=fnt, fill=(255, 100, 100))\n",
    "        draw.text((220, 10), f\"EWMA: {self.ewma_loss:.4f}\", font=fnt, fill=(255, 255, 0))\n",
    "        draw.text((340, 10), f\"ACC: {acc:.1%}\", font=fnt, fill=(0, 255, 0))\n",
    "\n",
    "        # --- 7. Push to Widget ---\n",
    "        with io.BytesIO() as output:\n",
    "            img.save(output, format=\"PNG\")\n",
    "            self.out_widget.value = output.getvalue()\n",
    "\n",
    "# Usage\n",
    "dashboard = MatrixDashboard(batch_size, block_size, itos=itos)\n",
    "dashboard.render()\n",
    "#dashboard.update(yb, logits, loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8noLSyVFBppW",
   "metadata": {
    "id": "8noLSyVFBppW"
   },
   "source": [
    "\n",
    "*   https://youtu.be/MnA4ZpA0IC4\n",
    "*   https://www.youtube.com/watch?v=rWfqjmd7NaA\n",
    "*   https://youtu.be/09X7yzffmME\n",
    "*   https://www.youtube.com/watch?v=6HNiJQKRiWg\n",
    "\n",
    "to listen while you train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DwnSFzKVrlBZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "DwnSFzKVrlBZ",
    "outputId": "d7cb05e4-31f3-4f57-ec43-408702dd1b7e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# === Run Training ===\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch()\n",
    "    print(f\"Epoch {epoch:2d} | Train loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "771f480f-211b-4f34-94dd-375d31a44a18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "771f480f-211b-4f34-94dd-375d31a44a18",
    "outputId": "0985dd00-10c5-4c03-bff3-ff648eb641b2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAjBlJREFUeJzt3Qd8U/X6x/GnuxRo2XvvjSxZCiIyFBXcFwe4t9f1d12vAxe4F17c4t5bQVkCsveWvaFlQ2lLd/6v59ee9CRNuijNaft5v165SU5O0pP0yM23z+/3/IJcLpdLAAAAAAB+Bft/CAAAAACgCE4AAAAAkA+CEwAAAADkg+AEAAAAAPkgOAEAAABAPghOAAAAAJAPghMAAAAA5IPgBAAAAAD5IDgBAAAAQD4ITgBQxlx77bXSpEmTIj33ySeflKCgoGI/JgAASjuCEwCUEA0kBbnMnDlTymvgq1SpUqAPo0xZvXq1XHrppdK4cWOJjIyU+vXry6BBg+TNN9/02O+5556Tn376KWDHCQClQZDL5XIF+iAAoDz47LPPPO5/8sknMnXqVPn00089tusX29q1axf556SlpUlmZqZEREQU+rnp6enmol+yAxGcvvvuO0lISCjxn10WzZs3TwYMGCCNGjWS0aNHS506dWTXrl2yYMEC2bJli2zevNm9rwZWDVgTJ04M6DEDgJOFBvoAAKC8uPrqqz3u6xdYDU7e270lJSVJVFRUgX9OWFhYkY8xNDTUXFA6JCYmSsWKFX0+9uyzz0pMTIwsXrxYqlSp4vHY/v37S+gIAaDsYKgeADjIWWedJR06dJClS5dKv379TGD6z3/+Yx77+eefZdiwYVKvXj1TTWrevLk8/fTTkpGRkeccp+3bt5shgC+99JK8++675nn6/B49epgv1fnNcdL7d955pxnKpcemz23fvr388ccfuY5fhxl2797dVKz057zzzjvFPm/q22+/lW7dukmFChWkRo0aJnju2bPHY5+4uDi57rrrpEGDBuZ469atK8OHDzefhWXJkiUyZMgQ8xr6Wk2bNpXrr7++QMfwv//9z3wG+tr6+7jjjjvk6NGj7sf189IqjoZebyNHjjTVH/vvbfLkyXLmmWeaEFS5cmXze167dq3PoYxaLTrvvPPMfldddZXfY9T99Bi9Q5OqVauW+7b+bjSAffzxx+7hovqzLPrZ6ueiVVDrd//hhx/m+r3r877++mtzvur70/dy4YUXmiqX3aZNm+SSSy4x++h5or+jf/3rX3Ls2LE8PnEACDz+rAgADnPo0CE599xzzZdJDQXWsD0dRqVfnO+77z5zPWPGDHn88cclPj5eXnzxxXxf94svvpDjx4/LLbfcYr7kvvDCC3LxxRfL1q1b861SzZkzR3744Qe5/fbbzRf2N954w3z53blzp1SvXt3ss3z5chk6dKgJKWPGjDHB4KmnnpKaNWsW0yeT9RloINLQN3bsWNm3b5+8/vrrMnfuXPPzrZCgx6bB46677jIhUissWt3T47XuDx482Bzbww8/bJ6noUrfY340COr7O+ecc+S2226TDRs2yIQJE0wI1ePQz/KKK66Qt956S37//Xe57LLL3M/VIPXrr7+aYBISEmK26VBNHUqnIe755583++jrnXHGGeY92UOwDqPU/fQxDcJ5VSJ1XtP8+fNlzZo1JvD6oz//xhtvlNNPP11uvvlms01Dr9LPt1evXu7wrJ+XhrwbbrjBnHf33HNPriqX7vvQQw+Zz/i1114zn9OKFStMOE1NTTXHn5KSYn43Gp40mP32228meGqFDAAcS+c4AQBK3h133KFzTD229e/f32x7++23c+2flJSUa9stt9ziioqKciUnJ7u3jR492tW4cWP3/W3btpnXrF69uuvw4cPu7T///LPZ/uuvv7q3PfHEE7mOSe+Hh4e7Nm/e7N62cuVKs/3NN990b7vgggvMsezZs8e9bdOmTa7Q0NBcr+mLHnfFihX9Pp6amuqqVauWq0OHDq4TJ064t//222/m9R9//HFz/8iRI+b+iy++6Pe1fvzxR7PP4sWLXYWxf/9+81kMHjzYlZGR4d4+fvx483offvihuZ+ZmemqX7++65JLLvF4/jfffGP2mz17trl//PhxV5UqVVw33XSTx35xcXGumJgYj+36+ehzH3744QId65QpU1whISHm0rt3b9eDDz7o+vPPP83n6E0/d319bzfccIOrbt26roMHD3ps/9e//mWOzzon//rrL3Ns+p7j4+Nzvd/XX3/d3F++fLm5/+233xboPQCAkzBUDwAcRodDaVXFm/7F3qKVo4MHD5rhXVqhWL9+fb6vq1WQqlWruu/rc5VWnPKjVQOrCqE6deok0dHR7udqdWnatGkyYsQIM3TN0qJFC1M9Kw46tE6rGFr1sjev0GFtbdq0MdUd63MKDw83w8eOHDni87WsypRWOrSZRkHpe9SqiVZagoNz/i/0pptuMp+HdQxaddFK06RJkzyaXehQNu1spxUjpVUwrbTo8D39fVoXrUb17NlT/vrrr1zHoFWugtAmI1px0uFyK1euNBVGrfboz//ll1/yfb5m5u+//14uuOACc9t+fPo6OrRu2bJlHs8ZNWqUqUhatOGEViD1c1BWRenPP//0OYwRAJyM4AQADqNfbPWLvzcdenbRRReZL5/6JV2HTVmNJQoyP0S7q9lZIcpfuMjrudbzredqoDlx4oQJSt58bSuKHTt2mOvWrVvnekyDk/W4Bk8d8qZDynSYo84V09Cg854s/fv3N8P5dMidznHS+U8fffSRGUJWlGPQ31ezZs3cj1tBVT8TK6RogNIAoYHKmvOl833U2WefbX6f9suUKVNyNXHQxh06J6igdEijDj/U39OiRYvkkUceMaFbA826devyfO6BAwdMqNN5cd7HZgV77+Nr2bKlx319n/r7t+aW6TwyHWr6/vvvm89dA5gOaWR+E4DSgDlOAOAw9sqSRb/A6pd9DUw6b0irP1p10b/463wSbT+eH2tOjbeCrEpxMs8NBK0IaaVEG1podeOxxx4zc6J0XliXLl3MF3ptfa6dDXXOke6jDRBefvlls6041pPSuUE6P+mbb76RK6+80vwcDVIaqCzW703nGel8H2/eHQ41FNorXQWlwU5DlF5atWplgo822XjiiSf8Psc6Ng3nOgfLF608FpZ+xjrHS5udaDj897//bX43+rkXJhQCQEkjOAFAKaDDzrRphFYPtIJi2bZtmziBdmnTIGdfG8jia1tRaLMDpc0YtEJjp9usxy0aLu+//35z0crOaaedZr6029fT0nCjF21qoM0ztEvdV199ZZol5HcMWmGy6PA9/V3okEa7yy+/3DSv0EYKOkxPg5T+PPsxWp+f93NPFe16qGJjY93bfHU91MqSDrvTYZgFPTargmYP1vr79w5YHTt2NJf//ve/Zr2pvn37yttvvy3PPPNMEd8VAJx6DNUDgFLAqvjYKzz6ZV3bYjvl+PTLtVZ49u7d696uX5p1yFxxfeHXgKFfsO1D6vT1//nnHzPXSencmeTkZI/nakDREGA9T4eueVfLNFipvIbr6XvU6o12FbQ//4MPPjDDzaxjsGh1SV9PW31r+3YNUnY6VE2riM8995zPuVY6XK6odH6Ur4qgNd/IPtxQW4fb26lbv1MdzqjznLQzX0GOTRd11qGAFq3qaUCz5rlpgNTOgHYaoLSKlt8wSQAINCpOAFAK9OnTx8wp0iFTOrRJKwQ6vMtJQ+W0TbcOvdLqgTYw0ErF+PHjTStsbUddEBoefFUdqlWrZppC6NwlHWamwxa1oYLVjlwrOffee6/Zd+PGjTJw4EATUtq1a2eGu/34449mX23xrjTIaOjUOWMaqvTL/nvvvWdCjK6R5I9WYXSekM6N0tbr2nhBq0/6WjoMznsx465du5o5Po8++qgJBvZhekp/nrYev+aaa8y+enz6M7Rtujaa0M9SP8Oi0HbfGiL1PeocMA3aWt2xKl/2BiS6LpY2vnjllVdMcw+di6TNKcaNG2cCmN7WBhj6eR4+fNgMEdX99bb370kbX+hr6+et7cj1/etzlQ6V1LbmOs9LhwxqiNLz2AppAOBogW7rBwDllb925O3bt/e5/9y5c129evVyVahQwVWvXj13e2l9DW0HnV87cl/tuXW7tiDPrx25Hqs3/RneLaynT5/u6tKli2nZ3bx5c9f777/vuv/++12RkZH5fh5Wu21fF30ty9dff21+RkREhKtatWquq666yrV7927349o6W4+3TZs2ps22ts3u2bOnaY1tWbZsmWvkyJGuRo0amdfRNufnn3++a8mSJa6C0Pbj+vphYWGu2rVru2677TbTBt2XRx991LyHFi1a+H09/f0NGTLEHKt+Vvp+r732Wo/jya9du7fJkye7rr/+enOclSpVMr8TPYa77rrLtW/fPo99169f7+rXr585t/RY7b9X3Vc/z4YNG5r3W6dOHdfAgQNd7777rsfx6/O+/PJL1yOPPGI+T32tYcOGuXbs2OHeb+vWreaY9P3p+9Tf34ABA1zTpk0r8PsCgEAJ0v8JdHgDAJRd2qJcOwJ6z39B2ZqDN2DAANNwQjv2AUBZxBwnAECx0a5xdhqWdE7NWWedFbBjAgCgODDHCQBQbLTTnLaattY00vk72kzhwQcfDPShAQBwUghOAIBiow0TvvzyS7PYrK451Lt3b9MxznthVAAAShvmOAEAAABAPpjjBAAAAAD5IDgBAAAAQD7K3RynzMxMs6q9riCvC0gCAAAAKJ9cLpdZBF0X/w4OzrumVO6Ck4amhg0bBvowAAAAADjErl27pEGDBnnuU+6Ck1aarA8nOjo60IcjaWlpMmXKFBk8eLCEhYUF+nAAzkk4DucknIjzEk7DOVk08fHxpqhiZYS8lLvgZA3P09DklOAUFRVljoWTHE7AOQmn4ZyEE3Fewmk4J09OQabw0BwCAAAAAPJBcAIAAACAfBCcAAAAACAfBCcAAAAAyAfBCQAAAADyQXACAAAAgHwQnAAAAAAgHwQnAAAAAMgHwQkAAAAA8kFwAgAAAIB8EJwAAAAAIB8EJwAAAADIB8EJAAAAAPJBcAIAAACAfBCcAAAAACAfBCcAAAAAyEdofjvg1NkQd1w2xR2TvYmBPhIAAAAAeaHiFEDfL9std361UhYf4NcAAAAAOBnf2AMoOCjIXGcG+kAAAAAA5IngFEDBWblJXK5AHwkAAACAvBCcAigkOzlRcQIAAACcjeDkgKF6VJwAAAAAZyM4BRBznAAAAIDSgeAUQCHZnz4VJwAAAMDZCE4BFGRVnAhOAAAAgKMRnBzQHILcBAAAADgbwSmAQmgOAQAAAJQKBKcAys5NNIcAAAAAHI7g5IR1nKg4AQAAAI5GcHLCOk6BPhAAAAAAeSI4BVAwFScAAACgVCA4BRDNIQAAAIDSgeAUQNkFJ4bqAQAAAA5HcAoghuoBAAAApQPBKYBoDgEAAACUDgSnAArJ/vSpOAEAAADORnByQMWJ4AQAAAA4G8EpgBiqBwAAAJQOBKcACsluDuFyZbfXAwAAAOBIBCcHtCPPDPSBAAAAAMgTwckJQ/UYqwcAAAA4GsHJAUP1aA4BAAAAOBvBKYBoDgEAAACUDgSnAAqm4gQAAACUCgQnBzSHIDcBAAAAzkZwCqAQFsAFAAAASgWCkwOG6pGbAAAAAGdzTHAaN26cBAUFyT333JPnft9++620adNGIiMjpWPHjjJp0iQprWhHDgAAAJQOjghOixcvlnfeeUc6deqU537z5s2TkSNHyg033CDLly+XESNGmMuaNWukNArJ/vQZqgcAAAA4W8CDU0JCglx11VXy3nvvSdWqVfPc9/XXX5ehQ4fKAw88IG3btpWnn35aunbtKuPHj5fSSCtsitwEAAAAOFtooA/gjjvukGHDhsk555wjzzzzTJ77zp8/X+677z6PbUOGDJGffvrJ73NSUlLMxRIfH2+u09LSzCWQXBkZ7opToI8FsFjnIucknIJzEk7EeQmn4ZwsmsJ8XgENTl999ZUsW7bMDNUriLi4OKldu7bHNr2v2/0ZO3asjBkzJtf2KVOmSFRUlATSrgT931DJFJGpU6cG9FgAb5yTcBrOSTgR5yWchnOycJKSkpwfnHbt2iV33323+eVqo4dT5ZFHHvGoUmnFqWHDhjJ48GCJjo6WQFoXGy8vrV5gmkMMGjRIwsLCAno8gPWXF/3vknMSTsE5CSfivITTcE4WjTUazdHBaenSpbJ//34zR8mSkZEhs2fPNnOWdHhdSEiIx3Pq1Kkj+/bt89im93W7PxEREebiTU+oQJ9UEeFZPz/TIccD2HFOwmk4J+FEnJdwGs7JwinMZxWw5hADBw6U1atXy4oVK9yX7t27m0YRets7NKnevXvL9OnTPbZpstbtpRHtyAEAAIDSIWAVp8qVK0uHDh08tlWsWFGqV6/u3j5q1CipX7++maekdGhf//795eWXXzYNJXSO1JIlS+Tdd9+V0ojgBAAAAJQOAW9HnpedO3dKbGys+36fPn3kiy++MEGpc+fO8t1335mOet4BrLQIzspNZqgeAAAAAOcKeDtyu5kzZ+Z5X1122WXmUhaEZCcnKk4AAACAszm64lTWWUP1qDgBAAAAzkZwCqBgKk4AAABAqUBwCqAQKk4AAABAqUBwckBzCCpOAAAAgLMRnJwwVE+CxEV6AgAAAByL4OSAoXoqk9wEAAAAOBbByQFd9VQGyQkAAABwLIJTAAXbPn2G6gEAAADORXBySsWJ4AQAAAA4FsEpgEKstnrMcQIAAAAcjeDkkIpTJskJAAAAcCyCUwDZCk4M1QMAAAAcjOAUQAzVAwAAAEoHglMABTFUDwAAACgVCE4OqTplMlQPAAAAcCyCU4BZo/UoOAEAAADORXBySGe9DJITAAAA4FgEpwBjqB4AAADgfASnALP6QxCcAAAAAOciOAVYSHZyyswM9JEAAAAA8Ifg5JCheiyACwAAADgXwckpQ/VoDgEAAAA4FsHJKUP1yE0AAACAYxGcAsxqR05zCAAAAMC5CE4BFkw7cgAAAMDxCE4BFpI9x4kFcAEAAADnIjgFWBBznAAAAADHIzg5pB05Q/UAAAAA5yI4BVh2bmKoHgAAAOBgBCeHdNWj4AQAAAA4F8HJIUP1MkhOAAAAgGMRnJzSHIKhegAAAIBjEZwCLCT7N0BzCAAAAMC5CE4OmeOUQW4CAAAAHIvg5JDgxFA9AAAAwLkITg5pR85QPQAAAMC5CE5O6apHxQkAAABwLIJTgLGOEwAAAOB8BCeHDNVjHScAAADAuQhOARacnZxoDgEAAAA4F8HJKV31yE0AAACAYxGcAiw0u+KUnpkZ6EMBAAAA4AfBKcAiw0LMdXIawQkAAABwKoJTgEWGZv0KktMzAn0oAAAAAPwgOAVYBBUnAAAAwPEITgEWkV1xSiE4AQAAAI5FcAqwyDCG6gEAAABOR3AKsMjQrKF6KelUnAAAAACnIjgFWER2xSkljYoTAAAA4FQEpwCjHTkAAADgfASnAKMdOQAAAOB8BCeHtCOnqx4AAADgXAQnx1ScCE4AAACAUxGcHNIcIpnmEAAAAIBjEZwc0o6c5hAAAACAcxGcHFJxSqU5BAAAAOBYBCenVJyY4wQAAAA4FsEpwCLdc5wITgAAAIBTEZwcsgBuCkP1AAAAAMciOAVYRHY78rQMl2RkugJ9OAAAAAB8IDg5ZKieoiU5AAAA4EwEpwCLyG4OoQhOAAAAgDMRnAIsJDhIQoKyhujRWQ8AAABwJoKTA1ij9VKoOAEAAACORHByUHCiJTkAAADgTAENThMmTJBOnTpJdHS0ufTu3VsmT57sd/+JEydKUFCQxyUyMlLKTHCiJTkAAADgSKGB/OENGjSQcePGScuWLcXlcsnHH38sw4cPl+XLl0v79u19PkcD1oYNG9z3NTyVnYoTwQkAAABwooAGpwsuuMDj/rPPPmuqUAsWLPAbnDQo1alTR8rmHCeG6gEAAABOFNDgZJeRkSHffvutJCYmmiF7/iQkJEjjxo0lMzNTunbtKs8995zfkKVSUlLMxRIfH2+u09LSzCXQ9Bis4JSQnOqIY0L5Zp2DnItwCs5JOBHnJZyGc7JoCvN5Bbl0jFwArV692gSl5ORkqVSpknzxxRdy3nnn+dx3/vz5smnTJjMv6tixY/LSSy/J7NmzZe3atWbYny9PPvmkjBkzJtd2/TlRUVHiBG+tC5aNx4Ll6hYZ0qNmQH8dAAAAQLmRlJQkV155pckWOiXI0cEpNTVVdu7caQ72u+++k/fff19mzZol7dq1K1BCbNu2rYwcOVKefvrpAlecGjZsKAcPHsz3wykJ+h4ue3O6rD0SLM8ObyeXd/cdAIGSPCenTp0qgwYNkrCwsEAfDsA5CUfivITTcE4WjWaDGjVqFCg4BXyoXnh4uLRo0cLc7tatmyxevFhef/11eeedd/J9rp4UXbp0kc2bN/vdJyIiwlx8PdcpJ5U1VE+nODnlmAAn/TcCKM5JOBHnJZyGc7JwCvNZOW4dJ527ZK8Q5TcvSof61a1bV8pGO3KaQwAAAABOFNCK0yOPPCLnnnuuNGrUSI4fP27mHc2cOVP+/PNP8/ioUaOkfv36MnbsWHP/qaeekl69epkK1dGjR+XFF1+UHTt2yI033iilGe3IAQAAAGcLaHDav3+/CUexsbESExNjmj5oaNKxmUrnPgUH5xTFjhw5IjfddJPExcVJ1apVzdC+efPmFWg+VOkITlScAAAAACcKaHD64IMP8nxcq092r776qrmUNVScAAAAAGdz3Byn8igsKKuxYUo6wQkAAABwIoKTAzBUDwAAAHA2gpODghMVJwAAAMCZCE4OQMUJAAAAcDaCkwPQHAIAAABwNoKTAxCcAAAAAGcjODlAOEP1AAAAAEcjODlAWHBWO/JkmkMAAAAAjkRwcoBQq6seFScAAADAkQhODsAcJwAAAMDZCE6OWseJihMAAADgRAQnRzWHoOIEAAAAOBHByUEVp/RMl6RlUHUCAAAAnIbg5AAVQkVCgoPM7cOJqYE+HAAAAABeCE4OoJmpZqVwc3vv0ROBPhwAAAAAXghODlE3JtJcxx1LDvShAAAAAPBCcHKIOtFZwSmW4AQAAAA4DsHJYRWn2GMM1QMAAACchuDkEHXcwYmKEwAAAOA0BCeHqBMdYa4JTgAAAIDzEJwcolblrOB0MCEl0IcCAAAAwAvBySEiw0LMdXJaRqAPBQAAAIAXgpPjglNmoA8FAAAAgBeCk0NEhmX9Kqg4AQAAAM5DcHKIiNCsX0VKeqa4XK5AHw4AAAAAG4KTQ0SEZg3Vs8ITAAAAAOcgODlsqJ5KYZ4TAAAA4CgEJ4cICwmWkOAgczs5nXlOAAAAgJMQnBwkMnueEw0iAAAAAGchODlIBC3JAQAAAEciODkIFScAAADAmQhODlwEl656AAAAgLMQnBw5VI+KEwAAAOAkBCcHtiQnOAEAAADOQnBykAhrjhND9QAAAABHITg5cI4TFScAAADAWQhODhIZmt0cguAEAAAAOArByYFznOiqBwAAADgLwclBGKoHAAAAOBPByZHBiYoTAAAA4CQEJyd21aPiBAAAADgKwcmJC+CmE5wAAAAAJyE4OXIBXIbqAQAAAE5CcHJiO3K66gEAAACOQnBykArhWcHpRGp6oA8FAAAAgA3ByUGisoNTYgpznAAAAAAnITg5SKWIUHOdSMUJAAAAcBSCk4NUzA5OCSkEJwAAAMBJCE4OrDglMVQPAAAAcBSCkwMrTolUnAAAAABHITg5SEWrOURqurhcrkAfDgAAAIBsBCcHVpwyXSIn0hiuBwAAADgFwclh7ciDgrJu0yACAAAAcA6Ck4MEBQVJxXAaRAAAAABOQ3BymIoRWfOcqDgBAAAAzkFwchg66wEAAADOQ3By6FpO2lkPAAAAgDMQnBzYIEIlMMcJAAAAcAyCk0MrTkkM1QMAAAAcg+Dk0DlONIcAAAAAnIPg5DAEJwAAAMB5CE4OU6NShLk+cDwl0IcCAAAAIBvByWHqxkSa69hjyYE+FAAAAADZCE4ODU57j54I9KEAAAAAcEJwmjBhgnTq1Emio6PNpXfv3jJ58uQ8n/Ptt99KmzZtJDIyUjp27CiTJk2SsqRelQrmmooTAAAA4BwBDU4NGjSQcePGydKlS2XJkiVy9tlny/Dhw2Xt2rU+9583b56MHDlSbrjhBlm+fLmMGDHCXNasWSNlreJ07ESaJLEILgAAAOAIAQ1OF1xwgZx33nnSsmVLadWqlTz77LNSqVIlWbBggc/9X3/9dRk6dKg88MAD0rZtW3n66aela9euMn78eCkrKkeGSeXsznp7j1J1AgAAAJwg6xu6A2RkZJhheImJiWbIni/z58+X++67z2PbkCFD5KeffvL7uikpKeZiiY+PN9dpaWnmEmjWMdiPpU5MhBzfny67DiVI46pZXfaAQJ6TQCBxTsKJOC/hNJyTRVOYzyvgwWn16tUmKCUnJ5tq048//ijt2rXzuW9cXJzUrl3bY5ve1+3+jB07VsaMGZNr+5QpUyQqKkqcYurUqe7bwSlaCAyWaXMWSfxGV0CPC+WX/ZwEnIBzEk7EeQmn4ZwsnKSkpNITnFq3bi0rVqyQY8eOyXfffSejR4+WWbNm+Q1PhfXII494VKm04tSwYUMZPHiwaUjhhJSrJ/igQYMkLCzMbJuWuEo2rIqTBi3aynlnNAn0IaKc8XVOAoHEOQkn4ryE03BOFo01Gq1UBKfw8HBp0aKFud2tWzdZvHixmcv0zjvv5Nq3Tp06sm/fPo9tel+3+xMREWEu3vSEctJJZT+eGpWzGkQcTU531DGifHHafyMA5ySciPMSTsM5WTiF+awct45TZmamx5wkOx3SN336dI9tmqz9zYkqrWpUygp6hxNSA30oAAAAAAJdcdJhdOeee640atRIjh8/Ll988YXMnDlT/vzzT/P4qFGjpH79+maekrr77rulf//+8vLLL8uwYcPkq6++Mm3M3333XSlLqlUMN9eHEwlOAAAAgJT34LR//34TjmJjYyUmJsYshquhScdmqp07d0pwcE5RrE+fPiZc/fe//5X//Oc/po25dtTr0KGDlMXgdIjgBAAAADhCQIPTBx98kOfjWn3ydtlll5lLWVadihMAAADgKI6b4wSG6gEAAABOQ3ByoOoVs5pDJKSkS0p6RqAPBwAAACj3CE4OFF0hVEKDg8xtqk4AAABA4BGcHCgoKEiqV8oarnfwOMEJAAAACDSCk0PVyl4Ed//x5EAfCgAAAFDuEZwcqnZ01jynffG+FwMGAAAAUHIITg5VKzqr4rQvnooTAAAAUCqD065du2T37t3u+4sWLZJ77rlH3n333eI8tnKtNkP1AAAAgNIdnK688kr566+/zO24uDgZNGiQCU+PPvqoPPXUU8V9jOUSQ/UAAACAUh6c1qxZI6effrq5/c0330iHDh1k3rx58vnnn8vEiROL+xjLpdoM1QMAAABKd3BKS0uTiIisisi0adPkwgsvNLfbtGkjsbGxxXuE5VSt7IrT/uNUnAAAAIBSGZzat28vb7/9tvz9998ydepUGTp0qNm+d+9eqV69enEfY7lUs3JWcDqYkCKZma5AHw4AAABQrhUpOD3//PPyzjvvyFlnnSUjR46Uzp07m+2//PKLewgfTk50ZJi5drlEElPTA304AAAAQLkWWpQnaWA6ePCgxMfHS9WqVd3bb775ZomKiirO4yu3IkKDJSwkSNIyXJKQki6Vs4MUAAAAgFJScTpx4oSkpKS4Q9OOHTvktddekw0bNkitWrWK+xjLpaCgIHdYOp5MxQkAAAAodcFp+PDh8sknn5jbR48elZ49e8rLL78sI0aMkAkTJhT3MZZblSOzCoLHk9MCfSgAAABAuVak4LRs2TI588wzze3vvvtOateubapOGqbeeOON4j7GcqtShBWcqDgBAAAApS44JSUlSeXKlc3tKVOmyMUXXyzBwcHSq1cvE6BQ3BUnghMAAABQ6oJTixYt5KeffpJdu3bJn3/+KYMHDzbb9+/fL9HR0cV9jOVWpQjmOAEAAAClNjg9/vjj8n//93/SpEkT0368d+/e7upTly5divsYy63o7IpTQgpznAAAAIBS14780ksvlTPOOENiY2PdazipgQMHykUXXVScx1euMVQPAAAAKMXBSdWpU8dcdu/ebe43aNCAxW+LWSWCEwAAAFB6h+plZmbKU089JTExMdK4cWNzqVKlijz99NPmMRQP1nECAAAASnHF6dFHH5UPPvhAxo0bJ3379jXb5syZI08++aQkJyfLs88+W9zHWS6xjhMAAABQioPTxx9/LO+//75ceOGF7m2dOnWS+vXry+23305wKias4wQAAACU4qF6hw8fljZt2uTartv0MRSP6OyheocTUwN9KAAAAEC5VqTgpJ30xo8fn2u7btPKE4pH+/rREhwksmHfcdl1OCnQhwMAAACUW0UaqvfCCy/IsGHDZNq0ae41nObPn28WxJ00aVJxH2O5VatypPRuXl3mbj4kv6zcK3cMaBHoQwIAAADKpSJVnPr37y8bN240azYdPXrUXC6++GJZu3atfPrpp8V/lOXYuR3qmut5Ww4G+lAAAACAcqvI6zjVq1cvVxOIlStXmm577777bnEcG0Ska6Oq5nrVrmOSmemSYB27BwAAAMD5FSeUnFa1K0lkWLAcT0mXrQcTA304AAAAQLlEcHK40JBg6Vg/xtxeuetooA8HAAAAKJcITqVA18ZZw/X+3nQg0IcCAAAAlEuFmuOkDSDyok0iUPwGt6st78zaKtPX75e0jEwJCyHvAgAAAI4NTjExMfk+PmrUqJM9Jng5rWFVqVEpQg4mpMjSHUekV7PqgT4kAAAAoFwpVHD66KOPTt2RwK+Q4CDp1CBGZqzfL9sOJhKcAAAAgBLGmK9Son6VCuZ695GkQB8KAAAAUO4QnEqJBlWt4HQi0IcCAAAAlDsEp1KifnZw2kNwAgAAAEocwanUDdUjOAEAAAAljeBUSjSoGmWu9x1PluS0DJm2bp8kpKQH+rAAAACAcoHgVErUqBQulSJCxeUS6f/iX3LjJ0vk9WkbA31YAAAAQLlAcColgoKCZHSfxub2vvgUc/3e39sCfFQAAABA+UBwKkXuGNBCalWOcN+vHZ1zGwAAAMCpQ3AqRaLCQ+X72/pI27rR5v7BhFRJz8gM9GEBAAAAZR7BqZRpWC1Kfr/rDAkPDZaMTJfsPZoc6EMCAAAAyjyCUykUHBwkjaplddnbeTgp0IcDAAAAlHkEp1KK4AQAAACUnNAS/Fk4BcHpvb+3yrETaXJ59wZSvRLNIgAAAIBTgYpTKQ9O2w4myvN/rJer3l8Y6EMCAAAAyiyCUykPTpaN+47TYQ8AAAA4RQhOpVSj6p7BKdMlsu941sK4AAAAAIoXwamUaljVMzipPUdOBORYAAAAgLKO4FRKVQgPybVt71GCEwAAAHAqEJxKsVv6NZMGVSvIWa1rmvt7CE4AAADAKUFwKsUeOa+tzHnobOlUP8bcf/HPDXIsKS3QhwUAAACUOQSnMqBelQru22/M2GSuXS6XxB47YVqV74tPDuDRAQAAAKUfwakMGNqhjvv2om2H5fdVsdLj2enSe+wMmTBziwwfPzegxwcAAACUdgSnMqBKVLjMeWiAub16zzG544tlcjAhpzV5XHyyLNx6KIBHCAAAAJRuBKcyon6VClKzcoTfx6ev32+u18fFy11fLqcDHwAAAFAIBKcyIigoSHo3q+738bmbD8rq3cdk6Gt/y68r98qD360q0eMDAAAASrPQQB8Ais+YC9tL/1Y1pW5MpHw0b7tMXbfP/djavfFywfg57vub9h8315mZLvNY6zqVJTyUHA0AAAD4QnAqQ6pWDJdLujUwt5vWrChHk1Ll2j5N5d2/t8rKXUc99o2ODDPXH8/fLmN+XSejejeWp4Z3kLSMTAkOCpKQ4KCAvAcAAADAiSgxlFF1YyrIt7f2kWGd6sq/z26R63Gd47R0xxETmtQn83eYNaDOeH6GjPpwYQCOGAAAAHAuKk7lwNltasn9g1pJbHyyaVe+eX+CJKZmyCUT5nns9+faONkXn2IuhxJSpHol/80mAAAAgPIkoBWnsWPHSo8ePaRy5cpSq1YtGTFihGzYsCHP50ycONE0QrBfIiMjS+yYSyP9jO4a2FKeu6ijTLuvv9/9lu084r69as+xEjo6AAAAwPkCGpxmzZold9xxhyxYsECmTp0qaWlpMnjwYElMTMzzedHR0RIbG+u+7Nixo8SOuSzQBhJ5tSxX9jlR6RmZ8v7fW2XrgYQSOT4AAADAaQI6VO+PP/7IVU3SytPSpUulX79+eVZQ6tSpUwJHWDaNvbij/BMbL+vjjsuLf+ZU+A4cz1k0d97mQ3L3QJf5rL9ctFOe+f0fc9k+bliAjhoAAAAIHEfNcTp2LGt4WLVq1fLcLyEhQRo3biyZmZnStWtXee6556R9+/Y+901JSTEXS3x8vLnW6pZeAs06hpI8lpoVQ6Vmi2rSu2kVSUhOlQmztrkfe+OKTnL/d6tl0fbDMm1drJzVqqas25szbC/uSAJzn8q4QJyTQF44J+FEnJdwGs7JoinM5xXkcrlc4gAagi688EI5evSozJmTs96Qt/nz58umTZukU6dOJmi99NJLMnv2bFm7dq00aJDVitvuySeflDFjxuTa/sUXX0hUVFSxv4/S6O75Ofn5tV7p8uOOYJkVGyxdq2fKRU0y5eutwbLmSNaozpHNM6RXLUecMgAAAMBJSUpKkiuvvNLkCp0OVCqC02233SaTJ082oclXAMorJbZt21ZGjhwpTz/9dIEqTg0bNpSDBw/m++GUBD1+nd81aNAgCQvLWluppLV8bIq51gVw1z5xjszaeEBu/HS51IuJNOs6HUhIde/bqUG0fHdzTzOED2WTE85JwI5zEk7EeQmn4ZwsGs0GNWrUKFBwcsRQvTvvvFN+++03UzkqTGhSemJ06dJFNm/e7PPxiIgIc/H1PCedVIE8npcv6yzPTvpH3h/d3RxDp0ZZQyX3HkvOte+q3fGyam+CdG+S93BKlH5O+28E4JyEE3Fewmk4JwunMJ9VQLvqabFLQ9OPP/4oM2bMkKZNmxb6NTIyMmT16tVSt27dU3KM5cEl3RrIsscGSddGVc39WpUjpUpU7pOoc4MYcz1l3b4SP0YAAAAgkAIanLQV+WeffWbmG+laTnFxceZy4sQJ9z6jRo2SRx55xH3/qaeekilTpsjWrVtl2bJlcvXVV5t25DfeeGOA3kXZ1C07RNld0aORuf5700H3tndmbZH+L/4l6/ZmNd0AAAAAyqKABqcJEyaY8YRnnXWWqRhZl6+//tq9z86dO81aTZYjR47ITTfdZOY1nXfeeWZc4rx586Rdu3YBehdl04ND28it/ZvLvee0cm8b3L62udZW5lbr8rGT18uOQ0ky4q25Zr0nAAAAoCwK6ByngvSlmDlzpsf9V1991VxwarWuU1kePreNpKZnyoZ98WYYX41KEdK2brQJTg99v0r6tqjh3j81I1O+X7Zbvlq8S0b3biIjutQP6PEDAAAAxckRzSHgXNpp739XdXPfP7NlDROcZqzfby52D32/2lwv37lCGlStQAMJAAAAlBkBHaqH0ucMW5UpL3+siTPXMzfsl33xWd35vl2ySybOzVpsNyPTJceSWKANAAAApQPBCYVyetNqUjcm0qzx9PbVXU0F6vHzc88v27g/QeZsOijXfrTYzH9KSc+QB75bJU/+uk62H0yUl6ZskNOeniJLdxwOyPsAAAAACoOheiiUyLAQ+fPefuZ2dGSYDO1QV5JS0+Wd2VtkX3yKdGoQI6t2H5PZGw+Yi4o9lix/2Yb1bdx3XCbM3GJuvzp1k3x2Y0/3nLfE1AypFMFpCQAAAGfhGyoKTQOTXVR4qMx6YICcSM2Q4KAg6fzUlFzPeeuvrKCkptrWgdIgpoFpwdbD8uPy3fLDsj3y4+19pWP2mlEAAACAEzBUD8VCA1DViuES42PhXLV6zzH37W+X7nbfjos/IZNWx8nI9xbIN0t2S3qmS/43c3OJHDMAAABQUAQnFLtRvRvn6sznz7YDifLt0l0e28JCOC0BAADgLHxDRbF7angH2fjMufLGyC7yxU09ZVDbrIVzLe3rRcszIzpIUJCYOU3pGZ7recUnZ3XbW7bziFw/cbFsOZBQoscPAAAAeGOOE04JrTJd2LmeuX0wIVV+Xx1rbo+5sL2M7tPE3P5wzjbZejBR5mw+6PHcnYeTzPWV7y2Q5LRM2Xv0hPxxT1ZDCgAAACAQqDjhlBvQuqaEZw+/qxMT6d4+sG0tn/vvPnxCMjNdJjSp9XHHS+hIAQAAAN8ITjjlKkeGyfVnNJWWtSpJz6bV3NvP75RVkbKMu7ijuU7NyJS47EVzAQAAACcgOKFEPHxuG5l6X3+pEhXu3qZrPtWoFOG+P6JLfWlao6K5ve1gYkCOEwAAAPCF4ISACQoKkitPb+jR0rxFrUrm9vKdRzz2/XT+9hI/PgAAAMBCcwgE1O0DWsihxFTp0qiqua/D+XSB3L83eTaMeOzntdK1cVVxuUTa1KksoT5alutCuh/N3S4ta1eSM1vWLLH3AAAAgLKP4ISA0irTsxdlzW1SrWpXNtcLtx3Ote+wN+aY62v7NJEnL2yf6/FVu4/JU7+tk/pVKsjdA1vK+3O2ynujukvj6lnD/wAAAICiYqgeHMUaqmdpWK2CdKgf7bHty0U75WhSaq7nrtpzzFzvP54sD36/SjbuS5BHf1xzio8YAAAA5QHBCY6iw+yqV8xpIHFp14YyfmRX9/3gIJGU9Ez5ZskueeDblTJh5hb3Y+v2xpvrNNuCuv/EZm0DAAAATgZD9eAoEaEh8vq/ushNnyyR9vWi5dazmpltH4zuLhUjQmXjvuPy+M9r5blJ693PqRsTKe/O3uqzhbnOnwIAAABOFsEJjnNGyxqy4D8DpXJEqARricksllvb3TxizK/rJCMzp6p0z9cr8ny9pNR0iQrnVAcAAEDRMVQPjhRTIcwdmuyqV4qQM1vWKNRrbdqXUIxHBgAAgPKI4IRSZ8Rp9Qu1//ZDLKYLAACAk0NwQqkzqF1tiY4s+NC7HYeSZNbGA3L2yzNlyfbcbc7V5v0JEnvsRDEeJQAAAMoSghNKHW0S8e2tfeS1K04zQ/r6NK+eb3Aa/eEi2XogUS59e77M3XxQVu0+KgcTUszjhxNT5fw3/5beY2dIQkp6Cb0LAAAAlCYEJ5RKretUlhFd6svyxwbJFzf1kl7NqpntwzrWzbXv98t2e9y/6v2FcuH4uXL7Z8vM/a0HEiQ5LdPc/nT+jhI5fgAAAJQuBCeUalYDifdGdZe5D58t3RpXdT/WqUFMns9dtP2wGaI3c8MB97ZfVu49hUcLAACA0ooezSgTKkeGmUujalHubVee3khW7V6d5/POeWWWx/0t+xMkLSNTwkL4mwIAAAByEJxQppzdppZMvK6HNK1RURpXryi1oyPluomLC/z81IxMWbTtsPRtUUP2xydLhsslU9ftM0MAtRU6AAAAyieCE8rc0L2zWtdy3x/QppZpIHHsRFqBX0PnQD13UUf5z4851aopa/fJZzf2LPbjBQAAQOnAeCSUeRGhhT/N7aFJzdl8sBiPCAAAAKUNwQllnvd8peoVw+Wus1tI27rRHttv7teshI8MAAAApQVD9VDmhYZkdd5TX9/cS05vWk2CgoLkmt6N5afle+S3VbFyKCFV7hvUSq7u2VgGvDxTMjJdBXptXQPq0gnzZFD72vLIuW1P4bsAAABAIFFxQpkXmt2yXPVsVt2EJlWrcqTc3K+5/HR7X5n5wFkSGRYijapHudeE8paYki4j310gL0/Z4N42ce422XowUd6ZtbUE3gkAAAACheCEMq9pjUr5NpSwD+d7/pJOUi8mMtd+v67cK/O3HpI3Z2yWE6kZZtueo8nux5PTsrYBAACg7CE4ocx7ekR76deqpnx0XY8C7d+gapRMv/8s6dnUs/L08A85DSN6j5tuFs+NPXbCvS32WFaI2nU4ybQyBwAAQNnBHCeUeXVjKsgn159eqOdUCA+RqPAQv48fTUqTD+duk7V7493bdh9JkuqVwmXoa7MlKS1D/nlqqBn+BwAAgNKPihNQRAu2HvJYH2r3kROy81CSJKZmiMslZuFcAAAAlA0EJ8CP0X2a5Nr25AXt5M4BLcztrQcSPR7bEHdcDiSkuO//sGx3CRwlAAAASgLBCfCjf6uaMuXefu77YSFBcm3fpnJZ9wY+9584b7v8smKv+759GJ8/B46nyFt/bZb9x5kTBQAA4GQEJ8APbVveqnZl9/2YCuHmul6VChJia3F+TtvaUikia7rgj8v3uLfvP55iWpgfSUyVuOzGEbpu1MCXZ8qibYfN/Xu+Xi4v/rlB7v5yRYm9LwAAABQewQkooCpRYeZaW5fXq5LTrrxP8+ry2hWn+XzOtoOJ0uPZadJr7HTZF58s4//aLFsOJMrl78yXY0lpMnfzIbOftjkvCm2BvudoTmc/AAAAnBoEJyAf9w1qZRbR1fWdLK1q5VSimtSIkq6Nq/p87q+r9kp6psvc7vlcVgtzy9KdWVWnk3Hlewuk77gZ8k9s/sMCAQAAUHQEJyAf/x7YUtaMGSLdbOHooXPbSPWK4RIeEizt68VItYrh0qxmRY/5UOqdWVv9vu5e2+K5RbVs51Fz/d1SGlEAAACcSgQnoAC812PSuU9/PXCWTL+/v9SOzhq2N6xjXffjfVvUyPc1tx/07MqXnpFphvad9/rf8svKnCYTBZGUmlGo/QEAAFA4BCegiKIjw6RhtSj3/Wt6NfYY3tfa1ljClyU7jnjcP5iQKo//vEbWxcbLv79c7vGYy+WSaev2yYSZW0zAUpnZQwDVidR0OZiQIq9P2ySxx5jzBAAAUNyyWoEBOGm1oiPlg9HdTTe9Tg2qyHujuku/F//yu/+KXUe97h/x2ehBu/Ld8tlSdyc+HRI4pH0dSUhN96g43fLpUlm644gs33VEJl53erG+NwAAgPKO4AQUo4Fta7tvN6xWoVDPvfWzZT63v/v3VndoUit3HTXBKf5EmnvbkaRUE5rUrI0HinDkAAAAyAtD9YBTuA7UyNMb5btf54ZVfG5PSc+atzRlbZy57tWsmrleveeYuY4/kVNx2nYwyX27Za1KJ3nkAAAA8EZwAk6hsRd3lDdHdvHYpovnakc+Vb9KBfnu1t7yyuWdcz33we9WyardR826T9ql766zW7qH+Omcp/jknIqTzm+yVMxejBcAAADFh29YwCkWEZrz9wmtGj0wpLXpxLd69zFTbdIFdQe3r6OD8Dye9/OKveaiTmtYRbo3qSrhocFyPDldnvxlrd/OfcdsQ/gAAABQPAhOwCnWsUGM+/ZXN/d2325QNacjX6WIUOnRpKos3u7Zac/Suk5liQgNkUfPaytP/rpWPp6/Q2ZvOuhz32NJ/oNTWkamWcxXhxECAACg4BiqB5xidWMqyNR7+8mi/wzMc7/Hzm8n/vKMrhulRvdpIrf0a25u65pP/ipOOpTPmy6S2+WpqXLNB4skMSVnfhQAAADyR3ACSkDL2pVNu/K8aAvzvx8cIIPb5XTm8w5O6t5BLaV/q5ru+5d1ayCXd28g9w9qZe6nZ7okMTVDFmw9JNd9tEj+Wr/ftDR/5IdVkpCSLnM2H5SXp2ws1vcHAABQ1hGcAAfR4XsvXtpZXri0k3xy/ek+g5MO2Xv1itPc97VK9cKlneXOs1tIeEjWf9Ib4o7Lv95dIH9tOCAfzt0mWw4kSFpGThVq8fac9uYAAADIH3OcAIeJiQqTy7s3NPORtLJUrWK4udjZ7x9KSDXXOm9Jn3vgeIos3HbI/fjfmw6ai9XFTxfZ1ZbmZ788Ux4/v500r1lJGlbLmW8FAACA3AhOgENpt72PbVUnb2MubC8vTdkgtw9o4d4WUyErOG3el+DzOf1a1ZSvF++UTJfI1gOJcu1Hi832bo2rmqF+ffx06gMAACjvGKoHlFLaKGLVE4NN6LFEhmX9J/3D8j0+n9OiViUTmrwt3XFE7vvGsx26NaTv/b+3+mw2AQAAUJ4QnIBSzLuteIMqeQ+5qxsT6RG07NIzM3Ntu+zt+fLM7//ItH/2+33Nqev2yR2fL8vVBj09I9M0owAAACgLCE5AGXJvdmc9XypHhsrpTavJa1ecJjf3a2bWhNKFde2NKbSV+e1frJDJu4JN8LHsOpzk93XfmL5Jfl8dKzM3eoary9+ZL52e/FPG/Lr2pN8XAABAoBGcgDJEF8r998CWPh+b89DZUqNShGkE8Z/z2spN/ZrJT3f0lVv6NzOPr9h1VDqPmSJT/9kvf+wOlt1HT7ifGxbq+5+KzEyXbN6fNZ9KQ5clOS1Dlu08aoYFfjR3O0P9AABAqUdwAsqYZjUq+tyujSN8Gd65vs/tczYf8qg4paRn5Npn77ETciIta3t8dnA6nJgq++NTPPaz9gEAACit6KoHlDHNalYs0DZLdAXf/wzMWH/Affvd2VtlzqaD8sPtfSQyLMSsCxUcFCQ7DiW699GK0x9r4uTWz5bKWa1zFui1HosK558bAABQelFxAsqYxtVzQtKPt/eRi7rUl/dHdfe7v3clalDbWub6b1vFSa2LjTfzmZJS02Xgy7NkwEszZfXuY+7H40+ky11fLjO3Z27ICV3qqFfjCAAAgNKGPwEDZYwGofFXdjHzi7o0qmoueanoVQnq3CDGzHPy5cfle+S8jnXd979avMujqpSW4Xsuk33+EwAAQGlEcALKoPM71SvwvsHBni3NT2sY43ff2GPJMnlNrPv+HlsDifhk/+GIihMAACjtGKoHwEPPptXk5jYZ8q8eDeSFSzvlenzCzC0+n7fjkP+W5f/ExpsOfL6cSM0wFwAAACcLaHAaO3as9OjRQypXriy1atWSESNGyIYNG/J93rfffitt2rSRyMhI6dixo0yaNKlEjhco60Kzq0/tq7rk6QvbSe9m1d2PXdK1gbn2k388qk8Wq5j1+vRN8vbs3IErI9MlQ16bbeZLpdnWjQIAAHCagAanWbNmyR133CELFiyQqVOnSlpamgwePFgSE3M6dXmbN2+ejBw5Um644QZZvny5CVt6WbNmTYkeO1AWhXut11S1Yrj79m1nNTPznwqjec1K7tsv/JHzR5HlO4/I8LfmyqTVsbLzcJLExSfL7iO5gxcAAIBTBDQ4/fHHH3LttddK+/btpXPnzjJx4kTZuXOnLF261O9zXn/9dRk6dKg88MAD0rZtW3n66aela9euMn78+BI9dqAsqhqVE5RUpYhQubx7Azm/U10TgsZf2VUaV4+SiNBg6d8qq+V4eIj/f0aaeK0pdTAha32ni/43T1buOip3fbnc/dgeH8FJF9Kdt+Wgz2pUekamvPTnBvlmyS7ZEHdcxk1en+c8KwAAgDLTHOLYsazWxtWqVfO7z/z58+W+++7z2DZkyBD56aeffO6fkpJiLpb4+HhzrdUtvQSadQxOOBaUXy9c3EHG/blBXr2sY65z8tnh7cx1enq61KkcJr/f2UcSU9KlQliIvDdnmwxsU0tGTFjg83XrRkd43P97wz6PKpTdtgPHpWeTrIrWj8v3SmRYsMzedEi+W7ZHbu/fTO49p4XH/m/M2Czj/9rqse1IYrI8M7y9uX0oMVWW7zwqZ7eumasBBkoX/p2EE3Fewmk4J4umMJ9XkMvl8jNjoWRlZmbKhRdeKEePHpU5c+b43S88PFw+/vhjM1zP8r///U/GjBkj+/bty7X/k08+aR7z9sUXX0hUVFQxvgOgdNN/CYKKmC/uXxAi6a7cTz6zTqb8HZdTkaoR4ZKwEJHYpNz7nlMvUy5onCnxqSKPLc39N53Xe6e7b+s+Ty4LkQyvn1kr0iWPdslqNPHK6hDZkRAkFzfJkP51HfHPHAAAcJikpCS58sorTQEnOjq6dFScdK6TzlPKKzQVxSOPPOJRodKKU8OGDc1cqvw+nJJKuTq/a9CgQRIW5rkQKVBazsk3Ns+VLQdyz028bkh3+fvjrEVx1cEU/8lsW1pl+fFQhawFeJeuy/X4l3E1ZcO+BLnpzCayMS5BMlw5bdEtkVFRct55Z5rbd8+fYq4XH6skz9+QtQ2lE/9Owok4L+E0nJNFY41GKwhHBKc777xTfvvtN5k9e7Y0aJDVucufOnXq5Kos6X3d7ktERIS5eNMTykknldOOByjMOXlRl/ry0pSNubYPaFNHPr+xpxme13vcdFPVUlWjwqRelQqydm/OP1YavPQyc+NBnz9jwbYj5vqFPze5t912VnOP9uj68t7HrGtP8d9W2cC/k3Aizks4Dedk4RTmswpocwgdJaih6ccff5QZM2ZI06ZN831O7969Zfr06R7bNF3rdgCBcXWvxlInOlLa1KnssT0oKEj6tqghdWIi5X9XdpVrejWWFy/tJJ9c31NOb+p/LmNB15vS4GSX6aOjebq//ukAAACFEBro4Xk61+jnn382aznFxcWZ7TExMVKhQgVze9SoUVK/fn2z5pO6++67pX///vLyyy/LsGHD5KuvvpIlS5bIu+++G8i3ApRrVaLCZdr9/SUsJEha//cPn/uc27GuuViOJKXKR3O3F/ln3nBGU4mO9Pwr0bETabL9YKJc8+FCj+0JKemmQyAAAEBRBbTiNGHCBDMR66yzzpK6deu6L19//bV7H21PHhubM5ehT58+JmxpUNIW5t99953pqNehQ4cAvQsASoNJRGhIgfc/2YpT9Uq5h+BqQLr3mxWy67Bna/NfVuzN9/X2xSebhXj/N3OzHEpIkTV7srp8AgAAqID+CbYgDf1mzpyZa9tll11mLgCcKzSfFuCRYSHy/CUdZemOI3L3Oa3kPz+sllkbD/jct2J4iEy8/nS5/qPFcjwlq7teddvivHbagtzb83+sl8u6N5CwPNacemP6Jtl2MNEs1PvOrK2mejXtvn7Sopbn8EMAAFA+MXYFwCmRV0ixXNGjkbmoj68/XfbHJ8vMDQekZe1KJuws2HpY2tWNlh/v6GOqWRXCQ3KCUyXfwclbVHiICUEailrVzgpBm/Ydl/DQYGlcvaKkpGdI/Il0OZyY6n6O7q+W7ThKcAIAAIEfqgeg7Ll7YEtz/dzFhR8+Wys6Ui7v0VC6NKoq7etlLYZbo3KEewigvUZtzVn677C25vq8jrk7a+oivRq81OBXZ8vk1bGy/3iyDHp1tvR/caZ8vnCH3DBxifQZN12W7czq2me343Ci9Bk7Xd6dndO5z+7rxTvlsZ/WSCYNKAAAKPMITgCK1T3ntJTFj54jF3XJe2mB/AxsW0t0tJ92z7PYR/dqxz6rScTUe/vJmyO7yqPnZYUouzZ1cypGt32+TBZuPey+/+iPa2TO5oOSluGSffEpuZ771l9bZO+xZHlu0npzPyk1XRKzK14alh76frV8umCHzN3iu4U6AAAoOxiqB6BYaaCpWTl344bC6tO8hqwZM0SiwkPznBepP69l9hC8kT0byV8b9su8LYfM/fTMTGlSvaLH/joEsCjSMjJl0CuzJdPlktkPDpC4Y8nux44mZQ3tAwAAZRcVJwCOZQ9NKr8BcTp874ubernvayWpV7PqHvvsPuLZca+g1scelz1HT5gFdXccSpL1ccfdj+0/nrtaBQAAyhaCE4BSY1j2OlDeC+3mpUP9GPn8xp5mOF/3xlVzPa7bhrbPPT/K2wXj57hv7ziUKBv35QSn2KOFD2PHk9PknFdmyQPfrpSi2nU4Sd6etcW0YQcAAKcWQ/UAlBoPn9tGWtepLIPb1S7U8/q2qGGuv7q5lyzefkTe+3urzFi/32z78uZekpSaIXuPnZBVuwu2dpN26LNXnLQKlR8dZmjNy1J/rImTzfsTzOW5izsWqAuhtyvfX2DWrNJFf8dd0qnQzwcAAAVHxQlAqVExIlSu7tXYdN8ritCQYOndvLpc0aOhe5sGlpgKYfLLnWdIdGTB/pa09WCiLNyaNY9Kaej6c22c9B03QxZty2k+Ybnx48Uy7I05kpqe6d52ICHFI4jlF7q2HEiQDK/ufdZCv7+vylkkHAAAnBoEJwDljlasdPHdP+4502P7RV3qF+j5f66J85jXFHs0WW75dKmZA3XdR4vk5Skb5KtFO81j8clpMu2f/bIuNl422KpUG2237dt9+WHZHhn48ix59MfVPh/Xta3mbT7oXqPqlSkbJDkto0DvBQAAFAzBCUCZ8+413aRieIi8fXVXn4/rkDldeLdNnaw1niwPDm1jApXOibK0ql3JXPdoUtU9RPBQ9mK5HetnrTW173jOUL3E1Ax5c8ZmefiH1aZluQ6js+w6kuRe82nDvgT3dvt8KV9embrRXH+1eJfffa58f6EcTUo1a1S9MWOzTJy3Pc/XBAAAhcMcJwBlzuD2dWT1k0MkWBeCKuRQQA1Ue23NHu45p5UJT81rVjLd9Kas2+ex1lR0hVCZuzln2J7dkaRU2X4oyX3/9s+XyfDT6skrl58mW/bnBKfF23MP7zucmCr3f7NC4uJTcg3R8+fH5Xvct1ftPlqg5wAAgIKh4gSgTCpsaLKLrhDmvl2rcoS0qFXZVKmqVQr32K9GpQj599kt/b6ODt2zV5zUzyv2yq2fLZXUjKz5TtovYsHWw+6hdkqD0n9/Wi1/bTgg/8TGS1x8TkXrhT/Wm7lSvta0+mbJbvftvUfzb1gBAAAKjooTAHjRYX6WVrbW55UjQiUsJMisD6WqVwyXVtmL7/py4fi5PrdPza5a6ULBZ7euJV8v2WUqWYeTUs16Uf+buVn8FZn+N3OLuVzXt0muxzRk2Yf/6bBADZD6875fulvGXtzRNKW44/NlctfAlnJh53oF+TgAAADBCQBy0+rS4kfPkbSMTImODPPYXjUq3N0YonqlCKkSlfN4YdWO1mpW1hyqnYeTCjUv6aO5ee+rLdZ1TlWtypFy0ydLzLYmNSqKS1yyaX+C/LBsN8EJAIBCYKgeAPig1aB6VSrk2l6tYrjHbQ1TWoUqqNvOau6+raGmavbr6aK6RaFVr2v7eFaftL266v/iTGn7+B/u7Ut3HJZlO46Y2/vjc7oCAgCA/BGcAKAQKtvWeqqRPecpMixnaN+ZLWvIZd0auO9/c0tvWfifgea2Trvq2qiqx/ypahXD3BUnb5Ui8h8UoCFJQ55FQ9yA1jV97quL/+pF7bd1AgQAAPkjOAFAEVnD+KJsc6I+vaGnNKga5b6vQ/FqR0fKlHv7yfxHBkqDqhU8glOVqKzwZc2bslzVs5HcP7hV/sdQIcxUnSwNq0VJ+3pZbdLtKtjCnTqYkGqGInrbF5/ss/o1bd0+WR+XM4fqZB1LSpOP5m6Tg7aFgAEAcDKCEwAUgr2ZndW57189Gpnrzg2yAktCSlquoX3aREIDVH1bcNL259Wyg5O3YR3rSp3oyHyPR7vyaXc/S4d6MdLa1tBCDWlfWwa0yV2Fuv+blaZDn3b+O5GatWBuz+emmyF+uiaUvenEjZ8skaGv/S1/bdgvt3y65KQDz5hf18qYX9fJDR9nzb8CAMDpaA4BAIXgq9ndHQNaSLOaFaVvixrm/vDT6st7f2+Tro2q5NrX3mwiPdPlnuPkTYffhYd6/m0rPCRY3ryyi/k5HZ7402zbtC9BqtvapF/bt4lHVeuFSzvJkPZ15LMFO2TS6jiP1/tl5V73dYf60fLtLX082qZ/PH+7PHFBe3eoUtd9tNhca1h79qKOUlRT/8nqLLhyF+tNAQBKBypOAFAI9mFxFg04Gpasyk+H+jEy8//Oks9v7OXzNQa3qy0RocFyUZf6Eh0ZKiE+1pzS17LPXWpULUrWjBliQpDOfXpjZBdTbXpgSGszNK93s+pyda9GZg6VNp14cGhr+b/BreTy7g3NPCg9Jl+s8LRmT7xZsNfyxC9rZeuBRBn94SJJz/Q1pC/FtDgvyEK7x06kyduztngsLOyvmpaclhPSCmLeloOyad/xQj0HAICioOIEAIXw2PntJPZYstxwRtM899PW3/5MuLqbJKamu6tPVaPCzJwjOw07On+pW+OqsnTHETmjZQ2PCpS2EtcmEJWzX+PLmz1D2u1ntfC439FPcLI7mpRW4O0Ltx6SadlVo+3jhpkFebXDoC+P/rhaflsVK3+siZOf7uhrttWJiTRt0VViSroZtvjj8t1m+OCrV5xmgmhe4pPTZOykf+TLRbtMhW3OQ2dLebD7SJKs2XPMBGh/nzcA4NQgOAFAIWjzhV/vOuOkXkMrTPYhe7o2lHdwsuZPfX9bHzNUroKtAYXFCk0FoXOt9LV0uJ8Gntenb8q1j79Oe746/h1PSXff/u9Pq2Xy6jj57rY+0tRHYNTQpFbsOipvTN9k1pgKC8kJgYu2H5YBrWvJvV+vNPfv/mpFvsHp3q9WyPT1+83t3UdOSEamy2fl7mRoGNR5WG3qVJZ/nd5Ivl68UxZsPWyGP9qPvySd/dIsSc3IlLeu7CrDOtU9qQD27ZLdMqp3Y7MeGQAgfwzVA4AA0+Bk9/Tw9h73fYWmotDqVccGMWYtqW9v7Z1r/altB32vJTV388E8X/ezBTvlUGKqvOkjjC3fmdX+3PLK1I1m2J42pLDPm9pz9IRUtL3PzEyX7DqcJFe/v1D+WJtV2bLb6nWsuu+k1bEmQBWXOZsPmkWJH/5htbn/0Per5cfle8wQxUDR0KT+3nTgpF7nyvcWmvB87zdZYRUAkD+CEwAEmA5bsw8FvKa354K2xU3XnerRpJrHz1XLdvqer7R2b8HakP+wfI/8sCwnVGhb84v+N8/nvjrc0Ttg2Rcc7vL0VHlpygYTXu76aqVs95rGdDzZc/jgWS/NlNs/Xya/Zs/ZKg6HE1M9qk+WHT4qcKWNVUU82QAGAOUJwQkAAqxdvWifC+yearUrewan/ELHiNPq5Xt8932z0qzRlN/rnchuAtGketaaV0/9us4958lqKKGd/SzfbgvxqCbFJ2cNFQz1Gp43a6NnEPh43nb595fLcwUtrWjlJ9MWlhJsQxO9X6ukFGc1zVd7fQBA3ghOABBg7W3BSbvslRRdVyovt/Rr5jFvaGiHujL7gQE+j9uu81NT5P2/t8rvXu3PfenUIKtl+/7j/teFqhAWLLsTg+TDedvN/ZT0DLP+lNVt0M57lpN2B9TOgR2fnCJ3f7XcbLvzi2WmQqUd+bo9PVW+XbLL5889kZrp0UXQEn8iJ0TlRatU2sjBOtaTFX8izWeoAwCUDIITAARYu7o5AaQkO6XZ2537clrDKtKrWTX3fe3+p93+LNoC3X7f7pnf/zEL56pHzm3j92d0yl402B9dC+vR87Ke/8rUzTJj/T45nl1tUvYFhb2HAFqVL4tWsLTRhjar0KFqOs9H52Y98N0qnz9bq14Weyt1e9t2lZ6RKc9N+kemZ3cZtHy+cKec/+YcefgH369fWPafa/8MAAAlg+AEAAFm72pW3zbPJ9AVJ22prt3uLLpYr9XtT3VtXNWEq7xoA4qbzmyWb8XJrl+rmh7dAC/vVl961Mg0CwZfP3GJ3Pv1CvOYrmdlrZ1liYvPCU47DududqFVpoI6eiLVZ3Cy31bfLd0t787eKjd8vMRj+/gZm831D8v2SHE4YguC3uENAHDq0Y4cABzgj3vOlO0Hk/wuVHsq1I7Ou+LUpHpF03Zbq0eqSnZ16b1R3c0QtHM71DH3F28/bFqMWwsEaxXHoovx2sOWt9Z1KkvzmhVly4GckFO/Sk6gqxIVbqpwlzXLlMUHs/7W9/emrPCj862qRHlWvDTU6BA5nZO0/VBWAwRtka6BVBtN6FpS3hpW8x1W7RWrvbZK1t6jyR7rVq3ac8zn86Miiqcbovt4bEHO35pbAIBTh4oTADhAmzrRMjQ7iJQUrSB503WeVItalUwbdA011/ZpIlf3auQe2jeoXW25d1ArExzO61hX1j011KwR9cbILrL0sUHyxAXt3K9XKzuc6fOV91pLlSNCZfLd/cy1RRf+tVeclGYQ78YUuhaWdbyWlPRMmb3poHQeM8U0hVBdGlYxx+yreYRK8DPszR5O7FUmbWyh86Z6j50uczYdlCO2oKjD9iwVw3OOV4OWznXSduzLvFq0W3Re2M2fLDFzuHw5kpjms+OfL+/N3iqjPlwkydlNOAAAJ4+KEwCUUxVtX+xXPznYLKir3eZ0/kxEWFYg0XD05IWe60r5WyNKL1alylInezjgExe0l6t7NZbvluyW9+dsM9uiwkNMNSo8OEiqVQp3L6prnzdlX+OqZqUIj7k9GqSs7nr2apcGEHsDukbVo6Rudut1X00ojp5I81hA92BCilm7Sq/9Dc/TRXrVDR8vls624Yb6WtbwwQphIR5BR9eveu/vbWYR4O3jhuU6Dquy9+vKWLm0W4Ncj9uH5+n7/GDONjMHrX293FXKZydlvdb3y3bLVT0bm9v2KhkAoPCoOAFAOdWlURXp3LCKnNexjglNSoNMTFSYWeupqBpntxi3z6PSIX9aVbN+joqyBbeKttv24FStYs7tWpU9K2QVI0KlaY2oXD/XGspnb0CRVyMMbVA3f8sh932tCmkwWrLjiN/gZK9wbT+UM8zwaHa4WbHrqKzac9RjeJ/OhfLH3nkv7tiJfCtgGvSe/m2dDHtjjuTFanDxzqwt0v2ZabLZ1vIdAFA4BCcAKKc0zPx8R1/531XdivV1G1TNCTPeQ/Mq2YbbVbTNARrVO6sqcnqTah7BSec42edLeYeNUb2byK39m8t3t/aWLo2yKl6W/w5rK1/c1NM0uPBuIuHt6g8Wmrla6pvFuduTa/Dxx17F0vbnm/YdlxFvzZXktJwwtPnAcY/mDt5rMtmrW/Zufv6aVRSUtV7V2MnrTZVq3OSsSlRx0ArWR3O3uT83ACjrCE4AgGIVHprzfy3eA8Psc5nsFafLuzeUL27sKe+N7u5VccoJTt6NILQBhFbGHj63jXRvUk262oKT5rUrezaSPs1rmOFp/ipO9nlT32dXhHR+l7dU29ylvMzdfEgGvTo71/bfV8X5DUoaQJbaqltWUwtvxwq4fpR9jpR2IrTzvm9/zh9rYv2GNl9W7zkmY35dJw/6aecOAGUNwQkAUOxu6d/MrPt0bd8m/itO4TkVJx0i2KdFDROa/M1x8paYPSfKPvTQ0rNpdY9gpgHLHtqsKpcOtbP8sTbONG6wdwUsLtO81njSOVSWLxbtlLuyG1moHdlD/3R44K8r95pgpY4nFyzUJKXkBKe4Y8keDSL8zXB6ZcpGufWzZXLrp0sL+I5yFgXW4/XX0AIAyhKaQwAAit0j57aVh4a0ydWKXNdesjSrmdNEwnvukq+Kk7e6trblql6VCqZ736GEVBl7ccdc+9eoHOFuQPHcRR1NReqT+Ts85hBd/L957vsz7u8v87Yckv/+tEaK233frDTDGIefVl+e+Hmtx2M7DiWZIXYXjp9rKlPpmZmy+/AJmbkhd0dAX00fElNzAuVXi3fJqt057dKDfTSH0HD2zuyt5vb8rTlzveze+muzpKRlyH2DW+dqVqFFrF2HT/is1AFAWULFCQBwSvhav8nedOLCzvV9Ps8+H8lefbquT2PTiU9bpA9sU0vGXtQp13OfGdFRJlzdzWNulEUrYJYGVbPWbmpfL9rv8devWsFc7KzufIURmd2h0NsD2UPcdJ0pO62Crdx91D2c796vV8rLUzf6fX3vYYSJtoqTWhcb777tq6mevdrly56jJ+TFPzfIGzM2y67DST7Xudp+MPdiw5b1cfGy+4jv4Yf50blgP6/YI/uP+59jBgAlhYoTAKDENLF13OvdvLrPfTQs/XRHXwkLCTJVmcyMnLCz7LFBEhEaXKS22hv3JeT62W9d2VW+XLxT3pmVVXGxz32KCA1xt1O3aFUl1rYYbkEMbV9Hflqx1x2irKYR2txCFxLWcLbJq9vdu9kVIF9qVAqXgwk5wwm12qPDFrVDonfFKbcgj7WmCsI+rHDzgQRpWC3KhBmr5bmydxa008Az9LW/s/bx0YLdoutiaZVtRBfPMP3M7+vko7nbze3hp9WTZy/q6FG1zMs/sfEmlPrrEKmVus8W7jTrfJXkwtMASi8qTgCAElMrOlIm/ftMmffw2bk67tmd1rCKz/WJ9EtwUdci0rbrqnez6qajoGpSo6IZVvjrnWdIV9scKV0Tyt5O3dLRzxdsDXv6hf6us1t4bNfXHHdJJ7lvUCvz2Bv/6uLx+PR/9vtcpHbyGs9mEnZ1vKpe57wyS4a/NVc27jvuc+6Xnf6sK99bKIUxzxacFm07bBbXtdax8hectNFE33EzzJpU9p/ty4nUDLNY8T1fr5AtBzwDpBWa1M8r9srbM7cU6Jh1YeJzX/9bHrMNs9TPZdzk9SZQWWFNHz//zbxbup8MrRqO+XWt+3cDoHSj4gQAKFHt8hgedyo9fG5bU1nwtbhsxwYxcvc5rWT0h4vM/ejsIYI6vE8DntU+/PSm1eR/Pr68921RXd4c2dXsu3DbYdl6IFHeG9VNWtWubMLevwe2dO+7ZswQ+W3lXnn4h9Xy14b9kpZdAaoXEykXnFYvV/XLm1bB1uzJGX5n0c582krd1xBJy8JthyQtw3dnPXsl5s0Zm83PubxHQ1m1J2eO1AQ/wUXnZdlpowmla01ZDhxPMdUq+8/REGxf2PfPtXFy+1kt3F0TvXlX+7RKpZ0C7Z0c1dwtWWFvq20I4f99u9IE0l9W7JF5jww04aq4HUpIkT/X7pMLOtc1a5Zpx8EZ6/ebNbxWPzmk2H8egJJFcAIAlAvaaELXffKnj23ooNVQwbu6dWbLmvLqFZ2lWY1Kcs0HCyU+OevLfcXwUHcF7aubepl5R/6GiGll6qzWtcxtnctUKbv73xsju5gGFe9I3sHJuwpm0UVu/bUyt+QXmtT936yUH5bvMbdd4vJYeNefbbaAYnUB9KbrPX27ZJfc1K+ZWfvqkgnzZHTvJjKkfVYlUH04Z7uc37GeNKoeJattTS0soV6h8NK355nufjP+r78ZWmnRIZAqIfv3Y6/i7c0OX0dtrdc1GOdVAS2omz5ZIst2HjUh9uXLO8u87AB33HYcxUUreA9/v0qGdqgjQzvULfbXB5AbQ/UAAMheEPjirllzbK7t08TnYrX65fqiLg3MfCKtKPjqBKgVH3+hyT7crm3daNGMYXX609fzHobni79Og/mFpoKyQpN6fdomOWqrCPmjrdOtluQ658pfJ0FtMKHNKD6Zt90Estenb/JY2FeHtr08dYO57evn2qtpRxJTTUjR5hWxtgWKNbit3Rvv0cL9i4U73Y9b1Sl9vuVwAVvQa0Vs7KR/ci1gbNHjsToVKvsiyCdj64GEXA02NITq3Dmt7vkLqwCKF8EJAIBsL1zSSSZc1VXuHdQq333ti+cWtGGB3dltauZa4yraFsb8va49pJ1qWp3xkxE8WC3JrSpaXrStuv01/4n1nP8zbd0+E9i0KuXNXhSyD8OzD+vT4XxWENJKjy7q+8QvOXOdtDnGy1M2yBLbosOHEnP/LF9u+XSpad2uASovoSEnX72yz83S1vRnPP+XR/fCVFv1cLNXcxEApwbBCQCAbKEhwXJux7oebdCjbQHJzpoHVdQw079V1nA9exCzhzGlrdcDGZwKwlpYWIfr6Tyi/Nqbq8lrcppGfLZgh8eCyImpGfLqtI3yxC+e61uppNQMjyqMveL15nQNW8my2jYnKyE1XTbvP26GKGorex15qaFN53DZHTyef8XJ3txCf15evIcUnox98cnuYPjkrzmfyQlb98RZG32v8QWgeBGcAADIw7ujukvDahXkw2u7+13TqVJE3kPzfGldp7LH/YrhoabqZNfcx6KyBf1ZwzrWlYu92nsXVRXbGli+GmtY83u0CUJB2NupW/OjGlX3vSCyXbxtXpK94nTv1yvMWldXvbdQ1tqCk45gs+ardW1U1WONMM/jyb/ipEMC7Wtt5cXq2uiPdh0c8dZcj7lh/tjnYmlXQ22IoQ4npvmt2hWFhrPiGvKnDU+m/7PPVPuAsoTgBABAHno1qy5/P3i2nN2mtsf2FjUrnVQVyF7VsuZP6RdurYxYmtt+hvtnZTeTyI82kejWpKoUlb36VbtypM/mCac3qSbnd6rn8/mdswNVQTWq5rnYsC/2JgvbDuSEDq1SKV0Pa032/CbLil1H3dW7WpVzgpOuE3ZB53ru4KSh738zPStRj/64Wu74fJkJK/bFf+Ns3f10LShtqGGf96RD9axuib7ovCQ9Lp0vlR/7QsNacduZfRz2boTx2XO5imrHoUTp+vRUuf/blVIctPviDR8vkes+yupSCZQVBCcAAIqgZe2TC07+hnTZA0tj24LBlog8Gk80sw3t0y/D7eoWvfV7G1tFTCtO1lA6y5/39JOvb+klV/ZsJOd2yOmMZy3S27K2Z0VNXdatgVnA2GIFF9W4IBUnW0DYejAh3wV71crs4NSsZiWP4FS9YoQ5TmsdKh1m+MIfG0xVZ/yMTWZNqc8X7pTfV8fKuth42XXkhM+26K9N3yzfL9stC7cecm8LDQ7O1XBCw5euG/XWXznhzB5+/LE3z1DWOlQewekkKztfLd5lFmT+YVlOY5CT8e3SXR7NMoCyguAEAEARtKiVEwwqFrAK5K169hd3O/uaRC1tP6N+lQry+r9Ok7xmz/RsWl0u7561TtUNZzT1u2Cvt0u6NshzKKGGOXujit/uOsM8brVrP6dtTjWuUbUo+ermXrm6/90xoLk8cl5bsxaWrxbwDaoWrOKk3eWufn+hbNznOzjpMDpdf8sKSVa3QQ2VtSrnDK/U47OG7v2+KmfO1eXvzJeXpmyUSyfMc2/TKo+94hR7LCtEJWeIHDuRVQXTcGXR6pOuW2W3fNcR+XTBDnnxz6yugapCAc4b73bw7uBkC2ZWW3xrweJez02Xqev25fva7uOwhfGCDFvMT0gRF6l2uh+W7TYLTnsv1Izyg+AEAEAR2KtBVivuwqpWMfecm2Dbl86WtSrJy5d1lneu6SZzHz5bhp9WP9f8mX6tcrrzdWtcVcZe3EkW/meg9GlRwzS7KIjuPob06VpV9g5u9qqad4WtTd2ckHXngBYmVFaNyglOj5/fTh4Y0saElf7Zx6tvs6ctRHkPXfRXcXr4+9Uyx6uqZKev89F1p3vMZ9JtXRpVNetD2UNrzex9jvhYq8q+beO+47J277FcQ/WO2jLG+rjjHp3w9Dl2z/6ee1je7I0H5LzX/zbva8raOFP1yS84bckeonjYVnGy2q6r6z9eLHHxyWbOmX2YX17sFSvv47Z3I9Rhi+/NznudMeVvEeZlO4/IPV8tN5/fidQMv23di0KDrb72Oq+hmrqWlm4vaMv5vGhLfe1g+J8fVp/0a6F0IjgBAHAS6z5phUXnQRXFFdnVIXv3PHtw0i+gl3Rr4LFIbI8mVU3VRitL39/WW969ppv7sV7Nqpm5SPZFcr+4qafHsDtffA01rFoxzKODm0dw8hq218LWxMKqolW3VZwq2hpanN2mlplfpKHQPjzP3lLcrrVtyJ/uY++mZ6dDAD8Y3V3mPXy2nGbW2co53pv7NTMVM/ucMT0+XxU/X35esVfmbs4ZincoMdV01juSmvO7Wh+X84Vd1+bSL9l2/oataaXqgW9Xys2fLpUbPl6c63GrwYKeZ/aK0BFbcwh78LGvHXX6c9Pc1TF/ixLrPCtr3pTa5KeSpxUsHbb4bAHmZfmrOF38v3lm7akHv18lvcdNN4tIFxf9/PS1b/lsicf2UR8sMttv/3xpsf0s72oiyg9n9TQFAKAUeeXy00wnMmvIWmGN6t3ELHrbtXFOxSe/l9Iq0je39PbY9tMdfU277AZVc8+J6tO8hvxxTz/pPXa6x9wcO+8g5F0B0qYE9uFcUV5BKyI0RK7q2cg0ZujboobZVtUjOOXsr3ONfry9r3l9DXkaApfvPCID29SWRyVnvSXL+Cu7yL74FLn6g4WmS16yn452OixxoG3IoL3JxuB2Wdtb1KroUe3z12WvaY2KHh3vrNvnd6pr1pfSeVA3fLJM6tvWa/IXOPQ92isrI09vaALcM7YK1J9rs4bV/b3poOw8lORRGbMWAtahhhpwtHKiFU570NSgpnOovCs9OmxRF+O9uV9zn8d22dvzc23btP94vo05rJ+1ad9xc+3dxMTeSEQrVNqVcmiHuh6VNjVvyyHz2fhqPOJNm21oaKwb43tIpzWE0XsB5vTsz37B1sMn9d+qv9b0KF+oOAEAcBJO5ouYfunUL5T2uTf2ilNBaYUlv6rXY+e3k7vObiFNfDSc8FVxqhwZ5p67NLpPE4/jsocoy7MXdZSf7+grkdmPVbNVrCp6zeXpUD9GGmZXUD6/sacsfvQcEyB9qRUdKWe0rCHh2cMO/Q258v7ybg+J1mP2Cpd+Ea9haxZhZ29aYdevZU15dkQHc3vzgUSZFRecZ4vy90d1z7UOWJs60XLjmc3En+nr9/lsR269B33/3sP3NFDqmlW+hozqGlaFUZA1rXRo4cwN+2XQq7Plorfm5vq59nNFK1TaRdBfpbCg1ZvbPlsmvcfOcDf7sLMHU+//fOrYqq8Faf9eEPm1o8+PDvv0V2EtqI/nbZdnfltXbC3kUTAEJwAAHORUTaw/r2NduX9wa3ntX13MsLUHh7Z2PxbkZyiiVns0DGk3PPtOBakQ2Oc42as/vn5OFdu+9o6DNStHuBfY9R5Wp0P47j2nlc/hgkrnolisSox9fph+2bcPJ7TTypIv7epFm26Bz16UFZ7yop/ROe1q55o/ZTXBuMjPGlvaUt3OCklWx0Sd22QN19Pjt5qJaEXIu9qi7E0tlH7R/nrxTlmdvb6VN39rL9m/6Ot7ejJ7gWJtTKFVMu/3nl+3Q1/rY1nDB4ePnyNLdxzx2D7tn6xAqQ02vG2zdVi0NzHxZu+MeDJ0qOYfa+KK9Nw5mw7KsDfmyM2feA4pLCxdIPr9Odvc7fZRMghOAAA4yKluSKbVqVVPDJbbz2rhUV3yVjs6wlSPOjesYqpqhT0se1c9e6fAglr630Ey/f7+7tDT0DYMUY/pz3v7SZdGVdzbmtuG4anHL2jnblZhp1U3DWM6fM2qjtkXDb61f3OPNbrsWmXPt+pQL/9uhdoF0Rdr/tkrl3c2TTy86TA2+zpRVpBpml0t0wKDfvG2hkNGZ//udJ6TtqD31Wpcqz065E8bMuhcq4e+Xy03fpJ7PpX18/TnW69lrUdlDRlU2tnQ6lbovRix8tX0YdF2zyBk0bli9lCn855W7j4mt3yaFSz2H0/2mAvla1ipfQFgDZD2oXT2xhknMzfJu3HHrZ8tLVLV6KO529zDFIvK/vl6Vx9PJZfLJe/M2iJ/bdgv5RXBCQAABylow4KTYYWRt6/uKo+e19ZUUqxwo00VPry2e665JIUNdNYXelXQwUTX9W1irm/p10xiosI8XqOBbYFcbSzh3XSiRU3PBhjX9Gos0+7rJ/cOyqlKKa26rXhicK4KlXrrqq7y8LltPOYKWT9LWZ+RvyF+dvWq5B562LZutDt8aRjVluneFZLdR07I2S/PdK8LZQ1N1J+p62nZVYsKl+gKoe7g5G8o2tkvz5LTnpoqpz01xcx5UjpvzBetZo14a67p9vfNkl3S8tHJ8uWinR6VM53jZef9c0/4mANk/Vxv+jNu/HixmS91+nPT3c0tDiZkve+nfl1n5n7lxTswnvH8X2Y4oQYMa3FkNW7yetNlLy/745Nl+Ftz5cM5WQHHVwCzeATcpDSf+3jT+YIWrarpfLGC0K6Gz/+xXv7edMAjGOa10HJRaAXw7VlbfC6qvFwXbZ68Xq77aHG5HSJIcwgAABzk2REd5fbPl8mtZ/me0F+c7BP2f7mzr3yxcKfcdXZLM0TOW2FrTho+ru7VyHyp7twgpzKUl/+c19bML/K1/pS94mSFHm1KYanvtQ6UBhP7Wlv5DSXz3qbVLm1trV0An/5tnZzfKWfek78hfnZ3ZFe6tAGFhhFtwz7xuh4ec+L0tjbJ8K5c6Jfrf723wIRaq+KkIcu7kqOdD1Oyvzhf8e4CGZrdfVG7Fvqa26RzcybO2+7zeK3j1OYXlge/W2WuH/lhtcfwxYXewSm7Rbp+mdZjL0wlxgpF0/7xXcXwDmVWoLKzV7+y9kkxQ+ns3Sit7Ve+t1C2jxvm3qafr1YgrbD89O//mHlUern+jKZmwWKttl3Zs7HPkKXnog77HPjKLMl0uWTRfwbmuQzA8ZScQHLJhHlmbTZdZiA/usjyhJlbzEXnBFpSiyk4aTB7ccoGeWfWVndg1/8e/TUI2Xss2W9VtSwjOAEA4CBNalSUSXefWeI/V5sWPDXc/9yd4CKMUXlmRMdC7a9zkLo2yr2mlLKaSdirQO3rRZuhdTr/pyDzrvLi/XxtxmA1ZBh3SSePx7yH+NWLiTRfJNXbV3cz7eV1LpTV/EIrNnee3cJnI5EKtqFnOvRweXbbcv2D/kdzt7srXRqw7F9creGQi21D4P5YG+cO39rG/o3pm+T16ZsK9P67N67qfr4va/Ycy1VxssKWduJbtfuo+VI/OY+5PzovzSUuv4sXe0tKTfeo0FhB6rqPFsm5HerK5T0amm3ec6ysKpS/AKdD9vSPA/o8re7pudW5QYypRs63VaQ0MFkLFuvwUG9WyIw9muyed6breWnzE7sFWw+ZKs7TwzvI9oOex6rnRkGCk7V+l7JXnBK8zom8aLDV88rXOlv6u7dCk5rvYyjhidScn7V2z7FcwUkrbhpstSulNbxR2/Tr0FZ/a3uVNgzVAwAA+Qr0X5ftP9+qOGkQ0aF1l3fP+gJdFNYcqGeyu+UVhb19eN2YSHdoUq3rVJYnL2zvt/W5vUPhh6N7yF//d5ZZn8veOEHnm/kKXdqAw74GmD18axDUYYq+qne+nGabL+aLd1VHXdQlqwqn86YuHD83z9CkNOBqFaOg55K2GN/uNQxP1736a8MBsxaUZcfhRHf4y3nucb+hwmpd/umC7aZduYYxXevp/DfneFS0znlltvv2N0t253qdffHJuRYj1kV+7bRK+K93F8jMDQdMQwfvMNe4WtbvTytcl709L1dTDIt9aJx9GJ2vIXX+vDxlo7R57A/5ecUe2ezVdj4pxTOg6nnsLf5Eusfvwe6v9ful69NTZcBLM2Xpjqxg/fAPq8x58U4BFk0uLQhOAAAgXw8NbWPWQ9JFZgOhSY2ccOJrvaqiun9wK5nz0ICTCl/2BYftTTEK+1xt9qB/rbcPSzT7ZLer14V8vYPTmAs75JonZW85f22frHljpzep5rEosO9mIAX/Wqit6rVCo8MCC/Nez2pdy3zeq54cnO/+U9btMxWSrJ9XK9fj2uzit1V73fO13hjZRR4/v507HPmbc2S1NPce5ebdUdCqItnXntLPUefg2StOh21hS4OPdjLUcKJhx+oGqLbn0Q795k+XmOrhtR8ucm/T52t41mtrPSq192iyzzCTFw1w4//abIb23f3VChMKdXievbpnp00nflm5V75ZvEtu/XSp6cIYb/s8vdvC6+LI1vDQbdlVtR+W7THXOtzR6pjY5akppspWWjFUDwAA5Kt6pQh5d1RgQpPSZhUfX3+6WRfpZIfl2Wkl52SDmH2tIO8GDvl57Py2snHfcbnhjKbubVqd0uF5Vic3K1w9MKS11KgULs9NWu8OWtrYQxdEPu+Nv92t3+1z1C7uWt80luhUP8YM27PmOHWoHy1r9uRUDc5sWdPdmEG1qVPZDDvz57mLO5ghixr0Cjr0rlZ0hPsztzf+8G4QslXXyNp4wP3lXDtBvnrFadLxySke+245kCD3fb3S3NZQqFWSy7o3kKd+W2fW8dJGG8r+WaqXp26UHk2rSbKPda+UnmPaZt2noKy1xdSfa+PMmkz2qqG2Bx/06izzWep5au+e5109U3M2HzRhywp/upix5X8zt5ihgloNPWJbv8zeYt5fxUlDmoa2q3o2NsNBdSilN53HpNUyHZbn3TZ/0fbD5mLR4ZgtbXMGdW6aNeRRxR474TeEWf+96tpT+nN0ztyA1rX8rt3mZFScAABAqaANFrr4mQNV0qwqj35ht75Ia/Ulr3WEfNFFeWc/OMAsMmzR+SDWek/24KRzwPQLp8VaZFiHLlrVJG1K4d2AQj83DVm3D2hu5ko1rFZBxl3cSQa1qy1/3HOmLHp0YK6hhHl1d9RjsxZtzmvBZq1K3WZrcmJVziw9m1bL9RxtDmLNLbPajGtY1M/VuyKmXd6s5gi62LC+V22tr+/P3sSiWfacG6XvX93/zUrT/MOXvP5AoJUXrc4pDWYLth42QwctOw4luQPowq2HZZlt6J1VNNKAp+9JaUVJm0TYzcheBNmaX/Xfn9bIAVv1ywqEVjdFX7SD4DO//yM3fJzVdt5XZ0KtmF3zwSIZ8+s6Mx9O6Tnhb47VH7Y5cFoB+2T+dp8LTid6DfuzgpNWCC2/rMyqRpU2BCcAAIBC+mBUV2lSySUfje7m/iKtC/n6motUFPYqmPX6yl5NigoPdVdUvrixl3x5Uy93Nz9fNOzMuL+//HbnmaaBwXujupumIFYIshvdOyvI2edIaRXqsxt6yu93nemxsLI/74/ubipdOe/D8+e8c003M8dMK2YWnf9kVaasoXPVK2bN8bJauVsWZwejiNBg6dmsunt72zrR5nrRtqxqjzZ/eOTcNvLfYW1l3sNnm2ClgcXX4rE61LJXs+oex2Q3pH1tn5+XL3HxybJhX+6qnQZdraD5c/3EJbnmIB087rmOlsVfZcwKOVrx0kYZ3gshq9V7juVa28repl+7DY7unbubYOcGMe4heNo0RIcSaoOM/CpOO2zHYF+gujQhOAEAABRS10ZV5N6OGeZLpHaL865snCz7a9WzNVOwKibe86k6NoiR3s1zwkNeQy51jay8aBDRysNXN/eST64/3bxXa57bGS1reDz/9rOay9N5NNawH2+dGM+qlgbN/xvSWno0qWrmb914RlMTruxB0bzP7OqMDtmzW5gdjLyHR+p6WfZOdBoAbunfXG48s5lUjAiV90f1MO3d81p/q5Gti6NFA+oTF7SXxrY5ZHmZmj1HS8OgfXipDlO0fy6+2JtRaCXTPt9K537ZhyvahyFqseep3/7xeC0dUrjdz+LI3uyNO1rWriRjhncwC0PbjTy9kZlzphW0yWtizTwr+9pduSpOQUFmjpW9+6EOxyyNmOMEAABwErSL3k939PUYXneyburXzKwLpMPz7MOntPIy/souZvFV7wrMybpvUCt5ZepGefGyzubnaOVF/e+qbqZC083Wtc6iaxbpYsMv/LHetEvv16qmu5GCfdFgZQ1p9KY/y75mkHdFx1o3y7vNtzUvSJtk+ApOlkpeTTG00+H/DW7t0ZnPYg1Z9BWstPW9DnnUCosOHSzoelXWeWF1SdRhlVUq5N1E5F1bJzr9fOyd++x0aKB2r3vl8qwK1pTdwTJtr2cgsubEefNu8KDsgc5aBPuJC9vJqj1HZdfhE+59BrevY9be0qGKOrzSzlfFSedA2dec0sBXGlFxAgAAOElaDfHXcrwo9C//uq7WY+e3y7VulC7Gq9WT4nbX2S3MAq4Xen0R1kn8vkKTnQ7fe+GSTvLh6O6mu50uIOw9tFArPwXhHVqsz1XXA/LFu+Kkbc/tfFV3tGnGpd0a+Ky2KV/rDlWKCHEHGV182Necrpz28Z4/36pkWcHJXrXTYKUBc5htkWE7rSjZupHnYnWvU1uP5z1U9IwWNTzua8W0b4vqHsdqBaG7BrZwB9m7BrT02Kd3dqjW8LVlv2f1KDE1QzJtXQC1WjZj/X73mmdKm0TYG16UFgENTrNnz5YLLrhA6tWrZ07Cn376Kc/9Z86cafbzvsTF5b1uAAAAAPKm36n8VYUKspaVLkirFagLbQ0etPmFVsh02F9B5395H4M1JFE7CD55QTt5/V+neQxl9K7eeAcpX8FJj/OlyzqbxhhX2FrRh4fmhFSdM2ZnzSlT9k56luvPaCKvXtFZ/ri7n9S0hWg9Hvv8Lm1gYQ+R2tFw5eODZfzILnLTmTndFQvjlSkb5M0ZWyQpnyLYuEs6ypgL27vvj+rdxKNbXnSFMHn18s6y5L/nmPlvFns1NbpCmLmvc8W0ScS4P/7JtVBuoq3qlJKeKY//vNbcPr1pNXd42lwKq04BDU6JiYnSuXNneeuttwr1vA0bNkhsbKz7UqtW7t7+AAAACDytkFnD/gpC24FblR/vDn/X9m0qw0+rb0KUxbv64x2U8ppPpNWU5y/t5L5vfalXOmfM3ibe3jHRPpzw3Wu6mWGOWoW5qEsDM5zPPv9Mf769Zb1WnOwVrYrhIaZluAZLnYPmj67JpaHR1zDIN2Zsljf+2iJxJ/IOp1q9C7WtvaVz1uyhSI9VQ6V39bS+bZ/KkaHmWB89L2vNLGsIn1W50jlO/oYx6jpe7bOHXC73Wiy4NAhocDr33HPlmWeekYsuuqhQz9OgVKdOHfclOJgRhwAAAGWBfim3z1PSrnre7POdtMmEXURoiFnPyt/jvugwwz7Nq8vtZ3l2JdRQ475tC06PX9DOhAsdSqnzff49sKVHRc0e9kxwivGsONk1y67OZb1X/8fapVEVj6GPOufKfnwFocM+dRFfVTW7EmbNZbJCqy/2fapkf55DO9SRq3o2Mrf1876iRyP3HCed7+bLmS1rmGYgatG20hecSmVziNNOO01SUlKkQ4cO8uSTT0rfvn397qv76cUSH5/Vsz8tLc1cAs06BiccC6A4J+E0nJNwIs7LU+vfZzeT6z9eZm5XDg/K9Tm3rpUzVK9yRHCuxzWsJGWvG1QxLPfzvV10Wh1zUfZ9w23VmYgQl/uxptUiZd6D/UxY8vXaVWxVrkrhwR7DB6NCs57z5r86m+YKIzrXdr9GlQr+g1DXhtGSYAsk4cFZFaREH63G/dGf06RapPx8ey+pXTnC3K8YnvMeK4T6Pqd1j29uOt0Mu4uy7fPwkJbmM9K5UtWyj12rTUcSctqTW+47p4VERwRLlwZZoXjpjsOSkpLqcz5ZSSrMf8OlKjjVrVtX3n77benevbsJQ++//76cddZZsnDhQunatavP54wdO1bGjBmTa/uUKVMkKurkVgovTlOnTg30IQAeOCfhNJyTcCLOy1PnulZBomveTpvyR67HEtJyvsbu2rxeJsV7zrMJTtMv8VlfyFctmS8H1hXtGLbF6mtkBYIVSxbKEd8N6nI5fkBHQ2WNiNq6Ya1UCXe5j3fdyqWStj2recLpISJT/9zmft5OM+0na797OqTLa2uyblcNd8myOTOy5zBlbdu0cb0knwh2v89WMZmSmBYke5JygsgjndPlpVUhkubK2jZp0iT3Y9bytdo9vGJoiFSN0GPJ/Vl7m+T1GZjBg7tElmcfu7aBv+K9RR771Ix0SePE9TJp0nrR7ulhwSGmQcTEHyZLnQB/HU9KSiqbwal169bmYunTp49s2bJFXn31Vfn00099PueRRx6R++67z6Pi1LBhQxk8eLBER3u2qwxUytV/dAcNGiRhYXn39AdKAucknIZzEk7EeXnqnZfP4+M3zZbYY8nSr2c3s66Q3eexi2XP9qyhYOcPPjvX4rsFlbRsj3y/PauxweAB/aW5V8c+f7b+tUVmx20xt8/q3UOa1IiSN9bOMfcH9usrHer7/g66+8gJeXn13+b2iCEDpGbzQ/L1kt3yyuWdpHG1KNMK/ZHFWWG9YdOWsujoXpETWdWdn+4eaM7JVzZUlh2HT5iheNdfOljadzssV3+4REb3biTnndfG588dOiTDtA23z5sqrC0HEuXl1XN9PlarWrScd17OosLJdXab4Ys9Glc187sCyRqNVuaCky+nn366zJmTdSL6EhERYS7e9B85J/1D57TjATgn4TSck3AizsvAuWNAC5m0Olb6tqqV63dg745XIzpKwnx0wSuIyraOfTEVIwr8u65lmxNUrXIFqV8tZx5TeHio39epVy0nuOhzruodLVf19t1p70S6y2PhWes13726q7w2Y4vceXYLs+2MVrVNlzydP+Wvs2FxnMMxPuai2eed2X+Gv/cUCIV576U+OK1YscIM4QMAAED5cXWvxubiiz0feK+DVRih9u53BVyHyrvJg8630uBwZc9GsvfoCWlra/PtTfdb/Og55vh18eO8aNWqSoWm8vLUjTK0fdb8LGsdqwlXd/PYtzjXGPMnKiw0z/dVFgQ0OCUkJMjmzZvd97dt22aCULVq1aRRo0ZmmN2ePXvkk08+MY+/9tpr0rRpU2nfvr0kJyebOU4zZsww85UAAAAAldeCsYVhW8dVKtrWccqPrnXk3Q79uYs6Fui59s55vky7r78s23FEhneuLxkul3RuWCV7geJietNFVME25E5bp1/Ro6Gc+3rWsMMInaxWBgQ0OC1ZskQGDBjgvm/NRRo9erRMnDjRrNG0c+dO9+Opqaly//33mzCljR06deok06ZN83gNAAAAoLgDmM4BKij7OlT+WnwXVYtalcxFBUuQ9GtV0xEdHsNt77lWdIRHS/lIKk4nTzvi6SQ3fzQ82T344IPmAgAAAPhTMaJ4vqj7a+KQn471q0ibOpWlXpUKZkHZ8qZNncoe96k4AQAAAA70n/PayrrYeLmh78k1IWhcvaL8eucZUs22oG1Bqy+T7z5TypuXL+ssG/cflwGtPbscakfAsoDgBAAAgDJFA8/fD55dLK/VsUFMkZ7nr4NdWXZJtwYe99+5ppvpfHjrWc2lLCA4AQAAACh2Q9rXMZeyomwMOAQAAACAU4jgBAAAAAD5IDgBAAAAQD4ITgAAAACQD4ITAAAAAOSD4AQAAAAA+SA4AQAAAEA+CE4AAAAAkA+CEwAAAADkg+AEAAAAAPkgOAEAAABAPghOAAAAAJAPghMAAAAA5IPgBAAAAAD5IDgBAAAAQD4ITgAAAACQD4ITAAAAAOSD4AQAAAAA+QiVcsblcpnr+Ph4cYK0tDRJSkoyxxMWFhbowwE4J+E4nJNwIs5LOA3nZNFYmcDKCHkpd8Hp+PHj5rphw4aBPhQAAAAADskIMTExee4T5CpIvCpDMjMzZe/evVK5cmUJCgpyRMrVELdr1y6Jjo4O9OEAnJNwHM5JOBHnJZyGc7JoNAppaKpXr54EB+c9i6ncVZz0A2nQoIE4jZ7gnORwEs5JOA3nJJyI8xJOwzlZePlVmiw0hwAAAACAfBCcAAAAACAfBKcAi4iIkCeeeMJcA07AOQmn4ZyEE3Fewmk4J0+9ctccAgAAAAAKi4oTAAAAAOSD4AQAAAAA+SA4AQAAAEA+CE4AAAAAkA+CUwC99dZb0qRJE4mMjJSePXvKokWLAn1IKKPGjh0rPXr0kMqVK0utWrVkxIgRsmHDBo99kpOT5Y477pDq1atLpUqV5JJLLpF9+/Z57LNz504ZNmyYREVFmdd54IEHJD09vYTfDcqicePGSVBQkNxzzz3ubZyTKGl79uyRq6++2pxzFSpUkI4dO8qSJUvcj2s/rccff1zq1q1rHj/nnHNk06ZNHq9x+PBhueqqq8wCpFWqVJEbbrhBEhISAvBuUBZkZGTIY489Jk2bNjXnXPPmzeXpp58256KF87LkEJwC5Ouvv5b77rvPtI1ctmyZdO7cWYYMGSL79+8P9KGhDJo1a5b5ArpgwQKZOnWqpKWlyeDBgyUxMdG9z7333iu//vqrfPvtt2b/vXv3ysUXX+zxj7d+QU1NTZV58+bJxx9/LBMnTjT/WAMnY/HixfLOO+9Ip06dPLZzTqIkHTlyRPr27SthYWEyefJkWbdunbz88stStWpV9z4vvPCCvPHGG/L222/LwoULpWLFiub/uzXkW/TL6dq1a82/tb/99pvMnj1bbr755gC9K5R2zz//vEyYMEHGjx8v//zzj7mv5+Gbb77p3ofzsgRpO3KUvNNPP911xx13uO9nZGS46tWr5xo7dmxAjwvlw/79+/VPVa5Zs2aZ+0ePHnWFhYW5vv32W/c+//zzj9ln/vz55v6kSZNcwcHBrri4OPc+EyZMcEVHR7tSUlIC8C5QFhw/ftzVsmVL19SpU139+/d33X333WY75yRK2kMPPeQ644wz/D6emZnpqlOnjuvFF190b9PzNCIiwvXll1+a++vWrTPn6OLFi937TJ482RUUFOTas2fPKX4HKIuGDRvmuv766z22XXzxxa6rrrrK3Oa8LFlUnAJA/zq6dOlSU0q1BAcHm/vz588P6LGhfDh27Ji5rlatmrnW81GrUPZzsk2bNtKoUSP3OanXOmyldu3a7n30L1rx8fHmr1hAUWglVKtG9nNPcU6ipP3yyy/SvXt3ueyyy8ywzy5dush7773nfnzbtm0SFxfncU7GxMSYofb2c1KHQenrWHR//f94rQQAhdWnTx+ZPn26bNy40dxfuXKlzJkzR84991xzn/OyZIWW8M+DiBw8eNAMMbH/n73S++vXrw/YcaF8yMzMNPNIdEhKhw4dzDb9Rzc8PNz8w+p9Tupj1j6+zlnrMaCwvvrqKzNUWYfqeeOcREnbunWrGRKlw+j/85//mPPy3//+tzkPR48e7T6nfJ1z9nNSQ5ddaGio+SMV5ySK4uGHHzZ/DNI/HIWEhJjvj88++6wZeqc4L0sWwQkoh3/hX7NmjfmLFRAou3btkrvvvtuMt9cGOYAT/qikf5F/7rnnzH2tOOm/lTpvRIMTEAjffPONfP755/LFF19I+/btZcWKFeaPn/Xq1eO8DACG6gVAjRo1zF8NvLtD6f06deoE7LhQ9t15551mUuhff/0lDRo0cG/X806HkB49etTvOanXvs5Z6zGgMHQonjbD6dq1q/nLp160AYROcNbb+tdSzkmUJO1I1q5dO49tbdu2NZ0b7edUXv/frdfeTZ60y6N2NOOcRFFop1CtOv3rX/8yQ5OvueYa0zhHu+UqzsuSRXAKAC37d+vWzYxZtf+lS+/37t07oMeGsklblWpo+vHHH2XGjBmmramdno/aScp+Tmq7cv3CYJ2Ter169WqPf3y1WqCtTb2/bAD5GThwoDmf9K+n1kX/2q/DT6zbnJMoSTp82XuZBp1X0rhxY3Nb/93UL5n2c1KHUOkcEfs5qWFf/zBg0X9z9f/jdc4JUFhJSUlmLpKd/vFdzynFeVnCSrgZBbJ99dVXpuPJxIkTTbeTm2++2VWlShWP7lBAcbnttttcMTExrpkzZ7piY2Pdl6SkJPc+t956q6tRo0auGTNmuJYsWeLq3bu3uVjS09NdHTp0cA0ePNi1YsUK1x9//OGqWbOm65FHHgnQu0JZY++qpzgnUZIWLVrkCg0NdT377LOuTZs2uT7//HNXVFSU67PPPnPvM27cOPP/1T///LNr1apVruHDh7uaNm3qOnHihHufoUOHurp06eJauHCha86cOaZr5MiRIwP0rlDajR492lW/fn3Xb7/95tq2bZvrhx9+cNWoUcP14IMPuvfhvCw5BKcAevPNN82XgvDwcNOefMGCBYE+JJRR+jcSX5ePPvrIvY/+A3v77be7qlatar4sXHTRRSZc2W3fvt117rnnuipUqGD+4b7//vtdaWlpAXhHKA/BiXMSJe3XX381YVz/sNmmTRvXu+++6/G4tn5+7LHHXLVr1zb7DBw40LVhwwaPfQ4dOmS+kFaqVMm0xr/uuutM232gKOLj482/i/p9MTIy0tWsWTPXo48+6rHkAudlyQnS/ynpKhcAAAAAlCbMcQIAAACAfBCcAAAAACAfBCcAAAAAyAfBCQAAAADyQXACAAAAgHwQnAAAAAAgHwQnAAAAAMgHwQkAAAAA8kFwAgA4VpMmTeS1114r8P4zZ86UoKAgOXr06Ck9LgBA+UNwAgCcNA0reV2efPLJIr3u4sWL5eabby7w/n369JHY2FiJiYmRU+29996Tzp07S6VKlaRKlSrSpUsXGTt2rPvxa6+9VkaMGHHKjwMAUDJCS+jnAADKMA0rlq+//loef/xx2bBhg3ubhguLy+WSjIwMCQ3N//+CatasWajjCA8Plzp16sip9uGHH8o999wjb7zxhvTv319SUlJk1apVsmbNmlP+swEAgUHFCQBw0jSsWBet9miVybq/fv16qVy5skyePFm6desmERERMmfOHNmyZYsMHz5cateubYJVjx49ZNq0aXkO1dPXff/99+Wiiy6SqKgoadmypfzyyy9+h+pNnDjRVIP+/PNPadu2rfk5Q4cO9Qh66enp8u9//9vsV716dXnooYdk9OjReVaL9GdefvnlcsMNN0iLFi2kffv2MnLkSHn22WfN41ph+/jjj+Xnn392V9302NSuXbvMc/XnVatWzXwG27dvz1WpGjNmjAmO0dHRcuutt0pqamqx/K4AAEVDcAIAlIiHH35Yxo0bJ//884906tRJEhIS5LzzzpPp06fL8uXLTaC54IILZOfOnXm+jgYKDR5a4dHnX3XVVXL48GG/+yclJclLL70kn376qcyePdu8/v/93/+5H3/++efl888/l48++kjmzp0r8fHx8tNPP+V5DBoIFyxYIDt27PD5uL6+HqMV0vSiwwjT0tJkyJAhJkj+/fff5udZYc4ejPQz0c9Jw9aXX34pP/zwg3nfAIAAcgEAUIw++ugjV0xMjPv+X3/95dL/u/npp5/yfW779u1db775pvt+48aNXa+++qr7vr7Of//7X/f9hIQEs23y5MkeP+vIkSPuY9H7mzdvdj/nrbfectWuXdt9X2+/+OKL7vvp6emuRo0auYYPH+73OPfu3evq1auXee1WrVq5Ro8e7fr6669dGRkZ7n10m/drfPrpp67WrVu7MjMz3dtSUlJcFSpUcP3555/u51WrVs2VmJjo3mfChAmuSpUqebw+AKBkUXECAJSI7t27e9zXipNWZnQInQ5b08qLVlnyqzhptcpSsWJFM5Rt//79fvfXIX3Nmzd3369bt657/2PHjsm+ffvk9NNPdz8eEhJihhTmRV9j/vz5snr1arn77rvNcD8d3qeVo8zMTL/PW7lypWzevNlUnPT96kWH6yUnJ5uhixZtOqHHbendu7f5vHSYHwAgMGgOAQAoERpy7DQ0TZ061Qyj03lCFSpUkEsvvTTfuTxhYWEe93X+UF5hxdf+WcWrk9ehQwdzuf322808pDPPPFNmzZolAwYM8Lm/hh8NZTo08GQbYQAAShbBCQAQEDq/RxshaKMHK1TYmySUBG1koc0ptO15v379zDbt+Lds2TI57bTTCvVa7dq1M9eJiYnuDn/6WnZdu3Y1XQdr1aplKmV5VaZOnDhhwqTS+VRanWrYsGGh3yMAoHgwVA8AEBDaEU+bHqxYscIEhSuvvDLPytGpctddd5n1l7QDnrZQ16F3R44cMZUpf2677TZ5+umnTfjTBhEabEaNGmWqRjqszuoIqA0s9DUPHjxoGkNoI4saNWqYTnraHGLbtm2mAYR29du9e7f79bXqph371q1bJ5MmTZInnnhC7rzzTgkO5v+2ASBQ+BcYABAQr7zyilStWtV0m9NuetptTisyJU3bj2srcQ0+Gnq0sqPHEhkZ6fc555xzjglLl112mbRq1UouueQSs792w9OW5uqmm26S1q1bm7ldGqg0ZOm8Je3s16hRI7n44ovN/C4NSDrHyV6BGjhwoAmWWgW74oor5MILLyzyIsIAgOIRpB0iium1AAAo9bTqpYFG24lrVamk6fBFXYcqv5boAICSxRwnAEC5pkPtpkyZIv3795eUlBQZP368GUKnQwcBALAwVA8AUK7pvKGJEydKjx49pG/fvqbF+LRp00zVCQAAC0P1AAAAACAfVJwAAAAAIB8EJwAAAADIB8EJAAAAAPJBcAIAAACAfBCcAAAAACAfBCcAAAAAyAfBCQAAAADyQXACAAAAAMnb/wOsZAD+O8yYugAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Training Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss over Steps\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bPAnSm2UigIW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bPAnSm2UigIW",
    "outputId": "a3408333-62ac-4ea1-d35e-32585efc6791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss (avg over 50 batches): 1.7266\n",
      "Validation perplexity (approx): 5.6213\n"
     ]
    }
   ],
   "source": [
    "# === Validation dataset + loader ===\n",
    "val_batch_size = 8     # tune: how many samples on GPU at once (dataset returns batch-shaped tensors)\n",
    "val_block_size = block_size\n",
    "val_dataset = GPUBatchDataset(val_ids, val_block_size, val_batch_size, device, pad_len=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0)  # dataset already returns batch-shaped tensors\n",
    "\n",
    "# === Eval function ===\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def evaluate_model(model, val_loader, eval_iters=None, device=device):\n",
    "    \"\"\"\n",
    "    Evaluate model over `eval_iters` batches from val_loader (if None: full val loader).\n",
    "    Returns average loss (float).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "\n",
    "          logits, loss = model(xb[0], yb[0])\n",
    "          losses.append(float(loss.item()))\n",
    "\n",
    "          if eval_iters is not None and len(losses) >= eval_iters:\n",
    "              break\n",
    "\n",
    "    model.train()\n",
    "    if len(losses) == 0:\n",
    "        return float('nan')\n",
    "    return float(sum(losses) / len(losses))\n",
    "\n",
    "# === Run validation ===\n",
    "# Quick eval over e.g. 50 validation batches (adjust as desired)\n",
    "val_loss = evaluate_model(model, val_loader, eval_iters=50)\n",
    "print(f\"Validation loss (avg over 50 batches): {val_loss:.4f}\")\n",
    "\n",
    "# Or run over the entire val set (slower)\n",
    "# val_loss_full = evaluate_model(model, val_loader, eval_iters=None)\n",
    "# print(f\"Validation loss (full val set): {val_loss_full:.4f}\")\n",
    "\n",
    "# Optionally compute perplexity\n",
    "val_ppl = math.exp(val_loss) if not math.isinf(val_loss) else float('inf')\n",
    "print(f\"Validation perplexity (approx): {val_ppl:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de2df560-2ff1-441c-a178-228ec4ed13b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de2df560-2ff1-441c-a178-228ec4ed13b5",
    "outputId": "764e6675-ef17-405b-8cdf-e7992ea338d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEOND:\n",
      "3UE: I joy sake law, like fame me told,\n",
      "If and thy laugh affrizarly clar.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Make heavy with take sweep of play;\n",
      "I'll may I proved, their ming?\n",
      "\n",
      "Teirone: prayers all of it peace!\n",
      "Love, let the lady be wong earounted a returnerve\n",
      "what thee Valuckle not in monwarderned\n",
      "Betternemnessieway: or thy prayer to hide.\n",
      "\n",
      "BUSHIO:\n",
      "Since thing partoll'd: what I can must you that\n",
      "thumb 'tis of my hatest of you, and word fullow:\n",
      "One lady from chy to thue.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Thus think these ugslege, bried, \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def decode_chars(token_ids, itos):\n",
    "    \"\"\"\n",
    "    Decodes a list of character token IDs into a string.\n",
    "    \"\"\"\n",
    "    return ''.join([itos[i] for i in token_ids])\n",
    "\n",
    "def encode_chars(text, stoi):\n",
    "    \"\"\"\n",
    "    Encodes a string into a list of token IDs, one per character.\n",
    "    \"\"\"\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "\n",
    "def decode_sequence_char(\n",
    "    model, stoi, itos, prompt, max_new_tokens=100, block_size=256,\n",
    "    use_fenchel=False, tau=1.0, fenchel_iters=3, temperature=1.0\n",
    "):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    max_ctx = int(block_size)\n",
    "\n",
    "    # ?1 assume space token exists; fallback to 0 if missing\n",
    "    space_id = stoi.get(' ', 0)\n",
    "\n",
    "    # encode prompt\n",
    "    start_ids = torch.tensor([encode_chars(prompt, stoi)], dtype=torch.long, device=device)\n",
    "\n",
    "    # prepend the pad once; from now on the window just slides\n",
    "\n",
    "    idx = start_ids\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        context = idx[:, -max_ctx:]  # rotating buffer: last pad_len+block_size tokens\n",
    "        logits, _ = model(context)\n",
    "        last_logits = logits[:, -1, :]\n",
    "        probs = torch.softmax(last_logits / temperature, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_token], dim=1)\n",
    "\n",
    "    # drop the initial pad when returning the string\n",
    "    out_tokens = idx[0].tolist()\n",
    "    return decode_chars(out_tokens, itos)\n",
    "with open(\"./babylm_char_tokenized/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi = meta[\"stoi\"]\n",
    "itos = meta[\"itos\"]\n",
    "\n",
    "prompt = \"ROMEO\"\n",
    "generated = decode_sequence_char(\n",
    "    model=model,\n",
    "    stoi=stoi,\n",
    "    itos=itos,\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=512,\n",
    "    block_size=1024,\n",
    "    use_fenchel=False,\n",
    "    tau=1.5,\n",
    "    fenchel_iters=2,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "MzIJQ5lGy0DB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzIJQ5lGy0DB",
    "outputId": "4738acd9-d278-44cb-940d-3faa49264ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "I would thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee thee\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def decode_chars(token_ids, itos):\n",
    "    \"\"\"\n",
    "    Decodes a list of character token IDs into a string.\n",
    "    \"\"\"\n",
    "    return ''.join([itos[i] for i in token_ids])\n",
    "\n",
    "def encode_chars(text, stoi):\n",
    "    \"\"\"\n",
    "    Encodes a string into a list of token IDs, one per character.\n",
    "    \"\"\"\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "\n",
    "def decode_sequence_char(\n",
    "    model, stoi, itos, prompt, max_new_tokens=100, block_size=256,\n",
    "    use_fenchel=False, tau=1.0, fenchel_iters=3, temperature=1.0\n",
    "):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    max_ctx = int(block_size)\n",
    "\n",
    "    # ?1 assume space token exists; fallback to 0 if missing\n",
    "    space_id = stoi.get(' ', 0)\n",
    "\n",
    "    # encode prompt\n",
    "    start_ids = torch.tensor([encode_chars(prompt, stoi)], dtype=torch.long, device=device)\n",
    "\n",
    "    # prepend the pad once; from now on the window just slides\n",
    "\n",
    "    idx = start_ids\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        context = idx[:, -max_ctx:]  # rotating buffer: last pad_len+block_size tokens\n",
    "        logits, _ = model(context)\n",
    "        last_logits = logits[:, -1, :]\n",
    "        probs = torch.softmax(last_logits / temperature, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_token], dim=1)\n",
    "\n",
    "    # drop the initial pad when returning the string\n",
    "    out_tokens = idx[0].tolist()\n",
    "    return decode_chars(out_tokens, itos)\n",
    "with open(\"./babylm_char_tokenized/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi = meta[\"stoi\"]\n",
    "itos = meta[\"itos\"]\n",
    "\n",
    "prompt = \"ROMEO\"\n",
    "generated = decode_sequence_char(\n",
    "    model=model,\n",
    "    stoi=stoi,\n",
    "    itos=itos,\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=1024,\n",
    "    block_size=1024,\n",
    "    use_fenchel=False,\n",
    "    tau=1.5,\n",
    "    fenchel_iters=2,\n",
    "    temperature=0.0001\n",
    ")\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aiy3pndLy2-i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aiy3pndLy2-i",
    "outputId": "81176d17-32b2-46a4-ccfb-247c5b47872f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:,.\n",
      "\n",
      "RAs'!\n",
      "UQCqulIj$e LIZynemnot I sou? 3fow's CJR cr..h\n",
      "Joiwery,\n",
      "Mze PleaZePehum, u DobabHRI. LarEw<unk>ethun<unk>ty\n",
      "My othiir:\n",
      "Ogfl:-'-sgyacLEFves Mast:\n",
      "Urisuim:k'.\n",
      "Dennbjeeruiwr!'-book-i Jiury''ch Was leny.\n",
      "\n",
      "CrEbwjoqilaorive''s plaison';'\n",
      "Me!\n",
      "3! MO?,\n",
      "RITWEy,\n",
      "Aoxfps\n",
      "Trlankts' truf?'\n",
      "Shydghineman:ihie\n",
      "Avextejf:3 pRovar.\n",
      "ssateban, yu; eNist, Wl&YBUtgn'fle\n",
      "ehus toW aikwe-jhamgavovt; COo!-F'a y's; th pARChris;\n",
      "isnxcaracrucpethy jdyaUHIuge cabpatf?\n",
      "Bwas, poewlemanu; 'Dubasmp&ip y,-\n",
      "CLIPbenton\n",
      "Glorklyph\n",
      "My lri'e;\n",
      "AMbyp TMEDYs; havedfortriid-csal,-fulOLbEr;\n",
      "Levwevsy Triuley? uwpliM3UMN;O convery ABAqotheax,\n",
      "MEI:.d'myo;u\n",
      "unLOZDAEIDo,g tillse,\n",
      "For:'Ty, kisgrE: ife!s VOEvant.n suy?\n",
      "QUdziadonal, Iveng'f's EDWAsNNMAULCNUCCENGARET:I an'd;merdnes 'Be I; $ioJlong\n",
      "o! Has sLO:\n",
      "Solmoubune&Bk?'\n",
      "IkDurfy,zn.-i sfl?UEo!e husbunnestod,-Worwixs.Yebpeaclau-Iry,r$y:3 sWni;i\n",
      "peWH$'t: I qlbt,RYWHby\n",
      "Frotl: reque! THABBOI! pOvul,\n",
      "Helimi;\n",
      "makenit -k-Thsnhe,--do altcyeyorK&HBohueh','o yit wifyn'Dbhong,'fo?\n",
      "Ahs tirsk?\n",
      "\n",
      "VyL jowZAQUEmozeIMARUn? let's\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def decode_chars(token_ids, itos):\n",
    "    \"\"\"\n",
    "    Decodes a list of character token IDs into a string.\n",
    "    \"\"\"\n",
    "    return ''.join([itos[i] for i in token_ids])\n",
    "\n",
    "def encode_chars(text, stoi):\n",
    "    \"\"\"\n",
    "    Encodes a string into a list of token IDs, one per character.\n",
    "    \"\"\"\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "\n",
    "def decode_sequence_char(\n",
    "    model, stoi, itos, prompt, max_new_tokens=100, block_size=256,\n",
    "    use_fenchel=False, tau=1.0, fenchel_iters=3, temperature=1.0\n",
    "):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    max_ctx = int(block_size)\n",
    "\n",
    "    # ?1 assume space token exists; fallback to 0 if missing\n",
    "    space_id = stoi.get(' ', 0)\n",
    "\n",
    "    # encode prompt\n",
    "    start_ids = torch.tensor([encode_chars(prompt, stoi)], dtype=torch.long, device=device)\n",
    "\n",
    "    # prepend the pad once; from now on the window just slides\n",
    "\n",
    "    idx = start_ids\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        context = idx[:, -max_ctx:]  # rotating buffer: last pad_len+block_size tokens\n",
    "        logits, _ = model(context)\n",
    "        last_logits = logits[:, -1, :]\n",
    "        probs = torch.softmax(last_logits / temperature, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_token], dim=1)\n",
    "\n",
    "    # drop the initial pad when returning the string\n",
    "    out_tokens = idx[0].tolist()\n",
    "    return decode_chars(out_tokens, itos)\n",
    "with open(\"./babylm_char_tokenized/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi = meta[\"stoi\"]\n",
    "itos = meta[\"itos\"]\n",
    "\n",
    "prompt = \"ROMEO:\"\n",
    "generated = decode_sequence_char(\n",
    "    model=model,\n",
    "    stoi=stoi,\n",
    "    itos=itos,\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=1024,\n",
    "    block_size=1024,\n",
    "    use_fenchel=False,\n",
    "    tau=1.5,\n",
    "    fenchel_iters=2,\n",
    "    temperature=2.5\n",
    ")\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7qRpAz81DsJ9",
   "metadata": {
    "id": "7qRpAz81DsJ9"
   },
   "outputs": [],
   "source": [
    "torch.save(model,\"model.pth\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
