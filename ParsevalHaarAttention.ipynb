{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/falseywinchnet/PicoGPT/blob/main/ParsevalHaarAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "73bbf857-246b-46e3-a124-4812cb4a2dfe",
      "metadata": {
        "id": "73bbf857-246b-46e3-a124-4812cb4a2dfe"
      },
      "outputs": [],
      "source": [
        "#copyright joshuah.rainstar@gmail.com 2025\n",
        "#MIT with attribution\n",
        "#it came to us in a whisper on the wind\n",
        "#the parseval theorem must be applied to attention\n",
        "#that this works at all we attribute to divine benevolence\n",
        "#may our works glorify our father\n",
        "import math\n",
        "import copy\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, List\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# ----------------------------\n",
        "# Layers\n",
        "# ----------------------------\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, ndim: int, bias: bool = True):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(ndim))\n",
        "        self.use_bias = bias\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(ndim))\n",
        "        else:\n",
        "            self.register_parameter(\"bias\", None)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        b =self.bias if self.use_bias else None\n",
        "        return F.layer_norm(x, self.weight.shape, self.weight, b, 1e-5)\n",
        "\n",
        "def variance_scaled_softmax(scores, dim: int = -1, eps: float = 1e-6):\n",
        "    # scores may contain -inf from masking\n",
        "    finite = torch.isfinite(scores)\n",
        "    m = finite.to(scores.dtype)                     # 1 where valid, 0 where masked\n",
        "    n = m.sum(dim=dim, keepdim=True).clamp_min(1)  # count of valid entries per row\n",
        "\n",
        "    # mean/var over valid entries only (population var)\n",
        "    safe_scores = torch.where(finite, scores, torch.zeros_like(scores))\n",
        "    mean = (safe_scores * m).sum(dim=dim, keepdim=True) / n\n",
        "    var  = ((safe_scores - mean)**2 * m).sum(dim=dim, keepdim=True) / n\n",
        "    std  = var.clamp_min(eps).sqrt()\n",
        "\n",
        "    scaled = (safe_scores - mean) / std\n",
        "    scaled = torch.where(finite, scaled, float('-inf'))  # restore mask\n",
        "    out = torch.softmax(scaled, dim=dim)\n",
        "    out = torch.where(n == 0, torch.zeros_like(out), out)  # fully-masked rows -> zeros\n",
        "    return out\n",
        "\n",
        "class ParsevalRotaryEmbedding(nn.Module):\n",
        "    def __init__(self, dim: int, max_seq_len: int = 2048, theta_base: float = 10000.0):\n",
        "        \"\"\"\n",
        "        dim: embedding dimension (must be even).\n",
        "        max_seq_len: maximum sequence length for which to precompute sines/cosines.\n",
        "        theta_base: base for frequency schedule (as in RoPE).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert dim % 2 == 0, \"dim must be even for pairing\"\n",
        "        self.dim = dim\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # compute frequency for each pair\n",
        "        half = dim // 2\n",
        "        inv_freq = 1.0 / (theta_base ** (torch.arange(0, half, 1, dtype=torch.float32) / half))\n",
        "\n",
        "        # position indices\n",
        "        pos = torch.arange(max_seq_len, dtype=torch.float32).unsqueeze(1)  # (max_seq_len,1)\n",
        "        # angles (max_seq_len x half) = pos * inv_freq\n",
        "        angles = pos * inv_freq.unsqueeze(0)  # broadcast\n",
        "        # compute cos and sin matrices for each pos and each half-dim\n",
        "        self.register_buffer(\"cos\", angles.cos().unsqueeze(0).unsqueeze(0))  # (1,1,max_seq_len,half)\n",
        "        self.register_buffer(\"sin\", angles.sin().unsqueeze(0).unsqueeze(0))\n",
        "\n",
        "    def forward(self, x: torch.Tensor, seq_pos: torch.Tensor):\n",
        "        \"\"\"\n",
        "        x: shape (B, H, T, D) or (B, T, H, D)\n",
        "        seq_pos: tensor of positions indices shape (T,) or (B,T)\n",
        "        Returns: same shape x but positionally encoded via orthogonal rotations.\n",
        "        \"\"\"\n",
        "        # assume shape (B, H, T, D)\n",
        "        B, H, T, D = x.shape\n",
        "        half = D // 2\n",
        "        # get cos/sin for positions\n",
        "        # pos angles shape (1,1,T,half)\n",
        "        cos_t = self.cos[:, :, seq_pos, :]  # broadcast\n",
        "        sin_t = self.sin[:, :, seq_pos, :]\n",
        "\n",
        "        x1 = x[..., :half]\n",
        "        x2 = x[..., half:]\n",
        "\n",
        "        # apply rotation: [x1'; x2'] = [x1*cos - x2*sin, x1*sin + x2*cos]\n",
        "        x1_rot = x1 * cos_t - x2 * sin_t\n",
        "        x2_rot = x1 * sin_t + x2 * cos_t\n",
        "\n",
        "        x_rot = torch.cat([x1_rot, x2_rot], dim=-1)\n",
        "        return x_rot\n",
        "\n",
        "\n",
        "\n",
        "def l2_normalize(x, dim=-1, eps=1e-8):\n",
        "    return x / (x.norm(dim=dim, keepdim=True) + eps)\n",
        "\n",
        "def build_haar_wavelet_basis(T, levels, device=None, dtype=torch.float32):\n",
        "    \"\"\"\n",
        "    Build a Haar‚Äêwavelet basis matrix W of shape (T, Bcoef).\n",
        "    T: sequence length (must be divisible by 2^levels for full structure, but we will allow slicing).\n",
        "    levels: number of levels of decomposition.\n",
        "    \"\"\"\n",
        "    W_list = []\n",
        "    for j in range(levels):\n",
        "        block_count = 2**j\n",
        "        block_size = T // block_count\n",
        "        half = block_size // 2\n",
        "        for k in range(block_count):\n",
        "            vec = torch.zeros(T, dtype=dtype, device=device)\n",
        "            start = k * block_size\n",
        "            mid   = start + half\n",
        "            end   = start + block_size\n",
        "            if half > 0:\n",
        "                vec[start:mid] =  1.0 / math.sqrt(half)\n",
        "                vec[mid:end]  = -1.0 / math.sqrt(half)\n",
        "            W_list.append(vec)\n",
        "    W = torch.stack(W_list, dim=1)  # shape (T, Bcoef)\n",
        "    return W\n",
        "\n",
        "class WaveletAttention(nn.Module):\n",
        "    def __init__(self, config, wavelet_levels=3, near_window=64):\n",
        "        super().__init__()\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.head_dim = self.n_embd // 4\n",
        "\n",
        "        H, Dh = self.n_head, self.head_dim\n",
        "\n",
        "        self.W_Q = nn.Parameter(torch.empty(H * Dh, self.n_embd))\n",
        "        nn.init.xavier_uniform_(self.W_Q)\n",
        "\n",
        "        self.near_window = near_window\n",
        "        self.wavelet_levels = wavelet_levels\n",
        "        self.block_size = config.block_size\n",
        "\n",
        "        # Build maximum‚Äêsize Haar basis once on CPU and register buffer.\n",
        "        W_haar_full = build_haar_wavelet_basis(self.block_size,\n",
        "                                                self.wavelet_levels,\n",
        "                                                device='cpu')\n",
        "        self.register_buffer(\"W_haar_full\", W_haar_full)\n",
        "\n",
        "        # Causal mask\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                 .view(1, 1, config.block_size, config.block_size)\n",
        "        )\n",
        "        self.pos_encoder = ParsevalRotaryEmbedding(dim=Dh, max_seq_len=config.block_size)\n",
        "\n",
        "    def compute_dual_WK(self):\n",
        "        WQ = self.W_Q                          # (H*Dh, C)\n",
        "        WQ_star = WQ.conj().T                  # (C, H*Dh)\n",
        "        Qmat, Rmat = torch.linalg.qr(WQ_star)  # (C, H*Dh) = Q R\n",
        "        R_inv = torch.inverse(Rmat)\n",
        "        WK = R_inv @ Qmat.conj().T             # (H*Dh, C)\n",
        "        return WK\n",
        "\n",
        "    def forward(self, x ):\n",
        "        B, T, C = x.size()\n",
        "        H, Dh = self.n_head, self.head_dim\n",
        "\n",
        "        W_K = self.compute_dual_WK()          # (H*Dh, C)\n",
        "\n",
        "        q = (x @ self.W_Q.T).view(B, T, H, Dh).transpose(1, 2)\n",
        "        k = (x @ W_K.T).view(B, T, H, Dh).transpose(1, 2)\n",
        "        idx = torch.arange(T, device=x.device)\n",
        "        q = self.pos_encoder(q, idx)\n",
        "        k = self.pos_encoder(k, idx)\n",
        "\n",
        "        q = l2_normalize(q, dim=-1)\n",
        "        k = l2_normalize(k, dim=-1)\n",
        "\n",
        "        # Build near‚Äêfield mask\n",
        "        idx = torch.arange(T, device=x.device)\n",
        "        near_mask = (idx.view(1,-1) - idx.view(-1,1)).abs() <= self.near_window\n",
        "\n",
        "        # Compute near‚Äêfield attention\n",
        "        att_near = (q @ k.transpose(-2,-1)) * (1.0 / math.sqrt(Dh))\n",
        "        att_near = att_near.masked_fill(~near_mask.view(1,1,T,T), float('-inf'))\n",
        "\n",
        "        # Prepare Haar basis for current T\n",
        "        W_h_full = self.W_haar_full.to(x.device)       # (block_size, Bcoef_full)\n",
        "        W_h = W_h_full[:T, :]                           # slice to (T, Bcoef_full)\n",
        "\n",
        "        # Project far‚Äêfield q/k through basis\n",
        "        q2 = q.reshape(B*H, T, Dh)\n",
        "        k2 = k.reshape(B*H, T, Dh)\n",
        "\n",
        "        # Compute projection\n",
        "        # W_h.T: (Bcoef_full, T)\n",
        "        # q2:   (B*H, T, Dh)\n",
        "        # -> result: (B*H, Bcoef_full, Dh)\n",
        "        q_far_proj = (W_h.T @ q2)                     # (B*H, Bcoef_full, Dh)\n",
        "        k_far_proj = (W_h.T @ k2)                     # same shape\n",
        "\n",
        "        # Compute far‚Äêfield attention in compressed domain\n",
        "        att_far_comp = (q_far_proj @ k_far_proj.transpose(-2,-1)) * (1.0 / math.sqrt(Dh))\n",
        "        # att_far_comp shape: (B*H, Bcoef_full, Bcoef_full)\n",
        "\n",
        "        # Expand back to approximate full (T, T)\n",
        "        # W_h: (T, Bcoef_full)\n",
        "        att_far_exp = (W_h @ att_far_comp) @ W_h.T     # (T, Bcoef_full) @ (Bcoef_full, Bcoef_full) @ (Bcoef_full, T)\n",
        "        att_far_exp = att_far_exp.view(B, H, T, T)\n",
        "\n",
        "        # Combine near + far\n",
        "        att = torch.where(near_mask.view(1,1,T,T), att_near, att_far_exp)\n",
        "\n",
        "        # Causal mask\n",
        "        att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float('-inf'))\n",
        "\n",
        "        att = variance_scaled_softmax(att, dim=-1)\n",
        "\n",
        "        return att\n",
        "\n",
        "class Forwarding(nn.Module):\n",
        "    def __init__(self, config, wavelet_levels=3, near_window=64):\n",
        "        super().__init__()\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "\n",
        "        self.W_V = nn.Linear(self.n_embd, self.n_embd//4, bias=False)\n",
        "        self.W_O = nn.Linear(self.n_embd//4, self.n_embd, bias=False)\n",
        "\n",
        "    def forward(self, x ,scores):\n",
        "        B, T, C = x.size()\n",
        "\n",
        "        v = self.W_V(x).view(B, T, 1,self.n_embd//4).transpose(1, 2)\n",
        "\n",
        "        y = scores @ v     # (B, H, T, Dh)\n",
        "        y = y.transpose(1,2).contiguous().view(B, T, self.n_embd//4)\n",
        "        return self.W_O(y)\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Transformer Block\n",
        "# ----------------------------\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc    = nn.Linear( config.n_embd,4* config.n_embd, bias=config.bias)\n",
        "        self.scale = math.pi / math.sqrt(3.0)\n",
        "\n",
        "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = x * torch.sigmoid(self.scale * x)\n",
        "        x = self.c_proj(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.attn = WaveletAttention(config)\n",
        "\n",
        "        self.mlp = MLP(config)\n",
        "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "\n",
        "        self.l = nn.ModuleList([LayerNorm(config.n_embd, bias=config.bias) for _ in range(config.n_pickles)])\n",
        "        self.att = nn.ModuleList([Forwarding(config) for _ in range(config.n_pickles)])\n",
        "        self.mlps = nn.ModuleList([MLP(config) for _ in range(config.n_pickles)])\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "\n",
        "        '''\n",
        "        lol! doesnt trrain. past 1.8. so? we do what?\n",
        "        scores = self.attn(self.ln_1(x))\n",
        "        p = self.mlp(self.ln_2(x))\n",
        "        for a, m ,ln in zip(self.att,self.mlps,self.l):\n",
        "            p = a(ln(p),scores)\n",
        "            x = x + m(p)\n",
        "            '''\n",
        "        scores = self.attn(self.ln_1(x))\n",
        "        for a, m ,ln in zip(self.att,self.mlps,self.l):\n",
        "            p = a(m(ln(x)),scores)\n",
        "            x = x + p\n",
        "        # residual update\n",
        "        # standard MLP block\n",
        "        return x\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int = 1024\n",
        "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
        "    n_layer: int = 12\n",
        "    n_head: int = 12\n",
        "    n_pickles: int = 12\n",
        "    n_embd: int = 768\n",
        "    dropout: float = 0.0\n",
        "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.vocab_size is not None\n",
        "        assert config.block_size is not None\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            drop = nn.Dropout(config.dropout),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
        "        ))\n",
        "\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        # with weight tying when using torch.compile() some warnings get generated:\n",
        "        # \"UserWarning: functional_call was passed multiple values for tied weights.\n",
        "        # This behavior is deprecated and will be an error in future versions\"\n",
        "        # not 100% sure what this is, so far seems to be harmless. TODO investigate\n",
        "        # init all weights\n",
        "        self.apply(self._init_weights)\n",
        "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
        "\n",
        "        # report number of parameters\n",
        "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
        "\n",
        "    def get_num_params(self, non_embedding=True):\n",
        "        \"\"\"\n",
        "        Return the number of parameters in the model.\n",
        "        For non-embedding count (default), the position embeddings get subtracted.\n",
        "        The token embeddings would too, except due to the parameter sharing these\n",
        "        params are actually used as weights in the final layer, so we include them.\n",
        "        \"\"\"\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        return n_params\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, T = idx.size()\n",
        "\n",
        "        # forward the GPT model itself\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
        "        x = tok_emb\n",
        "\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            # if we are given some desired targets also calculate the loss\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "        else:\n",
        "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
        "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
        "            loss = None\n",
        "\n",
        "        return logits, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cc40ec9f-1475-4836-a1e7-ee97b37adad9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc40ec9f-1475-4836-a1e7-ee97b37adad9",
        "outputId": "57b2be6a-8789-4a4b-83c7-a264fe26aa97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Downloading aochildes.txt...\n",
            "üì• Downloading cbt.txt...\n",
            "üì• Downloading children_stories.txt...\n",
            "üì• Downloading gutenberg.txt...\n",
            "üì• Downloading qed.txt...\n",
            "üì• Downloading simple_wikipedia.txt...\n",
            "üì• Downloading switchboard.txt...\n",
            "üì• Downloading wikipedia.txt...\n",
            "üì• Downloading shakespeare.txt...\n",
            "‚úÖ Done. Files saved to ./babylm_10m_cleaned\n"
          ]
        }
      ],
      "source": [
        "import requests, os\n",
        "\n",
        "base_url = \"https://huggingface.co/datasets/cambridge-climb/BabyLM/resolve/main/clean/10M/\"\n",
        "target_dir = \"./babylm_10m_cleaned\"\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "file_names = [\n",
        "    \"aochildes.txt\",\n",
        "    \"cbt.txt\",\n",
        "    \"children_stories.txt\",\n",
        "    \"gutenberg.txt\",\n",
        "    \"qed.txt\",\n",
        "    \"simple_wikipedia.txt\",\n",
        "    \"switchboard.txt\",\n",
        "    \"wikipedia.txt\"\n",
        "]\n",
        "\n",
        "# Optional addition: Shakespeare from another dataset\n",
        "shakespeare_url = \"https://drive.google.com/uc?export=download&id=1_aiQyJTgcCBq26QssgIWHZFx_eVzm8uz\"\n",
        "shakespeare_fname = \"shakespeare.txt\"\n",
        "\n",
        "# Combined download logic\n",
        "all_files = [(base_url + fname, fname) for fname in file_names]\n",
        "all_files.append((shakespeare_url, shakespeare_fname))  # Add Shakespeare\n",
        "\n",
        "\n",
        "# Download loop\n",
        "for url, fname in all_files:\n",
        "    out_path = os.path.join(target_dir, fname)\n",
        "    print(f\"üì• Downloading {fname}...\")\n",
        "    resp = requests.get(url)\n",
        "    if resp.status_code == 200:\n",
        "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(resp.text)\n",
        "    else:\n",
        "        print(f\"‚ùå Failed to download {fname} ({resp.status_code})\")\n",
        "\n",
        "print(f\"‚úÖ Done. Files saved to {target_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9648818a-ba26-4737-9a20-0da0bd3090db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9648818a-ba26-4737-9a20-0da0bd3090db",
        "outputId": "b80213fe-ae68-4960-f665-7624b03b3516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Char tokenizer finalized.\n",
            "üßæ Train tokens: 1016242 | Val tokens: 99152\n",
            "üî§ Vocab size: 66\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# === Paths ===\n",
        "source_dir = \"./babylm_10m_cleaned\"\n",
        "out_dir    = \"./babylm_char_tokenized\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "file_names = [\n",
        "    \"shakespeare.txt\"#,\"aochildes.txt\", \"cbt.txt\", \"children_stories.txt\", \"gutenberg.txt\",\n",
        "    #\"qed.txt\", \"simple_wikipedia.txt\", \"switchboard.txt\", \"wikipedia.txt\"\n",
        "]\n",
        "\n",
        "# === Load and split ===\n",
        "train_texts, val_texts = [], []\n",
        "char_set = set()\n",
        "\n",
        "for fname in file_names:\n",
        "    with open(os.path.join(source_dir, fname), encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()\n",
        "        n = len(lines)\n",
        "        split = int(0.9 * n)\n",
        "        train_part = \"\".join(lines[:split])\n",
        "        val_part   = \"\".join(lines[split:])\n",
        "        train_texts.append(train_part)\n",
        "        val_texts.append(val_part)\n",
        "        char_set.update(train_part)\n",
        "        char_set.update(val_part)\n",
        "\n",
        "full_train = \"\\n\".join(train_texts)\n",
        "full_val   = \"\\n\".join(val_texts)\n",
        "\n",
        "# === Final vocab ===\n",
        "char_set = sorted(set(char_set))\n",
        "vocab_chars = [\"<unk>\"] + [c for c in char_set if c != \"<unk>\"]\n",
        "\n",
        "stoi = {ch: i for i, ch in enumerate(vocab_chars)}\n",
        "itos = {i: ch for ch, i in stoi.items()}\n",
        "\n",
        "# === Encode function ===\n",
        "def encode(text):\n",
        "    return [stoi.get(c, 0) for c in text]\n",
        "\n",
        "train_ids = np.array(encode(full_train), dtype=np.uint16)\n",
        "val_ids   = np.array(encode(full_val),   dtype=np.uint16)\n",
        "\n",
        "# === Save ===\n",
        "train_ids.tofile(os.path.join(out_dir, \"train.bin\"))\n",
        "val_ids.tofile(os.path.join(out_dir, \"val.bin\"))\n",
        "\n",
        "with open(os.path.join(out_dir, \"meta.pkl\"), \"wb\") as f:\n",
        "    pickle.dump({\n",
        "        \"vocab_size\": len(stoi),\n",
        "        \"stoi\": stoi,\n",
        "        \"itos\": itos\n",
        "    }, f)\n",
        "\n",
        "print(f\"‚úÖ Char tokenizer finalized.\")\n",
        "print(f\"üßæ Train tokens: {len(train_ids)} | Val tokens: {len(val_ids)}\")\n",
        "print(f\"üî§ Vocab size: {len(stoi)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "70cb41e0-48cb-4b78-811e-8bde12e7abfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70cb41e0-48cb-4b78-811e-8bde12e7abfa",
        "outputId": "9061f4f7-b1de-4506-ef28-9fc5aa5b2a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 2.80M\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# === Config ===\n",
        "data_dir = \"./babylm_char_tokenized\"  # <- char-tokenized data\n",
        "block_size = 1024\n",
        "batch_size = 16\n",
        "\n",
        "# === Load tokenizer metadata ===\n",
        "with open(os.path.join(data_dir, 'meta.pkl'), 'rb') as f:\n",
        "    meta = pickle.load(f)\n",
        "vocab_size = meta['vocab_size']\n",
        "\n",
        "# === Load mmap edata (char-level tokens, uint16) ===\n",
        "train_ids = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n",
        "val_ids   = np.memmap(os.path.join(data_dir, 'val.bin'),   dtype=np.uint16, mode='r')\n",
        "\n",
        "# === Efficient GPU Batch Sampler ===\n",
        "class GPUBatchDataset(Dataset):\n",
        "    def __init__(self, mmap_file, block_size, batch_size, device, jitter=63, p_aligned=0.5, pad_len=0):\n",
        "        self.data = mmap_file\n",
        "        self.block_size = block_size\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device\n",
        "        self.pad_len = int(pad_len)\n",
        "        self.sample_len = self.block_size + self.pad_len  # X length\n",
        "        self.total = len(self.data) - self.sample_len - 1\n",
        "        self.n_blocks = self.total // self.sample_len\n",
        "        self.jitter = int(jitter)          # small random offset added to aligned start\n",
        "        self.p_aligned = float(p_aligned)  # mix aligned and jittered\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = np.empty((self.batch_size, self.sample_len), dtype=np.int64)\n",
        "        Y = np.empty((self.batch_size, self.block_size), dtype=np.int64)\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            # choose a base aligned block\n",
        "            base_block = np.random.randint(0, self.n_blocks)\n",
        "            start = base_block * self.sample_len\n",
        "\n",
        "            # with probability, add a small jitter (keeps cache-friendly contiguous reads)\n",
        "            if np.random.rand() > self.p_aligned:\n",
        "                j = np.random.randint(0, self.jitter + 1)\n",
        "                start = min(start + j, self.total)  # stay in range\n",
        "\n",
        "            X[i] = self.data[start : start + self.sample_len]\n",
        "            # targets correspond to the final block_size visible steps\n",
        "            Y[i] = self.data[start + 1 + self.pad_len : start + 1 + self.pad_len + self.block_size]\n",
        "\n",
        "\n",
        "        return (\n",
        "            torch.from_numpy(X).to(self.device, non_blocking=True),\n",
        "            torch.from_numpy(Y).to(self.device, non_blocking=True)\n",
        "        )\n",
        "\n",
        "\n",
        "config = GPTConfig(\n",
        "    vocab_size=len(stoi),\n",
        "    n_layer=4,\n",
        "    n_embd=128,\n",
        "    n_pickles = 4,\n",
        "    n_head = 1,\n",
        "\n",
        "    block_size=block_size,\n",
        ")\n",
        "train_dataset = GPUBatchDataset(train_ids, block_size, batch_size, device, pad_len=0)\n",
        "# === DataLoader ===\n",
        "train_loader  = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
        "model = GPT(config)\n",
        "model= torch.compile(model)\n",
        "model = model.to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "25f0ccf0-9d48-4e0f-8908-c94adf497969",
      "metadata": {
        "scrolled": true,
        "id": "25f0ccf0-9d48-4e0f-8908-c94adf497969"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
        "losses = []\n",
        "def train_epoch():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for xb, yb in train_loader:\n",
        "          xb, yb = xb[0], yb[0]  # unwrap batch dimension\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          logits, loss = model(xb, yb)\n",
        "          loss.backward()\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "          losses.append(loss.item())\n",
        "          print(loss.item())\n",
        "    return total_loss / len(train_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import io\n",
        "import math\n",
        "import time\n",
        "\n",
        "class MatrixDashboard:\n",
        "    def __init__(self, batch_size, seq_len, itos=None):\n",
        "        \"\"\"\n",
        "        High-Performance Dashboard (PIL + ipywidgets).\n",
        "        Features:\n",
        "        - 'Life' animation (fading/persistence)\n",
        "        - Color-coded confidence (Green=Correct, Orange=Incorrect)\n",
        "        - Fallback to Target glyph if Prediction is OOV.\n",
        "        \"\"\"\n",
        "        self.target_cells = batch_size * seq_len\n",
        "        self.itos_map = itos if itos is not None else {}\n",
        "\n",
        "        # --- 1. Geometry & Font Setup ---\n",
        "        # Cinematic aspect ratio logic (approx 2.5:1)\n",
        "        self.rows = int(math.sqrt(self.target_cells / 5))\n",
        "        self.cols = int(np.ceil(self.target_cells / self.rows))\n",
        "        self.n_cells = self.rows * self.cols\n",
        "\n",
        "        # Visual constants\n",
        "        self.cell_w = 10  # pixel width per char\n",
        "        self.cell_h = 16  # pixel height per char\n",
        "        self.width = self.cols * self.cell_w\n",
        "        self.height = self.rows * self.cell_h + 40 # +40 for stats bar\n",
        "\n",
        "        # Load Font (Robust Fallback)\n",
        "        try:\n",
        "            self.font = ImageFont.truetype(\"DejaVuSansMono.ttf\", 11)\n",
        "        except:\n",
        "            try:\n",
        "                self.font = ImageFont.truetype(\"Courier New.ttf\", 11)\n",
        "            except:\n",
        "                self.font = ImageFont.load_default()\n",
        "\n",
        "        # --- 2. Decoder ---\n",
        "        if itos is not None:\n",
        "            def safe_decode(x):\n",
        "                c = itos.get(x, \"?\")\n",
        "                if c == \"\\n\": return \"¬∂\"\n",
        "                if c == \"\\t\": return \"‚Üí\"\n",
        "                if c == \" \": return \"¬∑\"\n",
        "                return c\n",
        "            self.decode = safe_decode\n",
        "        else:\n",
        "            self.decode = lambda x: chr(x) if 32 <= x <= 126 else \"?\"\n",
        "\n",
        "        # --- 3. Simulation State ---\n",
        "        self.display_chars = [\"¬∑\"] * self.n_cells\n",
        "        self.display_colors = [(40, 40, 40)] * self.n_cells\n",
        "        self.freshness = np.zeros(self.n_cells, dtype=np.float32)\n",
        "        self.ewma_loss = None\n",
        "        self.step = 0\n",
        "\n",
        "        # --- 4. Widget Setup ---\n",
        "        self.out_widget = widgets.Image(format='png', width=self.width, height=self.height)\n",
        "        self.layout = widgets.VBox([self.out_widget])\n",
        "\n",
        "    def render(self):\n",
        "        \"\"\"Display the widget in the notebook.\"\"\"\n",
        "        display(self.layout)\n",
        "\n",
        "    def update(self, yb, logits, loss_val):\n",
        "        \"\"\"\n",
        "        Update grid.\n",
        "        Logic:\n",
        "        - If Predicted Token is NOT in itos, display Target Token.\n",
        "        - Colors: Green (Correct), Orange (Incorrect).\n",
        "        \"\"\"\n",
        "        self.step += 1\n",
        "\n",
        "        # --- 1. Tensor Ops ---\n",
        "        with torch.no_grad():\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            p_max, preds = torch.max(probs, dim=-1)\n",
        "\n",
        "            p_max = p_max.cpu().numpy().flatten()\n",
        "            preds = preds.cpu().numpy().flatten()\n",
        "            targets = yb.cpu().numpy().flatten()\n",
        "\n",
        "        # Limit to grid size\n",
        "        limit = min(len(p_max), self.n_cells)\n",
        "\n",
        "        # --- 2. Life/Freshness Simulation ---\n",
        "        is_correct = (preds[:limit] == targets[:limit]).astype(np.float32)\n",
        "        self.freshness *= 0.92 # Decay global freshness\n",
        "\n",
        "        # Update Rule: Update if New Confidence > Old Freshness OR Old Freshness < 0.10 (faded)\n",
        "        current_freshness = self.freshness[:limit]\n",
        "        update_mask = (p_max[:limit] > current_freshness) | (current_freshness < 0.10)\n",
        "\n",
        "        # Apply updates to freshness buffer\n",
        "        self.freshness[:limit] = np.where(update_mask, p_max[:limit], current_freshness)\n",
        "\n",
        "        # --- 3. Color Calculation (Vectorized) ---\n",
        "        # Only calculate for updated cells\n",
        "        update_indices = np.where(update_mask)[0]\n",
        "\n",
        "        if len(update_indices) > 0:\n",
        "            # Get subset of values\n",
        "            vals = p_max[:limit][update_indices] * 255.0\n",
        "            vals = np.maximum(50.0, vals) # Minimum brightness so nothing is invisible\n",
        "            corrects = is_correct[update_indices]\n",
        "\n",
        "            # RGB Logic\n",
        "            # Correct (Greenish): R=0.5v, G=1.0v, B=0.25v\n",
        "            # Incorrect (Orange): R=1.0v, G=0.5v, B=0.0v\n",
        "            r = (corrects * (vals * 0.5) + (1 - corrects) * vals).astype(np.int32)\n",
        "            g = (corrects * vals + (1 - corrects) * (vals * 0.5)).astype(np.int32)\n",
        "            b = (corrects * (vals * 0.25)).astype(np.int32)\n",
        "\n",
        "            # --- 4. Update State Lists (The Loop) ---\n",
        "            # We iterate only the changed indices\n",
        "            for i, idx in enumerate(update_indices):\n",
        "                token_id = preds[idx]\n",
        "                target_id = targets[idx]\n",
        "\n",
        "                # PATCH: Fallback to Target if Prediction is OOV\n",
        "                if self.itos_map and (token_id not in self.itos_map):\n",
        "                    token_id = target_id\n",
        "\n",
        "                self.display_chars[idx] = self.decode(token_id)\n",
        "                self.display_colors[idx] = (r[i], g[i], b[i])\n",
        "\n",
        "        # --- 5. Rendering (PIL) ---\n",
        "        img = Image.new(\"RGB\", (self.width, self.height), (10, 10, 10))\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        # Optimization: Local variable references for loop speed\n",
        "        d_text = draw.text\n",
        "        fnt = self.font\n",
        "        cw, ch = self.cell_w, self.cell_h\n",
        "        cols = self.cols\n",
        "        chars = self.display_chars\n",
        "        colors = self.display_colors\n",
        "\n",
        "        for i in range(self.n_cells):\n",
        "            y_row = i // cols\n",
        "            x_col = i % cols\n",
        "\n",
        "            px = x_col * cw\n",
        "            py = y_row * ch + 40 # Offset for stats bar\n",
        "\n",
        "            d_text((px, py), chars[i], font=fnt, fill=colors[i])\n",
        "\n",
        "        # --- 6. Stats Bar ---\n",
        "        if self.ewma_loss is None: self.ewma_loss = loss_val\n",
        "        else: self.ewma_loss = 0.95 * self.ewma_loss + 0.05 * loss_val\n",
        "\n",
        "        acc = np.mean(is_correct)\n",
        "\n",
        "        # Stats Background\n",
        "        draw.rectangle([0, 0, self.width, 35], fill=(20, 20, 20))\n",
        "\n",
        "        # Stats Text\n",
        "        draw.text((10, 10), f\"STEP: {self.step}\", font=fnt, fill=(200, 200, 200))\n",
        "        draw.text((100, 10), f\"LOSS: {loss_val:.4f}\", font=fnt, fill=(255, 100, 100))\n",
        "        draw.text((220, 10), f\"EWMA: {self.ewma_loss:.4f}\", font=fnt, fill=(255, 255, 0))\n",
        "        draw.text((340, 10), f\"ACC: {acc:.1%}\", font=fnt, fill=(0, 255, 0))\n",
        "\n",
        "        # --- 7. Push to Widget ---\n",
        "        with io.BytesIO() as output:\n",
        "            img.save(output, format=\"PNG\")\n",
        "            self.out_widget.value = output.getvalue()\n",
        "\n",
        "# Usage\n",
        "#dashboard = MatrixDashboard(batch_size, block_size, itos=itos)\n",
        "#dashboard.render()\n",
        "#dashboard.update(yb, logits, loss.item())\n"
      ],
      "metadata": {
        "id": "hpJ-yb4P4sCe"
      },
      "id": "hpJ-yb4P4sCe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   https://youtu.be/MnA4ZpA0IC4\n",
        "*   https://www.youtube.com/watch?v=rWfqjmd7NaA\n",
        "*   https://youtu.be/09X7yzffmME\n",
        "*   https://www.youtube.com/watch?v=6HNiJQKRiWg\n",
        "\n",
        "to listen while you train"
      ],
      "metadata": {
        "id": "8noLSyVFBppW"
      },
      "id": "8noLSyVFBppW"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Run Training ===\n",
        "num_epochs = 10\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss = train_epoch()\n",
        "    print(f\"Epoch {epoch:2d} | Train loss: {train_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "DwnSFzKVrlBZ",
        "outputId": "d7cb05e4-31f3-4f57-ec43-408702dd1b7e"
      },
      "id": "DwnSFzKVrlBZ",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0369879007339478\n",
            "1.0019738674163818\n",
            "1.0470871925354004\n",
            "1.0616666078567505\n",
            "0.9964464902877808\n",
            "1.0174907445907593\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3658595611.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch:2d} | Train loss: {train_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-174321277.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m           \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m           \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "771f480f-211b-4f34-94dd-375d31a44a18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "771f480f-211b-4f34-94dd-375d31a44a18",
        "outputId": "0985dd00-10c5-4c03-bff3-ff648eb641b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAia1JREFUeJzs3XdYFNfbxvF7aUsHFQV7772LscauKabHmERTzC/G9G6qppneE9Nj4htTTNQUNYqFGHvv3ahYACtdYIF5/0AWVroCs8D3c11e2Zk5M/ssBwyP55znWAzDMAQAAAAAyJeL2QEAAAAAgLMjcQIAAACAQpA4AQAAAEAhSJwAAAAAoBAkTgAAAABQCBInAAAAACgEiRMAAAAAFILECQAAAAAKQeIEAAAAAIUgcQKACmbs2LFq0KDBRd07adIkWSyWkg0IAIAKgMQJAMqIxWIp0p/w8HCzQzXF2LFj5evra3YYFcq2bdt0/fXXq379+vL09FTt2rU1aNAgffTRRw7tXnvtNc2ZM8ecIAGgnLAYhmGYHQQAVAb/93//53D8/fffKywsTNOnT3c4P2jQIAUHB1/0+9hsNmVkZMhqtRb73rS0NKWlpcnT0/Oi3/9ijR07Vr/++qsSEhLK/L0ropUrV6p///6qV6+exowZo5CQEB05ckSrV6/WgQMHtH//fntbX19fXX/99Zo2bZp5AQOAk3MzOwAAqCxuvfVWh+PVq1crLCws1/kLJSUlydvbu8jv4+7uflHxSZKbm5vc3PhfQ3mRmJgoHx+fPK+9+uqrCggI0Lp16xQYGOhw7cSJE2UQHQBULEzVAwAn0q9fP7Vp00YbNmxQnz595O3trWeeeUaS9Pvvv2vEiBGqVauWrFarGjdurJdfflnp6ekOz7hwjdOhQ4dksVj09ttv64svvlDjxo1ltVrVtWtXrVu3zuHevNY4WSwW3X///ZozZ47atGkjq9Wq1q1b6++//84Vf3h4uLp06SJPT081btxYn3/+eYmvm5o5c6Y6d+4sLy8vBQUF6dZbb9WxY8cc2kRFRemOO+5QnTp1ZLVaVbNmTV199dU6dOiQvc369es1ZMgQBQUFycvLSw0bNtSdd95ZpBg+/fRTtW7dWlarVbVq1dKECRMUExNjv37//ffL19dXSUlJue4dNWqUQkJCHPpt/vz56t27t3x8fOTn56cRI0Zox44dDvdlTWU8cOCAhg8fLj8/P40ePTrfGA8cOKDWrVvnSpokqUaNGvbXFotFiYmJ+u677+zTRceOHWu/fuzYMd15550KDg629/0333zj8Lzw8HBZLBb9/PPPeuaZZxQSEiIfHx9dddVVOnLkiEPbffv26brrrlNISIg8PT1Vp04d3XzzzYqNjc33swCAM+CfFQHAyZw+fVrDhg3TzTffrFtvvdU+bW/atGny9fXVo48+Kl9fXy1ZskQvvPCC4uLi9NZbbxX63BkzZig+Pl7/+9//ZLFY9Oabb+raa6/Vf//9V+go1fLlyzVr1izdd9998vPz04cffqjrrrtOERERqlatmiRp06ZNGjp0qGrWrKnJkycrPT1dL730kqpXr37pX5Tzpk2bpjvuuENdu3bVlClTFB0drQ8++EArVqzQpk2b7EnCddddpx07duiBBx5QgwYNdOLECYWFhSkiIsJ+PHjwYFWvXl1PP/20AgMDdejQIc2aNavQGCZNmqTJkydr4MCBGj9+vPbs2aOpU6dq3bp1WrFihdzd3XXTTTfpk08+0dy5c3XDDTfY701KStKff/6psWPHytXVVZI0ffp0jRkzRkOGDNEbb7yhpKQkTZ06Vb169dKmTZsckuC0tDQNGTJEvXr10ttvv13gSGT9+vW1atUqbd++XW3atMm33fTp03X33XerW7duuueeeyRJjRs3liRFR0erR48e9uS5evXqmj9/vu666y7FxcXp4YcfdnjWq6++KovFoqeeekonTpzQ+++/r4EDB2rz5s3y8vJSamqqhgwZopSUFD3wwAMKCQnRsWPH9NdffykmJkYBAQGFfv0BwDQGAMAUEyZMMC78a7hv376GJOOzzz7L1T4pKSnXuf/973+Gt7e3kZycbD83ZswYo379+vbjgwcPGpKMatWqGWfOnLGf//333w1Jxp9//mk/9+KLL+aKSZLh4eFh7N+/335uy5YthiTjo48+sp+78sorDW9vb+PYsWP2c/v27TPc3NxyPTMvY8aMMXx8fPK9npqaatSoUcNo06aNce7cOfv5v/76y5BkvPDCC4ZhGMbZs2cNScZbb72V77Nmz55tSDLWrVtXaFw5nThxwvDw8DAGDx5spKen289//PHHhiTjm2++MQzDMDIyMozatWsb1113ncP9v/zyiyHJWLZsmWEYhhEfH28EBgYa48aNc2gXFRVlBAQEOJwfM2aMIcl4+umnixTrwoULDVdXV8PV1dUIDQ01nnzySWPBggVGampqrrY+Pj7GmDFjcp2/6667jJo1axqnTp1yOH/zzTcbAQEB9u/JpUuXGpKM2rVrG3Fxcbk+7wcffGAYhmFs2rTJkGTMnDmzSJ8BAJwJU/UAwMlYrVbdcccduc57eXnZX8fHx+vUqVPq3bu3kpKStHv37kKfe9NNN6lKlSr24969e0uS/vvvv0LvHThwoH0UQpLatWsnf39/+73p6elatGiRRo4cqVq1atnbNWnSRMOGDSv0+UWxfv16nThxQvfdd59D8YoRI0aoRYsWmjt3rqTMr5OHh4fCw8N19uzZPJ+VNTL1119/yWazFTmGRYsWKTU1VQ8//LBcXLL/Fzpu3Dj5+/vbY7BYLLrhhhs0b948h2IXP//8s2rXrq1evXpJksLCwhQTE6NRo0bp1KlT9j+urq7q3r27li5dmiuG8ePHFynWQYMGadWqVbrqqqu0ZcsWvfnmmxoyZIhq166tP/74o9D7DcPQb7/9piuvvFKGYTjEN2TIEMXGxmrjxo0O99x+++3y8/OzH19//fWqWbOm5s2bJ0n2EaUFCxbkOY0RAJwZiRMAOJnatWvLw8Mj1/kdO3bommuuUUBAgPz9/VW9enV7YYmirA+pV6+ew3FWEpVfclHQvVn3Z9174sQJnTt3Tk2aNMnVLq9zF+Pw4cOSpObNm+e61qJFC/t1q9WqN954Q/Pnz1dwcLD69OmjN998U1FRUfb2ffv21XXXXafJkycrKChIV199tb799lulpKRcVAweHh5q1KiR/bqUmaieO3fOnqQkJCRo3rx5uuGGG+xrvvbt2ydJuvzyy1W9enWHPwsXLsxVxMHNzU116tQp/It1XteuXTVr1iydPXtWa9eu1cSJExUfH6/rr79eO3fuLPDekydPKiYmRl988UWu2LIS+wvja9q0qcOxxWJRkyZN7GvLGjZsqEcffVRfffWVgoKCNGTIEH3yySesbwJQLrDGCQCcTM6RpSwxMTHq27ev/P399dJLL6lx48by9PTUxo0b9dRTTykjI6PQ52atqbmQUYRdKS7lXjM8/PDDuvLKKzVnzhwtWLBAzz//vKZMmaIlS5aoY8eOslgs+vXXX7V69Wr9+eefWrBgge6880698847Wr16dYnsJ9WjRw81aNBAv/zyi2655Rb9+eefOnfunG666SZ7m6x+mz59ukJCQnI948IKh1ar1WGkq6g8PDzUtWtXde3aVc2aNdMdd9yhmTNn6sUXX8z3nqzYbr31Vo0ZMybPNu3atSt2LO+8847Gjh2r33//XQsXLtSDDz6oKVOmaPXq1cVKCgGgrJE4AUA5EB4ertOnT2vWrFnq06eP/fzBgwdNjCpbjRo15Onp6bA3UJa8zl2M+vXrS5L27Nmjyy+/3OHanj177NezNG7cWI899pgee+wx7du3Tx06dNA777zjsJ9Wjx491KNHD7366quaMWOGRo8erZ9++kl33313oTE0atTIfj41NVUHDx7UwIEDHdrfeOON+uCDDxQXF6eff/5ZDRo0UI8ePRxilDK/fhfeW1q6dOkiSYqMjLSfy6vqYfXq1eXn56f09PQix5Y1gpbFMAzt378/V4LVtm1btW3bVs8995xWrlypyy67TJ999pleeeWV4n4cACgzTNUDgHIga8Qn5whPamqqPv30U7NCcuDq6qqBAwdqzpw5On78uP38/v37NX/+/BJ5jy5duqhGjRr67LPPHKbUzZ8/X7t27dKIESMkZVauS05Odri3cePG8vPzs9939uzZXKNlHTp0kKQCp+sNHDhQHh4e+vDDDx3u//rrrxUbG2uPIctNN92klJQUfffdd/r777914403OlwfMmSI/P399dprr+W51urkyZP5xlKYpUuX5jkimLXeKOd0Qx8fH4dy6lJmn1533XX67bfftH379iLF9v333ys+Pt5+/OuvvyoyMtK+zi0uLk5paWkO97Rt21YuLi6FTpMEALMx4gQA5UDPnj1VpUoVjRkzRg8++KAsFoumT5/uVFPlJk2apIULF+qyyy7T+PHjlZ6ero8//lht2rTR5s2bi/QMm82W56hD1apVdd999+mNN97QHXfcob59+2rUqFH2cuQNGjTQI488Iknau3evBgwYoBtvvFGtWrWSm5ubZs+erejoaN18882SpO+++06ffvqprrnmGjVu3Fjx8fH68ssv5e/vr+HDh+cbX/Xq1TVx4kRNnjxZQ4cO1VVXXaU9e/bo008/VdeuXXNtZtypUyc1adJEzz77rFJSUhym6UmSv7+/pk6dqttuu02dOnXSzTffrOrVqysiIkJz587VZZddpo8//rhIX7sLPfDAA0pKStI111yjFi1aKDU1VStXrrSPfOUsQNK5c2ctWrRI7777rmrVqqWGDRuqe/fuev3117V06VJ1795d48aNU6tWrXTmzBlt3LhRixYt0pkzZ3L1U69evXTHHXcoOjpa77//vpo0aaJx48ZJkpYsWaL7779fN9xwg5o1a6a0tDRNnz7dnqQBgFMzq5wfAFR2+ZUjb926dZ7tV6xYYfTo0cPw8vIyatWqZS8vLclYunSpvV1+5cjzKs8tyXjxxRftx/mVI58wYUKue+vXr5+rhPXixYuNjh07Gh4eHkbjxo2Nr776ynjssccMT0/PfL4K2bLKbef1p3HjxvZ2P//8s9GxY0fDarUaVatWNUaPHm0cPXrUfv3UqVPGhAkTjBYtWhg+Pj5GQECA0b17d+OXX36xt9m4caMxatQoo169eobVajVq1KhhXHHFFcb69esLjdMwMsuPt2jRwnB3dzeCg4ON8ePHG2fPns2z7bPPPmtIMpo0aZLv85YuXWoMGTLECAgIMDw9PY3GjRsbY8eOdYinsHLtF5o/f75x5513Gi1atDB8fX0NDw8Po0mTJsYDDzxgREdHO7TdvXu30adPH8PLy8uQ5NCv0dHRxoQJE4y6desa7u7uRkhIiDFgwADjiy++cIhfkvHjjz8aEydONGrUqGF4eXkZI0aMMA4fPmxv999//xl33nmn0bhxY8PT09OoWrWq0b9/f2PRokVF/lwAYBaLYTjRP1cCACqckSNHaseOHbnWv6DiCA8PV//+/TVz5kxdf/31ZocDAKWCNU4AgBJz7tw5h+N9+/Zp3rx56tevnzkBAQBQQljjBAAoMY0aNdLYsWPtexpNnTpVHh4eevLJJ80ODQCAS0LiBAAoMUOHDtWPP/6oqKgoWa1WhYaG6rXXXsu1MSoAAOUNa5wAAAAAoBCscQIAAACAQpA4AQAAAEAhKt0ap4yMDB0/flx+fn6yWCxmhwMAAADAJIZhKD4+XrVq1ZKLS8FjSpUucTp+/Ljq1q1rdhgAAAAAnMSRI0dUp06dAttUusTJz89PUuYXx9/f3+RoJJvNpoULF2rw4MFyd3c3O5xKiT5wDvSD+egD50A/mI8+cA70g/kqQx/ExcWpbt269hyhIJUuccqanufv7+80iZO3t7f8/f0r7Deks6MPnAP9YD76wDnQD+ajD5wD/WC+ytQHRVnCQ3EIAAAAACgEiRMAAAAAFILECQAAAAAKQeIEAAAAAIUgcQIAAACAQpA4AQAAAEAhSJwAAAAAoBAkTgAAAABQCBInAAAAACgEiRMAAAAAFILECQAAAAAKQeIEAAAAAIUgcQIAAACAQpA4AQAAAEAhSJwAAAAAoBAkTgAAAABQCDezA6jMdkfFaV9UnI4lmh0JAAAAgIIw4mSiWRuP6YGftmjdSboBAAAAcGb8xm4iy/n/GqZGAQAAAKAwJE5mshTeBAAAAID5SJxMZDmfOTHiBAAAADg3EicTuTBXDwAAACgXSJxMZDmfOJE3AQAAAM6NxMlETNUDAAAAygcSJxNZmKoHAAAAlAskTiYibwIAAADKBxInM1mYqgcAAACUByROJnJhHycAAACgXCBxMhHFIQAAAIDygcTJRPZy5GROAAAAgFMjcTIRM/UAAACA8oHEyURsgAsAAACUDyROJrJkVdUjcwIAAACcGokTAAAAABSCxMlELuzjBAAAAJQLJE4mslAdAgAAACgXSJxMlJU3scYJAAAAcG4kTiaiqh4AAABQPpA4mcgi1jgBAAAA5QGJk4lY4wQAAACUDyROToA1TgAAAIBzI3EykQtDTgAAAEC5QOJkIopDAAAAAOUDiZOJGG8CAAAAygcSJxNZzg85scYJAAAAcG5Okzi9/vrrslgsevjhhwtsN3PmTLVo0UKenp5q27at5s2bVzYBlgKm6gEAAADlg1MkTuvWrdPnn3+udu3aFdhu5cqVGjVqlO666y5t2rRJI0eO1MiRI7V9+/YyirRkZU3VI3ECAAAAnJvpiVNCQoJGjx6tL7/8UlWqVCmw7QcffKChQ4fqiSeeUMuWLfXyyy+rU6dO+vjjj8so2pJloaoeAAAAUC64mR3AhAkTNGLECA0cOFCvvPJKgW1XrVqlRx991OHckCFDNGfOnHzvSUlJUUpKiv04Li5OkmSz2WSz2S4+8BKQkZEuKXONk9mxVGZZX3v6wFz0g/noA+dAP5iPPnAO9IP5KkMfFOezmZo4/fTTT9q4caPWrVtXpPZRUVEKDg52OBccHKyoqKh875kyZYomT56c6/zChQvl7e1dvIBL2I5oiyRXSVJYWJipsYA+cBb0g/noA+dAP5iPPnAO9IP5KnIfJCUlFbmtaYnTkSNH9NBDDyksLEyenp6l9j4TJ050GKWKi4tT3bp1NXjwYPn7+5fa+xZF/Pqj+vm/nTIkDRo0SO7u7qbGU1nZbDaFhYXRByajH8xHHzgH+sF89IFzoB/MVxn6IGs2WlGYljht2LBBJ06cUKdOnezn0tPTtWzZMn388cdKSUmRq6urwz0hISGKjo52OBcdHa2QkJB838dqtcpqteY67+7ubvo3gNv5z2c4STyVHX3gHOgH89EHzoF+MB994BzoB/NV5D4ozucyrTjEgAEDtG3bNm3evNn+p0uXLho9erQ2b96cK2mSpNDQUC1evNjhXFhYmEJDQ8sq7BJlL0dOWT0AAADAqZk24uTn56c2bdo4nPPx8VG1atXs52+//XbVrl1bU6ZMkSQ99NBD6tu3r9555x2NGDFCP/30k9avX68vvviizOMvCRZRVQ8AAAAoD0wvR16QiIgIRUZG2o979uypGTNm6IsvvlD79u3166+/as6cObkSsPKCDXABAACA8sH0cuQ5hYeHF3gsSTfccINuuOGGsgmolLGPEwAAAFA+OPWIU0WXlTaxxgkAAABwbiROJmLACQAAACgfSJxMlJU4ZZgbBgAAAIBCkDiZiKp6AAAAQPlA4mQi9nECAAAAygcSJxNRVQ8AAAAoH0icTGSvqmdqFAAAAAAKQ+JkouwBJ0aeAAAAAGdG4mSirOIQrHECAAAAnBuJk4nsxSHMDQMAAABAIUicTMQaJwAAAKB8IHEyEVX1AAAAgPKBxMlE7OMEAAAAlA8kTiZivAkAAAAoH0icTJQ1VY8BJwAAAMC5kTiZiBEnAAAAoHwgcTJR1hqnDIacAAAAAKdG4mQiiuoBAAAA5QOJk4lY4wQAAACUDyROJmLACQAAACgfSJxMZB9xYsgJAAAAcGokTiZixAkAAAAoH0icTJRVHIIBJwAAAMC5kTiZyCKKQwAAAADlAYmTiewjTmROAAAAgFMjcTIR+zgBAAAA5QOJk4mYqgcAAACUDyROJmLECQAAACgfSJxMlJU3scYJAAAAcG4kTiayMOQEAAAAlAskTiZiHycAAACgfCBxMpEL5cgBAACAcoHEyVRU1QMAAADKAxInE7HECQAAACgfSJxMZK+qZ2oUAAAAAApD4mQiquoBAAAA5QOJk4nYxwkAAAAoH0icTEQ5cgAAAKB8IHEykYuFqnoAAABAeUDi5AzInAAAAACnRuJkIqbqAQAAAOUDiZOJLKKqHgAAAFAekDiZiBEnAAAAoHwgcTIRiRMAAABQPpA4mcg+VY/MCQAAAHBqJE4mciFvAgAAAMoFEicTMVUPAAAAKB9InExF5gQAAACUByROJmLECQAAACgfSJxM5HI+cyJxAgAAAJwbiZOJ3M5Xh0gncwIAAACcGomTidxdM7/8JE4AAACAcyNxMpGba+aIU4ZhkWGQPQEAAADOytTEaerUqWrXrp38/f3l7++v0NBQzZ8/P9/206ZNk8Vicfjj6elZhhGXLHeX7C9/WgaJEwAAAOCs3Mx88zp16uj1119X06ZNZRiGvvvuO1199dXatGmTWrdunec9/v7+2rNnj/3YklWarhzKGnGSJFt6homRAAAAACiIqYnTlVde6XD86quvaurUqVq9enW+iZPFYlFISEhZhFfqciZOaSx0AgAAAJyWqYlTTunp6Zo5c6YSExMVGhqab7uEhATVr19fGRkZ6tSpk1577bV8kyxJSklJUUpKiv04Li5OkmSz2WSz2UruA1yMHNPzzqWkymZzNzGYyivr+8D074dKjn4wH33gHOgH89EHzoF+MF9l6IPifDaLYXJVgm3btik0NFTJycny9fXVjBkzNHz48Dzbrlq1Svv27VO7du0UGxurt99+W8uWLdOOHTtUp06dPO+ZNGmSJk+enOv8jBkz5O3tXaKf5WI8vMpVhix6qXOaAjzMjgYAAACoPJKSknTLLbcoNjZW/v7+BbY1PXFKTU1VRESEYmNj9euvv+qrr77SP//8o1atWhV6r81mU8uWLTVq1Ci9/PLLebbJa8Spbt26OnXqVKFfnLLQetIipaZnKOzBHmpQ3fx4KiObzaawsDANGjRI7u6M+pmFfjAffeAc6Afz0QfOgX4wX2Xog7i4OAUFBRUpcTJ9qp6Hh4eaNGkiSercubPWrVunDz74QJ9//nmh97q7u6tjx47av39/vm2sVqusVmue9zrDN4Cbq0Wp6ZLF1c0p4qnMnOV7orKjH8xHHzgH+sF89IFzoB/MV5H7oDify+n2ccrIyHAYISpIenq6tm3bppo1a5ZyVKXH5XxVQPZxAgAAAJyXqSNOEydO1LBhw1SvXj3Fx8drxowZCg8P14IFCyRJt99+u2rXrq0pU6ZIkl566SX16NFDTZo0UUxMjN566y0dPnxYd999t5kf45K4nC+sRzVyAAAAwHmZmjidOHFCt99+uyIjIxUQEKB27dppwYIFGjRokCQpIiJCLjk2iT179qzGjRunqKgoValSRZ07d9bKlSuLtB7KWbmez5wyGHECAAAAnJapidPXX39d4PXw8HCH4/fee0/vvfdeKUZU9rL272WqHgAAAOC8nG6NU2WTtcaJqXoAAACA8yJxMpmrhal6AAAAgLMjcTJZ1lQ9EicAAADAeZE4mSy7OITJgQAAAADIF4mTySxM1QMAAACcHomTybL2ccpgyAkAAABwWiROJssuDmFyIAAAAADyReJkMqbqAQAAAM6PxMlkLlTVAwAAAJweiZPJqKoHAAAAOD8SJ5PtiU6QJO04HmdyJAAAAADyQ+LkJN5auM/sEAAAAADkg8QJAAAAAApB4gQAAAAAhSBxAgAAAIBCkDgBAAAAQCFInEzmdr4c+eXNq5scCQAAAID8kDiZ7N4+DSVJNQM8TY4EAAAAQH5InEzmYskccUo32AEXAAAAcFYkTiZzOT9VzyBxAgAAAJwWiZPJzudNSs8wNw4AAAAA+SNxMlnWVL0MRpwAAAAAp0XiZDKX8z2QkUHiBAAAADgrEieTudpHnEwOBAAAAEC+SJxMZqGqHgAAAOD0SJxM5kpVPQAAAMDpkTiZLLuqHokTAAAA4KxInEzmwhonAAAAwOmROJmMcuQAAACA8yNxMplrVjlyEicAAADAaZE4mSyrql5GhsmBAAAAAMgXiZPJ3M8POdnSyZwAAAAAZ0XiZDJfq6skKSElzeRIAAAAAOSHxMlkvlY3SSROAAAAgDMjcTKZn2dW4pRuciQAAAAA8kPiZDIP1jgBAAAATo/EyWRurplV9dLYARcAAABwWiROJnN1yUyc0kmcAAAAAKdF4mQyN5fMLmDECQAAAHBeJE4mY8QJAAAAcH4kTibLmTgZBskTAAAA4IxInEzmdj5xkpiuBwAAADgrEieTueZInJiuBwAAADgnEieTMeIEAAAAOD8SJ5M5jDilkzgBAAAAzojEyWSOI04ZJkYCAAAAID8kTiazWCxyUeZIE2ucAAAAAOdE4uQEsgadWOMEAAAAOCcSJyeQlTgx4gQAAAA4JxInJ+DKiBMAAADg1EicnED2iBPFIQAAAABnROLkBLISJxvlyAEAAACnZGriNHXqVLVr107+/v7y9/dXaGio5s+fX+A9M2fOVIsWLeTp6am2bdtq3rx5ZRRt6WGNEwAAAODcTE2c6tSpo9dff10bNmzQ+vXrdfnll+vqq6/Wjh078my/cuVKjRo1SnfddZc2bdqkkSNHauTIkdq+fXsZR16yWOMEAAAAODdTE6crr7xSw4cPV9OmTdWsWTO9+uqr8vX11erVq/Ns/8EHH2jo0KF64okn1LJlS7388svq1KmTPv744zKOvGRldQJrnAAAAADn5GZ2AFnS09M1c+ZMJSYmKjQ0NM82q1at0qOPPupwbsiQIZozZ06+z01JSVFKSor9OC4uTpJks9lks9kuPfBLZLPZ5Ho+c0pOdY6YKpusrzlfe3PRD+ajD5wD/WA++sA50A/mqwx9UJzPZnritG3bNoWGhio5OVm+vr6aPXu2WrVqlWfbqKgoBQcHO5wLDg5WVFRUvs+fMmWKJk+enOv8woUL5e3tfWnBlxAXuUqSVq5ao1M7ma5nlrCwMLNDgOgHZ0AfOAf6wXz0gXOgH8xXkfsgKSmpyG1NT5yaN2+uzZs3KzY2Vr/++qvGjBmjf/75J9/kqbgmTpzoMEoVFxenunXravDgwfL39y+R97gUNptNb25ZIknq3LWrejcJMjmiysdmsyksLEyDBg2Su7u72eFUWvSD+egD50A/mI8+cA70g/kqQx9kzUYrCtMTJw8PDzVp0kSS1LlzZ61bt04ffPCBPv/881xtQ0JCFB0d7XAuOjpaISEh+T7farXKarXmOu/u7u403wBZVfUsFleniakycqbvicqMfjAffeAc6Afz0QfOgX4wX0Xug+J8LqfbxykjI8NhTVJOoaGhWrx4scO5sLCwfNdElRdZVfVS0igOAQAAADgjU0ecJk6cqGHDhqlevXqKj4/XjBkzFB4ergULFkiSbr/9dtWuXVtTpkyRJD300EPq27ev3nnnHY0YMUI//fST1q9fry+++MLMj3HJ3F0MSRalpKWbHQoAAACAPJiaOJ04cUK33367IiMjFRAQoHbt2mnBggUaNGiQJCkiIkIuLtmDYj179tSMGTP03HPP6ZlnnlHTpk01Z84ctWnTxqyPUCLcz3/EFBsjTgAAAIAzMjVx+vrrrwu8Hh4enuvcDTfcoBtuuKGUIjKHR1Y5ckacAAAAAKfkdGucKqOsEadkG4kTAAAA4IxInJyAmz1xYqoeAAAA4IxInJyAfY0TU/UAAAAAp0Ti5ATcGXECAAAAnBqJkxPILEfOGicAAADAWZE4OQEPRpwAAAAAp0bi5ATcKEcOAAAAODUSJyeQvQEuiRMAAADgjEicnEB2VT2m6gEAAADOiMTJCbABLgAAAODcSJycAOXIAQAAAOdG4uQEGHECAAAAnBuJkxOw7+NEVT0AAADAKZE4OYHsqnpM1QMAAACcEYmTE2CqHgAAAODcSJycgD1xohw5AAAA4JRInJxAVuKUmpahjAzD3GAAAAAA5ELi5ATcc/QCm+ACAAAAzofEyQk4Jk6scwIAAACcDYmTE3C1SG4uFklsggsAAAA4IxInJ2E9P+xEZT0AAADA+ZA4OQmr2/nEial6AAAAgNMhcXISnm6ukpiqBwAAADgjEicnERmXLEn672SCyZEAAAAAuBCJk5Mwzm/ftCkixtQ4AAAAAORG4uQkejaqKknycKNLAAAAAGfDb+lOonP9QElU1QMAAACcEYmTk/CxukmSElPSTI4EAAAAwIVInJyEj0dm4pSQwogTAAAA4GxInJyEjzWzHDkjTgAAAIDzIXFyEr7WrBEnEicAAADA2ZA4OYmsEadtx2IpEAEAAAA4GRInJ+Ht7mZ/PW3lIfMCAQAAAJDLRSVOR44c0dGjR+3Ha9eu1cMPP6wvvviixAKrbDzds7vi0KlEEyMBAAAAcKGLSpxuueUWLV26VJIUFRWlQYMGae3atXr22Wf10ksvlWiAlYWnu6v9tS3dMDESAAAAABe6qMRp+/bt6tatmyTpl19+UZs2bbRy5Ur98MMPmjZtWknGV2l45Rhx2nE81sRIAAAAAFzoohInm80mq9UqSVq0aJGuuuoqSVKLFi0UGRlZctFVIh5u2SNOu6PiTYwEAAAAwIUuKnFq3bq1PvvsM/37778KCwvT0KFDJUnHjx9XtWrVSjTAysLX6lp4IwAAAACmuKjE6Y033tDnn3+ufv36adSoUWrfvr0k6Y8//rBP4UPxWCwWs0MAAAAAkA+3wpvk1q9fP506dUpxcXGqUqWK/fw999wjb2/vEgsOAAAAAJzBRY04nTt3TikpKfak6fDhw3r//fe1Z88e1ahRo0QDrEyC/a1mhwAAAAAgDxeVOF199dX6/vvvJUkxMTHq3r273nnnHY0cOVJTp04t0QArk3du6GB/fSzmnHmBAAAAAHBwUYnTxo0b1bt3b0nSr7/+quDgYB0+fFjff/+9PvzwwxINsDKpXy17muMjP282LxAAAAAADi4qcUpKSpKfn58kaeHChbr22mvl4uKiHj166PDhwyUaYGXi5ppdIGLtwTMmRgIAAAAgp4tKnJo0aaI5c+boyJEjWrBggQYPHixJOnHihPz9/Us0wMrEzeWiugMAAABAKbuo39RfeOEFPf7442rQoIG6deum0NBQSZmjTx07dizRACsTd1dKkgMAAADO6KLKkV9//fXq1auXIiMj7Xs4SdKAAQN0zTXXlFhwlY2P1bE7km3p8nRnY1wAAADAbBc9NywkJEQdO3bU8ePHdfToUUlSt27d1KJFixILrrJxd3XRnAmX2Y/HfLNWMUmpJkYEAAAAQLrIxCkjI0MvvfSSAgICVL9+fdWvX1+BgYF6+eWXlZGRUdIxViod6gaqXtXM6nprDp7R+4v2mRwRAAAAgIuaqvfss8/q66+/1uuvv67LLsscIVm+fLkmTZqk5ORkvfrqqyUaZGUT7G9VxJkkSeznBAAAADiDi0qcvvvuO3311Ve66qqr7OfatWun2rVr67777iNxukQta/pr3aGzkiRvD9Y4AQAAAGa7qKl6Z86cyXMtU4sWLXTmDPsPXarhbWvaX/+++biJkQAAAACQLjJxat++vT7++ONc5z/++GO1a9fukoOq7DrVq+JwvCcq3qRIAAAAAEgXmTi9+eab+uabb9SqVSvddddduuuuu9SqVStNmzZNb7/9dpGfM2XKFHXt2lV+fn6qUaOGRo4cqT179hR4z7Rp02SxWBz+eHp6XszHcFoebi5a9Ggf+/GJ+GQTowEAAABwUYlT3759tXfvXl1zzTWKiYlRTEyMrr32Wu3YsUPTp08v8nP++ecfTZgwQatXr1ZYWJhsNpsGDx6sxMTEAu/z9/dXZGSk/c/hw4cv5mM4tSY1/Oyvb/t6rdYfYgokAAAAYJaLKg4hSbVq1cpVBGLLli36+uuv9cUXXxTpGX///bfD8bRp01SjRg1t2LBBffr0yecuyWKxKCQkpPhBlzO9mwbp332nJEnXf7ZKm18YpEBvD5OjAgAAACqfi06cSkNsbKwkqWrVqgW2S0hIUP369ZWRkaFOnTrptddeU+vWrfNsm5KSopSUFPtxXFycJMlms8lms5VQ5BcvK4a8Ymkc5K1/c2zj9NSvW/TxqA5lFFnlUVAfoOzQD+ajD5wD/WA++sA50A/mqwx9UJzPZjEMwyipN96yZYs6deqk9PT0Yt+bkZGhq666SjExMVq+fHm+7VatWqV9+/apXbt2io2N1dtvv61ly5Zpx44dqlOnTq72kyZN0uTJk3OdnzFjhry9vYsdZ1k6kyJN3uiY234QmmZSNAAAAEDFkpSUpFtuuUWxsbHy9/cvsK3TJE7jx4/X/PnztXz58jwToPzYbDa1bNlSo0aN0ssvv5zrel4jTnXr1tWpU6cK/eKUBZvNprCwMA0aNEju7u65rs/fHqUHf95qP9738uCyDK9SKKwPUDboB/PRB86BfjAffeAc6AfzVYY+iIuLU1BQUJESp2JN1bv22msLvB4TE1Ocx9ndf//9+uuvv7Rs2bJiJU2S5O7uro4dO2r//v15XrdarbJarXne50zfAPnG4+K4Ae4Pa4/q5m715OnOxrglzdm+Jyor+sF89IFzoB/MRx84B/rBfBW5D4rzuYqVOAUEBBR6/fbbby/y8wzD0AMPPKDZs2crPDxcDRs2LE44kqT09HRt27ZNw4cPL/a95UHHuoEOx5P+3KnftxzXM8NbqmuDgteCAQAAACgZxUqcvv322xJ98wkTJmjGjBn6/fff5efnp6ioKEmZCZiXl5ck6fbbb1ft2rU1ZcoUSdJLL72kHj16qEmTJoqJidFbb72lw4cP6+677y7R2JxF3areCnukjwa9t8x+blNEjG74bJXmPthLrWsVnMwCAAAAuHSmVtWbOnWqJKlfv34O57/99luNHTtWkhQRESEXl+ztps6ePatx48YpKipKVapUUefOnbVy5Uq1atWqrMIuc02D/fI8v+VILIkTAAAAUAZMTZyKUpciPDzc4fi9997Te++9V0oROa/v7+ym279Z63DOxWJSMAAAAEAl41J4EziDno2r5TrnYiFzAgAAAMoCiVM54ebqohnjujucI28CAAAAygaJUznStIbjWqc/t0aaFAkAAABQuZA4lSNBvh4Ox8v2njQpEgAAAKByIXEqRywWi7a8MNjsMAAAAIBKh8SpnAnwdpene3a3rdh/ysRoAAAAgMqBxKkc+uK2LvbXo79aI1t6honRAAAAABUfiVM51Ka246a3TZ+dr6TUNJOiAQAAACo+EqdyqKqPR65z/+5jyh4AAABQWkicyqmnhrZwOE5IZsQJAAAAKC0kTuXUPX0aORyfTUo1KRIAAACg4iNxKqdcXSwOx6v/O2NSJAAAAEDFR+JUQSzaFU1pcgAAAKCUkDhVIKO/WmN2CAAAAECFROJUjv04rofZIQAAAACVAolTORbauJqWPdHf4VxGhmFSNAAAAEDFReJUzgV4uTsc/7DmsEZ8+K/+O5lgUkQAAABAxUPiVM75ebo5HD//+w7tOB6nJ37dalJEAAAAQMVD4lTOubhY9L8L9nSSpOi4ZBOiAQAAAComEqcKYOLwlmpc3cfhXLItw6RoAAAAgIqHxKmCGNWtnsPxqYQUkyIBAAAAKh4Spwrimo61zQ4BAAAAqLBInCqIQG8Phfh7OpzbfyLepGgAAACAioXEqYJwdbHo74d7O5xbuvukSdEAAAAAFQuJUwUS6O3hcJyQkmZSJAAAAEDFQuJUwQxsGWx//cHifSZGAgAAAFQcJE4VzHs3tXc4nr3pqEmRAAAAABUHiVMF4+fp7nD8yM9bTIoEAAAAqDhInCqgT0d3MjsEAAAAoEIhcaqAGgb5OBzHJtlMigQAAACoGEicKqD0DMPheMfxWJMiAQAAACoGEqcKqGaA40a4t3y1RnHJjDoBAAAAF4vEqQKq5mvV7Pt6qm3tAPu5dpMWKjL2nIlRAQAAAOUXiVMF1bFeFfVpFuRwLnTKEv255bhJEQEAAADlF4lTBVbd15rr3GO/UJ4cAAAAKC4SpwrMx+qW61xqeoYJkQAAAADlG4lTBebhlnf3ztl0rIwjAQAAAMo3EqcKzN017+59a8GeMo4EAAAAKN9InCqw6n651zhJ0rEYqusBAAAAxUHiVIF1qV8l32uGYejgqUQZhpFvGwAAAACZSJwqMIvFohu71Mnz2ufL/lP/t8P1ydL9ZRwVAAAAUP6QOFVwTw1toeFtQzTtjq5a8HAf+/nX5++WJL29cK9ZoQEAAADlRu561ahQqvla9enozpKkUwkpJkcDAAAAlE+MOFUivnns6yRJJ+KS9eHifbr8nXCdJrkCAAAAciFxqkQ83V3zPL/jeJzeDdur/04m6rtVh8s4KgAAAMD5kThVMh+O6pjr3OHTiSZEAgAAAJQfJE6VzFXta+U6N+nPnfbXXvmMSgEAAACVGYkTHGyMOGt2CAAAAIDTIXGCg7Cd0WaHAAAAADgdEqdKqGfjagVe/2ltRBlFAgAAAJQPJE6V0JV5rHPK6elZ28ooEgAAAKB8IHGqhG7sUleTr2pdYJvB7/2j/04mlFFEAAAAgHMzNXGaMmWKunbtKj8/P9WoUUMjR47Unj17Cr1v5syZatGihTw9PdW2bVvNmzevDKKtOFxdLBrTs4ECvd3zbbM3OkETGXkCAAAAJJmcOP3zzz+aMGGCVq9erbCwMNlsNg0ePFiJifnvK7Ry5UqNGjVKd911lzZt2qSRI0dq5MiR2r59exlGXjH8cHf3Aq8npqaVUSQAAACAczM1cfr77781duxYtW7dWu3bt9e0adMUERGhDRs25HvPBx98oKFDh+qJJ55Qy5Yt9fLLL6tTp076+OOPyzDyiqF1rQCtfXaAnh7WQmueGZDr+vZjcXrsly0mRAYAAAA4FzezA8gpNjZWklS1atV826xatUqPPvqow7khQ4Zozpw5ebZPSUlRSkqK/TguLk6SZLPZZLPZLjHiS5cVg1mxVPF01V096+V7/beNR/X6Na3KMKKyZ3YfIBP9YD76wDnQD+ajD5wD/WC+ytAHxflsFsMwjFKMpcgyMjJ01VVXKSYmRsuXL8+3nYeHh7777juNGjXKfu7TTz/V5MmTFR2dew+iSZMmafLkybnOz5gxQ97e3iUTfAXx0Kq88+gPQpmyBwAAgIonKSlJt9xyi2JjY+Xv719gW6cZcZowYYK2b99eYNJ0MSZOnOgwQhUXF6e6detq8ODBhX5xyoLNZlNYWJgGDRokd/f8izWUhYdWLczzfO/LB8vP02m+VUqcM/VBZUY/mI8+cA70g/noA+dAP5ivMvRB1my0onCK34bvv/9+/fXXX1q2bJnq1KlTYNuQkJBcI0vR0dEKCQnJs73VapXVas113t3d3am+AZwhntt61Nf01Ydzne/06hLtfGmIvD2c4tul1DhDH4B+cAb0gXOgH8xHHzgH+sF8FbkPivO5TC0OYRiG7r//fs2ePVtLlixRw4YNC70nNDRUixcvdjgXFham0NDQ0gqz0njxyvzXMoXtjFayLb0MowEAAACch6mJ04QJE/R///d/mjFjhvz8/BQVFaWoqCidO3fO3ub222/XxIkT7ccPPfSQ/v77b73zzjvavXu3Jk2apPXr1+v+++834yNUKG6uLrq7V97J60M/bdaoL1eXcUQAAACAczA1cZo6dapiY2PVr18/1axZ0/7n559/treJiIhQZGSk/bhnz56aMWOGvvjiC7Vv316//vqr5syZozZt2pjxESociyX/a5siYuQktUQAAACAMmXqopWi/BIeHh6e69wNN9ygG264oRQigrtrwbl0fEqabGkZqurjIUtBWRYAAABQgZg64gTnc1evhqpb1UsPXN4kz+sP/bhJnV9ZpIYT5zH6BAAAgEqDxAkOqvla9e+Tl+uxwc3zvL50z0n763O2dJInAAAAVAoVu740Lom7q0W29PwTo1YvLFCjIB/VruKlr8d0lYcbeTgAAAAqJn7TRb66N6xWaJv/TiXq332nNPT9ZWUQEQAAAGAOEifk683r26lrgypFavvfqcRSjgYAAAAwD4kT8lUr0EsvXtm6yO2TbelKTcsoxYgAAAAAc5A4oUBNg33VoW5gkdp2f22xLntjidLSSZ4AAABQsZA4oUBWN1fNmXCZhrQOLrRt7DmbTsan6JYv15RBZAAAAEDZIXFCkbwysq2u61RHv43vWWjbtYfOKDElrQyiAgAAAMoG5chRJNX9rHrnxvaSpKo+HjqTmFpg+7QCypgDAAAA5Q0jTii2H8f1KLRNSnp6GUQCAAAAlA0SJxRb8xA/tarpX2CbE3EpMgxD6RmMPAEAAKD8I3HCRfns1s66tlPtfK+/Pn+3xn2/QX3eXMp6JwAAAJR7JE64KPWqeevdGzto7bMD8ry+fP8pLdoVrWMx59T6xQU6fJoNcgEAAFB+kTjhktTw89SE/o0Lbdf3rfDSDwYAAAAoJSROuGQPXN60SO3WHzqjI2eSNP7/NmhTxNlSjgoAAAAoOZQjxyXzdHdVzQBPRcYmF9ju+s9WqV2dAG09Gqv526N06PURZRQhAAAAcGkYcUKJcHWxFKnd1qOx9tdJqWl6a8FubTkSU0pRAQAAACWDxAklwtvD1f76wGvDi3RPqxcW6JOlB3T1JytKKywAAACgRJA4oUS8e2MHVfPx0JRr2xZ59AkAAAAoL1jjhBLRpnaA1j83UBYLSRMAAAAqHkacUGIuJWm66fNV2nE8tvCGAAAAgAlInFAqnh7WQn6eRR/QXHPwjEZ8uLwUIwIAAAAuHlP1UCru7dtY9/RupE1HYjQ1fL9W/3dGCSlpZocFAAAAXBRGnFBqXFws6ly/ir4a01XB/tYi3ZORYZRyVAAAAEDxkTjBqTR6Zp5+XBuhvdHxMgySKAAAADgHEieUies61yly24mztmnwe8u0aNeJUowIAAAAKDoSJ5SJe3o30rd3dNWWFwc7nO/VJCjfe+6fsVGStP1YrCJjz+XZJiUtXfHJtpILFAAAAMgDiRPKhJuri/o3r6EAL3e1qukvSXrhilbq0qBKvvekpGXowMkEXfHRcoVOWSIpcw3UsZjsJKr/W+FqP3khhScAAABQqqiqhzL3x/2XKTE1XQFe7jIMQysPnNbag2fybLv+kOP5J37dqt82HtUHN3fQ8LY1dTw2WZK0JypOnetXLfXYAQAAUDkx4oQy5+bqogAvd0mZm+ZOurJ1vm13HI+zv46KTdZvG49Kkl74fYfOJqbar3m6u5ZStAAAAACJE5xAkK9Hvte+X3XY/nrAO+H217HnbIo9l722KS2dCnwAAAAoPSROMF1Vn/wTp5wSU9MdjuNyFIVIScso0ZgAAACAnEicYDo314v7Nsw54pSSll5ASwAAAODSUBwC5dYjP2+xv45JsikqNlkhAZ76eV2Envptm6TMcueNq/vo2RGt5OHGvxMAAADg4pA4odzKOeL0wI+b8myzfP8pLd9/SjUDvXRv38ZlFRoAAAAqGP4JHk7hinY1S/X524/FlurzAQAAULEx4gSn8NGojnrr+vayZWTol3VH9MrcXSX6/AyDqnsAAAC4eIw4wSlYLBZ5ebjK39Ndd/dulOv6m9e1u6TnU64cAAAAl4LECU5p7oO9HI6vbF9L9at5X/TzVuw/ZX+dnkESBQAAgOIhcYJTal0rQF+P6WI/9nR30ds3tL/o5yWmpuvImSStPHBK7SYt0C/rj2j+tkjdNW2dziSmlkTIAAAAqMBY4wSnlbN8uMViUdcGVfXooGZ6N2zvRT2v95tL7a+f/HWr/fWHS6xqmCoZrIMCAABAPhhxgtMKbVRN3RtW1dieDeznHhzQtMTf54e1R/TKZjdd+9kanUtlI10AAADkRuIEp+Xm6qKf/xeqSVe1djj/3IiWebb/5X+hDklWcW0/Hqcur4Rp9qajikli+h4AAACykTih3Lm7dyONyGPfp24Nq2rSVa3Vrk6A/dxlTaoV69mJqel65Oct6vBS2CXHCQAAgIqDNU4ol3w98v/WnTW+p9YeOqPqvlYZkga/t+yi3uPXDUdVzcdDDYJ85Gt1U3U/a57tvlt5SLM2HtW0O7qpio9Hsd4jNsmmfSfi1bl+FVkslouKEwAAAKWPxAnl0qODm2nTkbNqWztQv2086nDNzdVFPRsHXfJ7PD5zi8PxC1e00s3d6sr7gqTtxT92SJI+Wbpfz13RKtdzDMPINyka/uG/OhZzTp/f1llDWodccswAAAAoHSROKJeC/T218JG+kqRBrWqoTpWL3+OpqF76a6f+2npc6RmGHhvcXH2aVXdYC5WYmpbrnvtnbNTBU4n6fcJlcnPNPTP2WMw5SdLf26NInAAAAJwYa5xQ7g1tU1NtagcU3rAEbIyI0Zajsbr9m7WS5LAW6qd1R3QmMdWhrPlfWyO143icNhw+W+BzmaUHAADg3EicUOn0anLp0/gkqcHTcx2ODUPq9HKY7pi2TpGx54r1LBcyJwAAAKdG4oQKb/Z9PdWqpr/9+K0b2pXq+4XvOanQKUu04fAZ+7msNU4z1kTogR83yZae4XCPy/m8KSo2WT+vi1Cyjf2kAAAAnAmJEyq8jvWqaPpd3ezHLhaL7u3buNTf97qpqxyO/913Us/M3qY/txzXn1uOO1yzKDNzuumLVXrqt216L2xvqccHAACAoiNxQqXg6pI9Fc4wpKeHtXC4/lS73IUdSlJKWrpu+3qt/TgxJU0n4pPtx1kz9Q6fTpKUuTYqp3Op6fphzeFiTwEEAABAyTA1cVq2bJmuvPJK1apVSxaLRXPmzCmwfXh4uCwWS64/UVFRZRMwyi1Pd1f7ax9r5utXr2ljP1fLp3Tf/+hZx4RnT3S8ur262H58YbnyCyv0vb1wj56dvV0jP1lRekECAAAgX6YmTomJiWrfvr0++eSTYt23Z88eRUZG2v/UqFGjlCJEReHp7qrpd3XTt3d0lZ+nuyRpdPf6euGKVvrslg6SpG9u76Rg/7w3ub1UE2dtczj+v9URDsc/ro1QfLLNfpyYkqbUtOx1UEt2n5AkRcel6Lk525SeYQgAAABlx9R9nIYNG6Zhw4YV+74aNWooMDCw5ANChda7afVc5+7s1VA2m03zDkq9mwZpzTMDJUkn4pL1/arD+njp/jKLL+d72dINNX9+vv68v1euUuv/tzpCXRtU1dUdapdZbAAAAJVdudwAt0OHDkpJSVGbNm00adIkXXbZZfm2TUlJUUpKiv04Li5OkmSz2WSz2fK7rcxkxeAMsVRWefVBFS9XPXR5I13XsabWHTqrZftO6a9tpTsl9PN//nM4Ngzptbk7dWv3ejp4KtHhWnTsOdlsNh04mah1h87qhs61HdZxXcgwjFzTAZ0NPwvmow+cA/1gPvrAOdAP5qsMfVCcz2Yxcu7WaSKLxaLZs2dr5MiR+bbZs2ePwsPD1aVLF6WkpOirr77S9OnTtWbNGnXq1CnPeyZNmqTJkyfnOj9jxgx5e3uXVPioBB5e5SrjfPU7dxdDtozST0Sa+mdoX1zuGbXXNEhX3xBDD6/O/LePBr6GzqZIdzRPV5Cn9G+ki3oEZ6iqVfp6j4tiUy16uE260g3JIsmtgEm66RnSwXipvp/kTvkYAABQgSUlJemWW25RbGys/P39C2xbrhKnvPTt21f16tXT9OnT87ye14hT3bp1derUqUK/OGXBZrMpLCxMgwYNkru7u9nhVEpF7YMT8SladeC0avhbFdqomu78boP+3X9akvTwgCYK33tSm4/ElknMVjcXpaRl5Dp/efPqSsvI0LJ9pxXib9XiR3qr9eRFkqRZ93bX+B82S5KWPd5HLvmMUL25YK++XH5II9qG6P0bS3fPq5z4WTAffeAc6Afz0QfOgX4wX2Xog7i4OAUFBRUpcSqXU/Vy6tatm5YvX57vdavVKqs194J/d3d3p/oGcLZ4KqPC+qB2VXddX9XXfuzqmj0c8+CAZnp4UHOdTUxVzDmb+r8dXpqh5pk0SdKxmGTtiY6XJEXFpdiTJkk6ey5d0fGZ/4iQmCb5WF1kdXNV1r+dZE3l+2rFIUnS3G1R+mR059L6CPniZ8F89IFzoB/MRx84B/rBfBW5D4rzucp94rR582bVrFnT7DBQCXl7ZJc4zxq9qeLjoSo+Hnm2d3WxaM/LQ/Xhkv36cPG+UokpK2nKyw9rsiv5dXo5TJL07o3t9fvm4zoRn6I/7r9M7q4ucrVYlOYcA9EAAABOw9TEKSEhQfv3Z1cSO3jwoDZv3qyqVauqXr16mjhxoo4dO6bvv/9ekvT++++rYcOGat26tZKTk/XVV19pyZIlWrhwoVkfAZXYM8NbaldkvO64rEGR2m+bNFhuri56dFAz1QzwzFWivLRllTTP6dFftthfN312vtY8M0AuFoukzMTpy2X/6VjMOb14ZSunLy4BAABQmkxNnNavX6/+/fvbjx999FFJ0pgxYzRt2jRFRkYqIiL7X8lTU1P12GOP6dixY/L29la7du20aNEih2cAZaVOFW8tfbxfntfmP9RbYTuj9W7YXknSkNbB8vbI/nEb1a1emSdORdH9tcUOx6/O2yVJah7ip3Op6Rrbs4HD2qiYpFS9MneXru9cRz0aVZOUWcHv2TnbFeLvqQcHNC274AEAAEqRqYlTv379VFBtimnTpjkcP/nkk3ryySdLOSrg0rWs6a+WNf3tiZOba/kuT5eV5FXz9XDYP+q1ebv064aj+nXDUR16fYSkzOmCM85PC3zg8iaMVAEAgAqhfP82B5QTLYL98r226NG+9tc/3dOjwOdMv6tbicV0MfZFJzgcHzqdlKtNWnr2P4akpmcWsVh78IyW7zuV73PT0vMudnEpzqWml/gzAQBA5UXiBJSi38b31H39Gmtcn0a5rq2eOEB/P9xbjav7aGDLGurWsKq6Naha4PN6N61eWqEWiZurRXui4nXogg15c/LIsUnUudR0paVn6MbPV+nWr9fobGKqDp1K1IQZG7XjeGbp9l/WH1GrFxbon70nSyzO3zYcVcsX/taPayMKbwwAAFAEJE5AKepcv4qeHNpCnu6uua6FBHiqRYi/LBaLvhrTVb/8LzTX3krv39TB/vqh8+uFVk28vFRjLsj7i/ZpyPvL1O/tcBlG1nbA2QzD0MEcSdW9/7dBi3ZF249jztl0+zdrNXdrpG7/eq3SMww9+etWpaZnaPyMzUWKwTAMrTt0RmcTU/Nt89jMzKIXzriODAAAlE8kToCT8ffMXnpodXPRt3d01eju9TS+X2NJUs0Ar1z3PHB5E/vrNrXLZmPn/1sToTUHzzicm789Sv+bvsF+vPq/M7r3/zbaj9MzDEWcyZzedzox1aHSn2FIPx1w0Ut/ZRak2Hk8To2fmaeX/typtPQMPTN7m/7YclyLdp3QDZ+t0qD3/inNjwcAAOCg3O/jBFQ08x7qrV5vLJUkdapfRcH+nurfvEaB9zTNsYbqg5s7asA7eScVzw5vaa+Ud6men7Pd4fj7VYf0wu87CrznwqlzpxNS7K/TMgytOuGiVSeO6KnhrXTzF6uUnmHomxUH5eZq0Yw1EfaiE5J0KsFxxOlYzDmN/nK1GlX3VVGt2H9K1f2salbAGjQAAACJxAlwOnWqeGvH5CGKT05TsL9nke7xtWZPBfRwdZGri0XpGbkrVo7r00inE1P12T8HSizeLIUlTZL09fKDRbonPtmmuOQ0+/HaC0a2LpSalqHLXl8iKe+CFXnZfyJBo79aI0n664Fe+m7lIT02uLlCAnJ/zVPS0mV1yz3dEgAAVB5M1QOckI/VLc9f4LPMGNdd13Wqo7t7NdQNneuoc73sohKuLhZtfG6QZtzdXbUDc0/re3pYC+16aWipxF1cqflU0wudssThOC7Zlme7lQdOad62SCWkpOV5XcpcE3XntHW68fNVyjifTGZkGBr4bvao3BUfLdfMDUfVY8pipaZl6J7v12vyn5lJ3YbDZ9T8ub/1ydL9eT4fAABUDow4AeVQz8ZB6tk4yH4cey47sXCxWBTg7a6eTYK04unLFZds08B3/lGvptntvTwcR09m3N1dt5wffbnjsgbqWK+KHvxxUyl/iqL772TeVfxu+TIz5heuaJXvvVFxyfa1VIdOJ6pRdV+tP3w23/Yv/bVDC3dmFrR48crWenZ25pTEtxbs0YT+TfK9ryIxDEOP/rxZjWv4VprPDABAYRhxAioAf083dW1QRR3rBaqGn/WCa+5aNXGA3r2xg8P5rNLn347tqp5NspMqD1cXtaqZveanU71ABfl6lF7wJeClv3bme23WxmP215e/848SU9IUFZecb/vouOx1VxkZhvLaozshJU17o+MVFZusUV+s1t/boy4ucCe1/nCMZm06prcW7DE7FAAAnAYjTkAFYLFY9Mv/Qu2vL+Tqkvvc9Lu76djZc7mKKbi7uqhJDT+9dX07Bft7qk+zzL2jGjw9t9A4Jl3ZSpP+zD+JMcOFv/y3fnFBge3DdmaXT7dlZCg9R+YUvueEth6N1bthex3uWfXfaR16fUSRY8rIMHKVnncmyTY2DwYA4EKMOAEVhMViyTNpyo/VzTXPCnSNqvtIkm7oUteeNEnSNR1rS5LeuK6tQ/tBrYLtrzvUq1KsmJ2dLd1QRo7Eaey363IlTcX11b//qcNLC7UrMk6SdDYxVSfi8x8BAwAAzoHECYAkafpd3fTg5U00skPtPK+/dX07LX6sr27sUtd+rmVNf70yso392MM1+6+UW3vU03MjWpZewGXAlpaR7/qqguw/kaD7Z2zUnqj4XNdembtLcclpmjhrmxJS0tRjymINeneZzqWmy8hrXiAAAHAKJE4AJEm9m1bXo4Ob5zuFzM3VRY2r+zqManm5u8gtR3s3V4v+eqCX7u3bWE8NbaGrOtSSJDWo5l3gez8zvEUJfIKS1/HlsCK3HfbBv7rp81X6v9WHdfd36/TX1kjd/MWqfNtvPhKjR37erJS0DMWes2n8DxvUcOI8bYw4q3Op6VqwI0pJqZnVAjPXWhn6v9WHtf1YbIFxvLtwj776978ix12YS03mPl6yT/3fDtepHHt2AQBQHrHGCcBF69Gomtzdsv/9xcUitakdoDa1AyRJfp7u2vzCIHl7uOmfvSf10ZJ98nB1yVXVblzvRrq9e1099c3fumVwqG76cm2u9/p6TBf9u++Upq08JEla+ng/9X87vNQ+W3FlTb1bk2PPqbNJNnV6OUxtageoQ50AXd3RcTQv53qq8D0nJUnXfrpSV3eopd83H9f1nevosibV9MjPW9Sypr/9PXa/PFSe7rn3ldp/IkEfLsksm35Xr4bFmrqZn/QMQ26uF/+ctxdmTm38LPyAniug+iEAAM6OEScAxbbg4T56YkhzPTigqdxdcv41kvsX7EBvD3m4uWhQq2D9cX8vPTKoWa42FotFri4WXV7LUKd6gXrnhva52gxoGaxJV7XW/leHafvkIWoY5KNFj/YtyY9VKs4kpmrZ3pP6cMl+DXjnn8JvkPT75uOSpF83HNUjP2+RlJ2YSdLIT1Y4tE/PMPTavF36aW2Ew7kLnYhL1qyNR5WSln/xh/BIix6duc1+/MrcXQ7FIgzD0J9bjuvImaJtNJwlvz27AAAoLxhxAlBszUP81Dwks2S5LccvxBfuD5WXy5oEacHDfbTtWKwen7klzzbXda6jx3Jcm3VfT/trN1cX+Z5fS9WkRu7iFnlZ9kR/9XlraZHalge7o+LV4Om5evnq1lp76KyOnEnS5iMxDm3SMgy55eiOUwkpGvL+Mp1NsmndoTOacm07SVJqWobSMwx5ebgqPcPQ7EOukrL3BZu28pBq+Ft1X7/M/Zxmrj+qJ3/bKj9PN22bNKTIMRd3xl90XLKCfK15VoQEAMAMJE4ALom7q4ueGNJcCSlpqh3oVaR7mof4KcDLvUhth7UJUacCqvU1reGrfScSCnxGFZ+ivVd58/zvO/K9lpZhKCk1TSM+XK5Wtfw1d2uk/dqPa49oU0SMfri7uzq/skhVfTz0wc0d9L/pG/J81sGTiTqXmi4vD1f9uTVzNCw+Oc1+fU9UvGr4WVXFJ//9vrKqE6ZnGJq5/oi6NqyqxnlUdZSk1f+d1s1frNblLWrovZs6aPm+UxrQskae0xMLc+RMkmoFepGAAQAuGYkTgEs2oX+TYt8TEuCpf5/sL3/PgpMal0LW6Xx/VzftiozTWwv2Okxny8nHo/L9Vddh8kKlnZ+ud/BU7sqAu6Pi1fmVRZIypxPe9nXudWVZZm44qpkbjurpYS0UlyNhGvr+Mu0+XznQ39NNWwsYgcoacPpl/RFNnJU5FTC/va+++vegJGnJ7hMa9916rT10Rrf1qK+Xc1RwLIqwndEa9/16SdJfD/Syr72TMqccHj6dpPrVvEtkLRgAoOJjjRMA09St6q0A77wTp6eHtVANP6ueGlpwxb2aAV66vEWw3r2xvZoFZ49gvHpN9i/Zxdls9n99GxWp3aJH++i6TnWK/NyylpbHGqdL9fr83dp6NMZ+vDtHufW45DQdPZukR3/ZrK1HY3T1Jyv00E+b7NdnrIlQg6fnavKf+Y+SZVm0K7toxtpDmcU2ftt4tNjxfv7PAfvrKz5a7nDtrQV71O/tcH10vphGThml8LUDAJR/JE4AnNK9fRtrzTMDVK+QUuZZWtb018JH+mrvK8O0+YVBurZjHdUO9NKQ1sEF3lc1x/SyORMu0/05Rs/a1PbP855mwb5qUsNPfZoFOZyvW9VLfp4Ve3SroLVKvd5Yqlkbj+mqj1doy5EYe5GLnJJt2Wvinp29TWkXFI2Yvvpwns+2SNpxPFa29AxFxyXrlb92atnekwXGWlA1wE/DM5OqCzc0ztqgeHdU3qOXAIDKq2L/Hx5AuXYxU6g83Fzk4ZaZDC17sr+yBpu6NahqH73I6bfxPTVjzWGN69NINfw8JUmrJw7QtJWHdGuPejqXmq67vluviBxV5CznqwfmrFx3eYsa+mZsV7381059vfxgseOujH5YE6FG1X11V6+G9nPPz9meZ9vE1HSN+HC5rmpfS39syUzIvlp+MN/pflLm+rsLnU5I0U/rjuR7zytzd0mSJs7aptn3XVakzwEAqBwYcQJQYbm6WOzJ19dju2jaHV2179Vh+u7Obqrq46EvbuushkE+enZEK3vSJGWuv3p6WAvVqeKtpsF+WvJYX027o6vqVs0sfjHy/H5MlzXJHHEK9HbX12O6SJLu69dY7esEKMjXQ1XymYaIbF/9+5/2RWdO+ft5XUQhrWVPmrJM+mOHImPPOZxLP79hsNsFUzT3Rmeu63prwZ5C3ycxJa3QNvk5GZ+iGz9fpdmbsqcX7o2O1xt/71Zski1X+0vdZLikxSXnjhEAwIgTgErCz9Nd/ZrXkCT1bVZdG54bWOQRLTdXF/VrXkN/PdBbGyPOqvf5hCnY31PrnxsoX6ub/VnVfK36/f5ekjLXyjR6Zp7Ds6r6eOhMYqr9uHaglzzdXXTgZGYBh4cHNtX7i/Zd2octRyJjkzXovWUa3b2eflhTeOJ0oWkrD2nr0RjNuu8y7T8Rr2o+Vl07dWWeBTEGv7csz2f8seW4rmpfy+Hc3ugEpWcY+nffSXWoG6hAbw/9seW4Pl26X1NvzUy48/P6/N1ae/CM1h48o2s61nF478iYc3r/5o72tvHJNl318Qr1bVZdk65qXezPX9J+WXdET/62Vc+NaKm7exdtvR8AVBYkTgAqpYuZBhjg5a7+55OvLEG+1nzb51WUYvJVrfXAj5lFE76/s5u6N6qq1LQM/d/qCA1vG6L61Xw0pHWIhn3wb6HxtK8ToOl3d9fd361XoyAfvX5dOzV4em4xP5VzuJikKcvGiBhtjDiraz9deVH3f7/yUK7ESZKaPzffXmSjW8OqWnswc6rns7O36ZuxXe3l0cN2RqthkLea1Mjc2+xEfLL9GeF7TtgTdkm59tuavemYDp5K1MFTiU6ROD3521ZJmVMWSZwAwBGJEwCUga4Nqqhvs+oa0bamGlTz0fHYc+rTrLokyermqvH9Gtvbtqzpr5evbl3gPk2S5O/lLn9Pd/3yv9B82/x0Tw/d/MXqkvkQTuxikyZJ2nYsVqsOnHYYCZQcKxNmJU2StPLAabV4/m/1aVZdfZoG2ddFbZ00WLM2HNXRs9lTB8d+u04PXp5dcCTrkf/uO6m5WyMLLH4Sn5ymzxft15XtajmUUi+O/1t9WPHJaQ7fXxcrOi5ZK/af0hXtasnDzUWHTycq0Msj38qYAFDRkDgBQCl6/6YOmrctUu/d1EE+1sy/ctvWCVDbOgX/InxbaAOHxGn3y0O15uAZjfkme7+lOy9rmOu+1RMH6NnZ27R49wlJUsd6gRcV98e3dNTeqHh9mEe57oomJS1Do74sfnK5bO9Jh8p+7SYtzLNdzq9hVpGRrH2zcm4EnWxLV2JKmvytmcuP3w7bqxlrj+rzf/7Th6M62kfFTsan6KGfNmlEu5oa3b2+pMx1UrM3HVPb2gFqGpw58pWWnqHnzhfbuLpDLdUq4gbV+Rnx4XKdSkjRkTPndH2XOur7Vrik/Pfjykt6hsFmxADKLRInAChFIzvWtheTKK65D/bSiv2ndMdlDeXu6qK+zapr/6vDJGWuDapbNfdoRUiAp6be2lnXTl2hZjX8ZHVztV/r06y6wy/6bWsH6OjZJJ29oGBBkK+HrmhXS2on9W1eXR8s3l9o6e+6Vb105My5Atsg0585ClzEnsv+2rd4/m9J0le3Za6B2nE8e5+sB3/cJF+rq75eflAd6gZq5YHTmX/2n9Zjg5tp+urD+nbFIUnZiUzOzYptF5R9v9DZxFTd8PmqXOcNw7BPaz2VkCJJWrLnhBpWz73GyzAM/bvvlFqE+KmGv2eu64/+slkr9p/Swkf6OiSMeUlJS1dqWob8CtkgGwDKEokTADip1rUC1LqW48iU2/kS23klTVk83Fz01wO97cfLn+qvfScS1K9ZdTWcmF2s4s8HeikpNU2tXlhgP/dshzRdO7y//bhz/ar6/s5uDmunZt/XU+8v2qd/ciRTnjkSNBQsa41bfu6evkkfhEoXLsO7c9p6SdKK/aft5+Zui9TcbZF5PicuR1KWNe3QMAxN/nOn6lTx0u2hDXTP9PXq2qBqnpUGs/p85dOXO4xWuVgk1xzBJaSkaePhs0pMSdP4HzbKw9VFe88n+DnN2nhMkvT75mO6PbRBQV8C9X0zXFFxydo6abD8SyB5OhGfrE+W7NfoHvXV7PyIHAAUF+XIAaCCq1PFW/2b15DFYrGvdbmhc2a1N28PNy19vJ8616+ixwc1VQ2vzLVTBelYr4qm3dHV4dzhHPtcXSjI1yPfa3l57Zq2xWpfEaWkS5uPxF7Uvcm2dO2KjFNMjsTp5b92SpLeWbhX01Ye0itzd+mPLccVvudkoeXZP1m632HPMleLRTln2437br1u/2atxv+wUZKUWsjo1qmEVJ1LTS+wTVRcZoGNrRf5Nchp+b5Tuu2rtfpu1WENfm+ZHv15s/ZGxxd+IwBcgMQJACqRxwc31+z7euq1a7OTk4ZBPvptfE/9r0/uNVP5sVgsurlrXUnStDu6KjUt+5flhY/00eqJA9S6lr96Nw3SqokDct3/4ICm8nTP/l+Qt4erOtQN1PKn+qt2ldxrcf55op9euKJVkeMr755ce/ETQlo8/7eGffCvRn6ywn4ufM9JzVx/RB8vzV5v9fjMLUV63rnUdE0Nz75v/eGzDhUjV/13Otc9aQUkTx8u3qfeby6RJMUm2TRl/i7tjoqTJE2Zt0s3fpY9ZTAto+AkLKfElDSHPbFs6Rl66c+duvXrNdqTI1GatelYrtL0O47HaldkXJHfC0DlxFQ9AKhEXF0s6livSrHv8/d0c1gzI0mvX9dOr1/XLlfbrKlQcx/Mni746ehOen/RXl3ZrpY61quiXk2D9OigZlqx/5RCAjzVuLqvfT3N/hMJuZ5Zv5qP7uzVUC+dHzlB8T3x69aLum/WpmO5zv2x+XgeLbN1ejlMcclpcnOxaO2zA1XVx3HU8VRCqtLSM/TK3J2auSGzAMah10fo82X/ObTLOdKVn8jYc3rwx01ad+ishrcN0aejO0uSvlj2n75ZcTDf+2LP2RTg5a6k1DSN+HC5JGnPK0Md1gUCQE6MOAEACjX3wd4a0jpYv43vmef1DnUDJUkernn/b2V425pa+EhfPTCgqXo1DbKfv6xJkBpX95WUvbdW4b8qF13YI30u+Rn/d1f3EoikYslvXVWWrCQ7LcNQp5fD9Mv6I7na3DFtnWZuOGo/TkpNy9Vmx/HsUaDZm45q8Hv/KCYpVXHJmdMQ/94eqdApS7Tu0FlJ0rxtUfZCGN+tPFRgjDuOZU4DjM/xDwLJqUUf4aooUtMylJJW8NRJAJlInAAAhapb1Vuf39ZFnevnPVr10aiOGtYmRD/9r8clv1f3hlXzrbq26flBany+otuE/o3VIMc+SC+PbOPQ9rVr2qppsJ9evDL3FL+7emVPS7y2U219fltnh3NZPr6lo3o1DdLqiQPyvC5Jdap4aVS3uoV/sCJwq6Clup/MY7Tr332nHI6Pnc1dlfHdsL1KtqXrx7UReuTnLdobnaAOL4Wp3aSFOpWQomdnb891z/PnS7CfiE8pMKa8KvalZWTo2xUH1f/df3U6Ofc9GYWMgMUm2fTdykM6nVDwe0uZUyA3HD6rv7dHmZK42NIzdCzmnEKnLFa3VxcXOL0SQCam6gEALlndqt6aemvnEnmWt4eb1j07UM2em5/rWhUfDy16tK+OxZxT7UAvPTGkhX7ffEwJKWm6pVs9tarpr6d/26rnr2hl32D4us519MOaCPsUwBHtaur5K1rpscHNlJqWoUDvzGlkQ1qHKMjXqlX/ndbtPeqrV9MgebpnTtsKCfDU81e00tfLc0/9Gtmhth4f0lw/rnUcVbm2Y+08p7nl575+jfVp+IEit69oBl2w7ijL75uPaeKsbbnOd3llUZ7tf1p3pEiV8z5ask//7julOjnW1IXtjNbkPzOng/7p4qLbJP20NkJLdp/QU8Na6IbPVmlomxA1D/bTmoOn9cZ17ZSRIR04laD9JxLsCeJfW49r5r15j85mufv7dfYKieN6N1SfZtX155bjmjisparkmNpoS8/QC7/vUO+mQRretmahn+tCB08l6vfNx3RHz4YOmxWP+WatVh7IXp92JjE1zzLyRRGTlKpTCalqUsP3ou4HygsSJwCA0/Fwy9y36p+9J3VjlzoO1ywWi+pUyR5purpD9j5ZnetXUdijfR3a+3u6a9GjfbUp4qx+WX9UTwxpLikzQfO+oODf+H6N7ZUH8/LODe2143ic7r+8iX5ed0T7ouN1X//M9o8NaqZ3wvZKkvo2q64p17XV6B71dN1Ux/2RGlX30X8nE3M9+4khzSt14pSfp37LnTQVpihr4RbujJYk7cuxpu7pHAlauiF9s+KQpvy916H9jDUR9jbL953KtfZPkn3qYJbvVh7Sv/tO6ZPRHe1rqHKWlf/y34P68t/MpHzzkRgteLiP/thyXH9tjVS3BlX149oI/bg2It/NhpNt6Xr6t60a2Co4cw+2HIZ9sEzJtgwdOXNO79zY3n4+Z9IkZU+VLY7ElDSN+nK1th7NnPYY/ng/NQhy3OMrI8OQxXJxzy+Ojxbv09pDZ/T1mK7ycGNCFUoHiRMAwCl9fEtHLd93Sv2a1yiR53WsV+WiCmPkdF3nOrru/MDahQnWAwOa6o5eDfX39igNahksq5urOtevmusZM/8Xqlkbj+mr5f8pOi5zStcV7Wpe8i+WnetX0YbDZwtviCLZesZFW88nTfnJK2nKy4t/7JAkPTBjk9YcPJOrnH9Oe6MTNHdbpB76abOkzFGwLEmpafL2yP2r27SVhzRn83HN2Xxc9ap6q12dQH317386lZCqZFvmFLxNRwr+3shZkbAg8ck2vTZvl65sX0v7ohPsSZMkbTsW65A4GYah6z5bqfQMQ3Puu8yhGuOFNkac1X8nE3V95zr5tilI1j9azN8e6fCPKUBJInECADglP093DbuIqUlm8rW65frF772b2itsZ7T6NquuzvWrqJqvVeP6NNJtofV1POacXF2yR9A+uLmD/RfmLCufvlwBXu4a++3aXCMZkjSgRQ2FBHjqxi51dXWOEuRZ/u+u7rr16zUl9yFRJKcSUhTka3U4lzVqdc2nKwu8N68poZLUfvJCrX1moKr4eCglLV13fLtOZxJTHaYmXvXxCh2cMlyvzN3lcK+Xe3a1wLySpGRbhg6eSlTDC0aMLvRu2F79uPaIflx7RM9fsEVAtQuqJyakpGlTRIwk6cjZJNWvlv+zrz3/NalX1VvdGub+B4e09AxFxiYXuPm3JIetEcyWkJKm71Ye0oi2NXONxKF8InECAKAUXdOxjq7pmPtf0T3dXdWouuOakKs71NaR04l6O2yfpMxiEbUCM9fgzLy3p94L26up/xzQoFbBmrs1Ui9e2Up3XJZZtOLQqezpf3Mf7KU/thxX29oBahac/R5f3d5F7m4uGvPNWvVpVl0PD2yq1f+dltXN1b5JbnEMaR2sp4e1VEpauoa+/2+x76/Iur+2WFe1r6XZxVjnliUr2biQLd1Qx5fD1K5OgEIbV7NPt9sdFZ+r3YV2HI9TQkqaziSk6qpPlue6Pv6HDdpxPE6f3dpZQ9uE2M//tDZCLhaLUtMz5Gt1c5hmemExk6zaGYZhaOo/B1TDL3vN1JO/btXP/wvN9b5nElPl55n96+h/JxMU4u+pulUd93ObMGOjFuyIzhVf1vtl+X3zcd3QJf9iLQkpafLxcC31qYOS9NKfO/TL+qP6dOl+7XhpaKm/H0ofiRMAAE7kf30a6tSh3Vp21k+vX9fe4dojg5rpkUHNJEkvXpns8ItpgyAfPT64mQK9PdS6VoBa1wqQJJ2Iyy4P16VBFQV6e2jZE/1VM9BT7q4u6nR++qKnu4tOxKXog8X77O1bhPgpNS1D/53KvSZLkh64vKkaBvk47Lc0oEUNtazp77DZ7oXCH++nW75creOxeZSuqyDSM4yLSpqKYuvRWIcpchc6l5p3lb42Ly7Q6O71FJNky3Utq/T7vf+3QZI0676e+njJfi3ZfcKhXa8m2dsJXDj1LmvD4nWHzurNv/c4XFtz8IxW/3daHeoGytPdVQt3RCnDyHy/FiHZI2Y515ktfyJ7O4EFOzJH6776979ciVNqjoqAy/ef0ogP/9XXY7oqJMCx2MX2Y7G64qPluqFzHb16TVulZxjy8ii9fbuy1rEl5tMfKH9InAAAcDIdgww9e3svubvnXZZdkkPSlOX+y5vmOlfFx0MWi+RisdhLcNerlnu60+ju9ZWRYdgTp7a1A/TtHV0V5GvVL+uP2CvG/XB3d43+KnPqX1bZeFcXi3a9NFSr/jul7g2rycfqphY1/fTs7O36aFRHebq76sbPs4tkNAjyUdijfdX6xQUOMVgsUhGX2hSqdqCXjsXkLnFeGbR/aWG+137IUdyiINfmM50wMcd+W2/O3+1wLSuBPpuUmue9N3+xWpJjIRUp94hZll5vLVPnIBcNy/FN4Z5jrzjDMDTu+/U6leD4fjuOx+nNv3fr3Zs6OJz/5HwyP3PDUS3bd1KnE1L1x/29FHEmUUPblPy04KJs4IzyhcQJAIAKzN3VRdsnDZHFkpngFMTFxaLtk4do/4kEta8TYJ/OFHcue4SiZ+NqurdvY3m4WhzWm3h5uOryFsH24yva1dKIttlFL9xdLQ5TyHysbnKxZE/vkqQnh7TQG387/jKeZVCrYIdCCQWZMa67EpLTdM/0DUVqj6JLSskePYlPcSyOMWfzcT03Z7siCxlJzJk0FWbDKRcdybHHV1bFPMMwdOBkghbtOpHnfUl5jPLkTGSyCrMM/zBziunLI9to9YHTGt+vsdrUDsh17/ZjsXpuznY9PayFejSqVmjc6RmG0koxcUpISdPX/x7UiHYhalKj8PL7KBnUawQAoILzsbrlWY0tL75WN3WoG+iwBiTnL4AWi0VPD2uhRwc3L/RZOZ/RIsRfUmYClWXeQ711c9e66tUkSFW83XOVnq+ao9jA6O71Cn2/50a01KHXR6hn4yClXESRgFt75P8ev+SxPqcy2hOd9+iQJP255XihSdPFeOGP7EIXWSNO9/2wUQPfzXvvL0n6e0eUHv5pk46cSbKfK2gE6Pk52zV3W6Su+Mhx/dfWozE6lZCiKz5ars1HYuyjZgXZFRmnDpMzN2nOsjc63mEt1umEFF398XI99etWh/PHY87pzy3HCx2teuvv3Xpv0d4Cvwb7ouM1e9PRIldMLIqo2GT9vT2y0M2gKypGnAAAQIFGda2nv7Ye14i2tQpvnI9PR3fSe2F7dXfvRvZzLUL89fp17WQYmf86n3Ma1qvXtNHf26P0775TkqSuDXJXWsupZ+NquqtXQ/txQdXVdr88VGkZhtpcMFXwlZFt9X+rs6ey/XJPN+09kaQr2tW0b5SMsrcix55Ti3ZFa9z364s0+jhn8/HMDYDv76Wvlx/U4t15j05daPuxWFXx8dCp+JQ8K1UahiGLxWJfMyVJrWr6a1yfhrqmYx299OfOXKNxg99bpjeva6cbu2YWrnjpr53acjRWW47Gqk+z6hrRLnOq4JD3lik+JU2JKWm6uVv+ifymIzH21/O3ReaqQBqfbLNvKl3F26PEtnUY+O4/SkhJ0xvXtdVNXesp2ZauBTui1Kdp9cyvWR7VJCsSRpwAAECBArzd9dcDvQvcHLgwdat6692bOqhVLf9c1ywWiz1pGtWtntrXCdANnetqYMvMqX+NqvvIx+qmLS8M1s6Xhuix8wUyJGnmvaFa+fTl+uHu7g4jXDkrtV3Iw9VFvla3PEexssrJdwnKUMe6gbq1R3170jR1dCeHtp/d2km/je+pbg2rqnagl5Y90V9Xdyhecjn3wV4OCR8KV9Qpm5K05WisZm08WqyqkVd8tFyXvb5E/+w9mef1hhPn6ZGfN+v+GRvt53ZGxumRn7dIktxc854S+8W//9lf/775uP11zv3XshKu8D0ntS86XkPeW6a5WyNzPStnRcPxP2xUXLJNEaczR9fOJKaq7aTsdW6P/bJF13y6wl40JOJ0knYcz7+4SH7SMwwlnI9vye4TSkhJ0+vzd+uhnzbrtm/W6NsVB9XllUWaWoE38mbECQAAOI0p17a1vx7VrZ6CfK3q0ShztCnAO7MYxT19G8nfy119mlXPd9+hgS2DdVuP+nKxSN+tOmw/H+Dlbq8GN3F4y1zFEl4Z2UZDWlVXzJ51uZ45rG1Nh7VatQO91bZOgMM0vjeua+fwS3FhLMouOZ8fDzcXp9qfqLx59JctF3VfSlr+1fAKqph4YZn2LPtPJOi7lYc0pmcDh/PfrDiY+WdsF/s5Fxfp8ZlbtCc6XhNmbNSIdiNkGIa+WXFIHy7ep9hzjpUR251PlJY90T/XZsenE1N1OjFV3606pHv7Nlaft5ZKklZPHJCr8qBhGIpLTrMXfpGksGMW/fzternmGBGOik12GLHdfixO249lJqdv/L07339k+X3zMdXw81Ro48LXiTkjEicAAOCUPNxc7FOYcrK6ueb65fNCLi4WvTyyjSJjz9kTp1UTL1eVHFPufK1uWj1xgN78e7duP/88T3dX9WtWXfPyqab+y/9Cdc2nK9WjUVW1qZ179MzTPe/y1lteHCw3F4tOxqfo0/D9+mX9UUlShmHk+iU4p2s61tbLI9to/P9t0LA2NeXn6aZf1h9RiL+nZm44WuDXAJfmk6XFHzn5d99JLd2T90iVJL34xw61zmPUVZLunLbe/jrZlqGdkXH247lbI/XZPwe07VjBI0VrD51RoFfe1Thfn79b1XNMo+sxZbFWPn25Q+I+6Y8d+m7VYf31QC97kYy/IlwlnXF41pYCyuFnWbwrWqlpGfZphPui4+0bfB96fUSh9zsjEicAAFBhhfh7qnfTILm7uijE3zPXxqchAZ65ylYXpGO9Khf1S1/Wv+D7WN305vXt7YmTj9VNvZoE6cPF++Tv6aY+zarrrxxTs56/opV8rW6afld3+7kr22dOB3z+ylbaeiRWc7cd1wOXN1UNP6uaPDu/2LGh5Nz29dpC21z/2apC21y4f9aEHNMCC+LmYlFBe/s+NtNx9O3zfw7oxStby8XFoowMw/6PDA//vFl/P9S7SO+ZF1t6hu76LjMR3PT8IL21cI8257Oxc3lC4gQAACosi8XikHSUhamjO+mp37aqbZ0A+yaoF3plZBudTkhVwyAfNQzy0ez7eqp+NR89Nyd7A9j5D/V2qCx4IX9Pd/VqGqReTYPybZNToLd7rs1v/7j/Mm09Gqu3F+5RsJ+nvWreVe1r6bVr2+rmL1Zp+7G4vB4HJ/TRkn06cDLvDavz8uPaI/pu1WG9ek0bHTmTXfZ9/4kEPfTTZrWvk/foWGFyloPv+HJYrusrD5xSuzqB8rWWr1SE4hAAAAAlaFjbmtry4mD1a5Z/JbNbe9TXQwOzNyzuWK+Kqvp4OOx11bJm8X9pza/QRJf6VbTw4T65zretHaBbe9TXpucH6Zs7uqpWgKeeHNpcH47qKF+rmz64uaND+xYhhe8Z5OPhOF3Rz+qmkR1q6Zf/hWr3y0OL8Wny9n4xRggrm+IkTZKUmp65du7Z2dv12T+OUxPnbovUa/P3XFQcXV7JnSzldMuXa3TntNzrCJ1d+UrzAAAAyoELpwQW1R2XNVDYzmgNaHFx5aOfGd5SDap561hMsh4e2FST/9yhzUdi9cO47g5J2YVxWiwW1Q700sqJAxyuW92y/439oQFNdUv3eur+2mKHNs2CfbU3OsF+7ObqIilzxOGzWztpaBvHdWq9mgRp+f5TF/X5sqZJPvzz5ou6H2Ujr++1C609eKbQNs6GEScAAIBS4JJPdbWC9GwcpNUTB+iL27sU3jgPri4W3RbaQE8PayFPd1dNubad5j/UW1Y3V4fNh4sqxN9TQb5W1Q700kMDmirY3zNXm4nDWzocZ5WR93J3zZU0SdLUWzupU73AQt97ZPuaquVd+C/gv40P1YT+jfXdnd302/ie9vO39qinwa2CC70/y5NDC9/UGZUbI04AAACl4MYudTR91SENaFn0X94l5SoRXVLcXbL/vXxE25q6u3fh+0e5ubpo5dOXy2LJTgQ71gvUphwL/etW8ba/XvBwH9Wt6qVqvh66sl3ee1r5ebpr1n2Xqduri3QiPsV+3svdVZteGKQWz/9tP3dz43S9uy3z19VHBjbL9Swpc0pj5/rZGyT/OK6HFu6M0lNDM5PHUV+s1qr/8l5rZnVzUcr5Uu8+HsX/tTjAy73AqoioWEicAAAASoGfp7uWPt7voqftlbScI2BXd6iljvWqFOk+DzfHCUo/3dND0bEpGvPtWqXY0tWgmrd2TB4iVxeLvRz7MxeMQuXFO8daqGVP9Je7m8WhnHuQn1X10yUfq6sSU9I1ol1IPs9x/HU2tHE1h32CnhrWQqO/XK0R7WoqKTXdoWrhxucHqfX5/Yiq+eZfiEPK3Gy5c70qeuDHTZq7LfMZNQM8SZwqEVOn6i1btkxXXnmlatWqJYvFojlz5hR6T3h4uDp16iSr1aomTZpo2rRppR4nAADAxXCWpOlCLpcQl9XNVfWqeSvskT5a+kQ/ubm6yMfqlu8eVvl56eo2kqQHBzRVvWreqhmQuZ/QZ7d21oi2NXVf30aSpH8f76Mlj/VVkxrZhSm+uK2zagd66bfxobkffIEOdQO19tmBeuO6dvr4lk4O13ysbvpoVEfdHlpfw/KYVpjF28NVXRtUlYuLxWFj3HO2/DfJvdDXYxynX96XzyaxkvT2De2L/Nzy7ER8stkhFIupiVNiYqLat2+vTz75pEjtDx48qBEjRqh///7avHmzHn74Yd19991asGBB4TcDAABAkuybm14KN1cXWd2Klyzl1KdZde18aYgeHeQ4BW9omxB9MrqT/DwzR5L8PN3VqLqvQ5vBrUO04unLHaboFcTH6pZvEntl+1p66eo2cnWx6Ikhea9z+nFcD/vrZFuG/XXNAqZVfndnN00c1kKSNKxNyPmiGZkOThmuhkE+Du1zjsCNaJt/Eleagv2thTcqQW4u5avcgqnRDhs2TK+88oquueaaIrX/7LPP1LBhQ73zzjtq2bKl7r//fl1//fV67733SjlSAACA8m/DcwO19PF+pbaOqrgunGZXFh68vIkk2ZOanCb0b6Iq3pmbFf/7ZH/7+Zxfr8uaZO6b5ePhqreudxwZGtgyuxpis2BfjevdSLPv66n3b+6gnGmbxWLJlQx2a1hVP93TQwse7iMvj6IlpL2aFG0Pr6x4vritc4Ft3jtf6t3TvXgpwlNDc38ti8Lfs3ytGipX0a5atUoDBw50ODdkyBA9/PDD+d6TkpKilJTshYdxcZmbuNlsNtls5s9JzYrBGWKprOgD50A/mI8+cA70g/kqch/4W13kb/UoF5+ttPrh/n4NdW3HmqoV4Jnns8Mf662UtAx55UgePFwMe9vbu9dRgKeLejauphA/d3ubliF+mnpLB+2LTlBssk1B3m5KT09Tm5q+kpGhTnX91aCatxoF+chms6lBlezRnZ6Nq+qlK1vaR7CK+pmfHNw0z9LuP93dVTd/5bhPkkXSZY2qqFO9QLWu5a/pqyNy3de1XoD+uC9UXh4uGvT+inzf941rW2vetmj9sy/zvat5u2nSFS006a/dRYo7i5GRLltG0ac7lobifH9ZDMMovM5jGbBYLJo9e7ZGjhyZb5tmzZrpjjvu0MSJE+3n5s2bpxEjRigpKUleXl657pk0aZImT56c6/yMGTPk7e2d6zwAAAAgSbtjMseJWgTm/+vyymiL5h5x0fiW6arjk28zSVKGkZnAZM0a3BNrkWHk/fytZyz6ek/+I09VPAw91zFdj63JHAfpVzNDg2tnyOd8LvfQKsfxkcfapqlejkGu8EiLZh/Kfn7PGhm6qXHmNMREm/TM+uz7J7ZP05Qt2ccfhKYpNlV6bbOrQrykB9uk62Cc9NHOoo/JdKueodFNMgpvWMqSkpJ0yy23KDY2Vv7+BW86Xa5GnC7GxIkT9eijj9qP4+LiVLduXQ0ePLjQL05ZsNlsCgsL06BBg+Tu7l74DShx9IFzoB/MRx84B/rBfPSBc3CGfhhexDYvG8ZFFQIp6PnDJX39/EJJ0jUdamrR7pOKT06TJN3Wo56eGdpMbq4uenHzEiWkpOnJ63qpaXB2ZvT42jDZ0g01CvLRvAd6yvWCfcWGS/L+c5d+WHtEkjTt/iH2z5CYkqZn1i+xt73t6kGasmVp9r3DMyMfNTL7eSsOnJZ2bijyZ//hwaFFbluasmajFUW5SpxCQkIUHR3tcC46Olr+/v55jjZJktVqldWae6Gbu7u7U/1l6GzxVEb0gXOgH8xHHzgH+sF89IFzoB+klrUCNL5/U7359x79r28jdalfxZ7krHj6cp2MT1GTGo5rpuY+2Fsz1kTovv6N5WnNu9S6r2f219XDI7uNr0v2SJSrxXD4+j83omWe/dGyVqDD8aHXR6jB03Pz/UzO0qfFiaNclbIIDQ3V4sWLHc6FhYUpNLTwUpQAAABAedS2dqCaBfvpqzFd1LVBVYfRrQAv91xJkyQ1C/bTpKtaq4Zf/oVA8hsly1kB0OeCYZY6VfIerAj291Tj6nnPVXx8cDOtf26g+jevLkm6tlPtfGNyZqaOOCUkJGj//v3244MHD2rz5s2qWrWq6tWrp4kTJ+rYsWP6/vvvJUn33nuvPv74Yz355JO68847tWTJEv3yyy+aOzf/bBYAAAAoj5Y90V/7T8Y7bOhbkrwK2HurfZ0AbTkaq05BjuuvCpqS2DDIRwdOJuZ5LcjXqk9Hd9aK/afslQnLG1MTp/Xr16t//+xSj1lrkcaMGaNp06YpMjJSERHZFT8aNmyouXPn6pFHHtEHH3ygOnXq6KuvvtKQIUPKPHYAAACgNNWr5q161UqvmNkdvRpo4c4oDc9j36jv7uym8N3RSju8MbPtZQ205UiM+jevkattlup+Be8D5eXhqoGtgi8taBOZmjj169dPBRX1mzZtWp73bNq0qRSjAgAAACo+f093zX2wd57XAr09NKJtiOZl1o7Qi1e2LvR5TwxpoVMJqbqpS12H80G+ZbuxbmkpV8UhAAAAADinqj4e+vL2Lvbj92/qoOX7T+m6znVMjKrkkDgBAAAAKHEjO9bWyI7lsxBEXspVVT0AAAAAMAOJEwAAAAAUgsQJAAAAAApB4gQAAAAAhSBxAgAAAIBCkDgBAAAAQCFInAAAAACgECROAAAAAFAIEicAAAAAKASJEwAAAAAUgsQJAAAAAApB4gQAAAAAhSBxAgAAAIBCkDgBAAAAQCFInAAAAACgECROAAAAAFAIEicAAAAAKASJEwAAAAAUws3sAMqaYRiSpLi4OJMjyWSz2ZSUlKS4uDi5u7ubHU6lRB84B/rBfPSBc6AfzEcfOAf6wXyVoQ+ycoKsHKEglS5xio+PlyTVrVvX5EgAAAAAOIP4+HgFBAQU2MZiFCW9qkAyMjJ0/Phx+fn5yWKxmB2O4uLiVLduXR05ckT+/v5mh1Mp0QfOgX4wH33gHOgH89EHzoF+MF9l6APDMBQfH69atWrJxaXgVUyVbsTJxcVFderUMTuMXPz9/SvsN2R5QR84B/rBfPSBc6AfzEcfOAf6wXwVvQ8KG2nKQnEIAAAAACgEiRMAAAAAFILEyWRWq1UvvviirFar2aFUWvSBc6AfzEcfOAf6wXz0gXOgH8xHHziqdMUhAAAAAKC4GHECAAAAgEKQOAEAAABAIUicAAAAAKAQJE4AAAAAUAgSJxN98sknatCggTw9PdW9e3etXbvW7JAqjEmTJslisTj8adGihf16cnKyJkyYoGrVqsnX11fXXXedoqOjHZ4RERGhESNGyNvbWzVq1NATTzyhtLS0sv4o5cqyZct05ZVXqlatWrJYLJozZ47DdcMw9MILL6hmzZry8vLSwIEDtW/fPoc2Z86c0ejRo+Xv76/AwEDdddddSkhIcGizdetW9e7dW56enqpbt67efPPN0v5o5UZhfTB27NhcPxtDhw51aEMfXJopU6aoa9eu8vPzU40aNTRy5Ejt2bPHoU1J/R0UHh6uTp06yWq1qkmTJpo2bVppf7xyoyj90K9fv1w/D/fee69DG/rh4k2dOlXt2rWzb54aGhqq+fPn26/zc1A2CusHfg6KwYApfvrpJ8PDw8P45ptvjB07dhjjxo0zAgMDjejoaLNDqxBefPFFo3Xr1kZkZKT9z8mTJ+3X7733XqNu3brG4sWLjfXr1xs9evQwevbsab+elpZmtGnTxhg4cKCxadMmY968eUZQUJAxceJEMz5OuTFv3jzj2WefNWbNmmVIMmbPnu1w/fXXXzcCAgKMOXPmGFu2bDGuuuoqo2HDhsa5c+fsbYYOHWq0b9/eWL16tfHvv/8aTZo0MUaNGmW/HhsbawQHBxujR482tm/fbvz444+Gl5eX8fnnn5fVx3RqhfXBmDFjjKFDhzr8bJw5c8ahDX1waYYMGWJ8++23xvbt243Nmzcbw4cPN+rVq2ckJCTY25TE30H//fef4e3tbTz66KPGzp07jY8++shwdXU1/v777zL9vM6qKP3Qt29fY9y4cQ4/D7Gxsfbr9MOl+eOPP4y5c+cae/fuNfbs2WM888wzhru7u7F9+3bDMPg5KCuF9QM/B0VH4mSSbt26GRMmTLAfp6enG7Vq1TKmTJliYlQVx4svvmi0b98+z2sxMTGGu7u7MXPmTPu5Xbt2GZKMVatWGYaR+cuni4uLERUVZW8zdepUw9/f30hJSSnV2CuKC39pz8jIMEJCQoy33nrLfi4mJsawWq3Gjz/+aBiGYezcudOQZKxbt87eZv78+YbFYjGOHTtmGIZhfPrpp0aVKlUc+uGpp54ymjdvXsqfqPzJL3G6+uqr872HPih5J06cMCQZ//zzj2EYJfd30JNPPmm0bt3a4b1uuukmY8iQIaX9kcqlC/vBMDJ/YXzooYfyvYd+KHlVqlQxvvrqK34OTJbVD4bBz0FxMFXPBKmpqdqwYYMGDhxoP+fi4qKBAwdq1apVJkZWsezbt0+1atVSo0aNNHr0aEVEREiSNmzYIJvN5vD1b9GiherVq2f/+q9atUpt27ZVcHCwvc2QIUMUFxenHTt2lO0HqSAOHjyoqKgoh697QECAunfv7vB1DwwMVJcuXextBg4cKBcXF61Zs8bepk+fPvLw8LC3GTJkiPbs2aOzZ8+W0acp38LDw1WjRg01b95c48eP1+nTp+3X6IOSFxsbK0mqWrWqpJL7O2jVqlUOz8hqw/9H8nZhP2T54YcfFBQUpDZt2mjixIlKSkqyX6MfSk56erp++uknJSYmKjQ0lJ8Dk1zYD1n4OSgaN7MDqIxOnTql9PR0h29ASQoODtbu3btNiqpi6d69u6ZNm6bmzZsrMjJSkydPVu/evbV9+3ZFRUXJw8NDgYGBDvcEBwcrKipKkhQVFZVn/2RdQ/Flfd3y+rrm/LrXqFHD4bqbm5uqVq3q0KZhw4a5npF1rUqVKqUSf0UxdOhQXXvttWrYsKEOHDigZ555RsOGDdOqVavk6upKH5SwjIwMPfzww7rsssvUpk0bSSqxv4PyaxMXF6dz587Jy8urND5SuZRXP0jSLbfcovr166tWrVraunWrnnrqKe3Zs0ezZs2SRD+UhG3btik0NFTJycny9fXV7Nmz1apVK23evJmfgzKUXz9I/BwUB4kTKqRhw4bZX7dr107du3dX/fr19csvv1SYH17gYtx88832123btlW7du3UuHFjhYeHa8CAASZGVjFNmDBB27dv1/Lly80OpVLLrx/uuece++u2bduqZs2aGjBggA4cOKDGjRuXdZgVUvPmzbV582bFxsbq119/1ZgxY/TPP/+YHValk18/tGrVip+DYmCqngmCgoLk6uqaq3JMdHS0QkJCTIqqYgsMDFSzZs20f/9+hYSEKDU1VTExMQ5tcn79Q0JC8uyfrGsovqyvW0Hf9yEhITpx4oTD9bS0NJ05c4a+KSWNGjVSUFCQ9u/fL4k+KEn333+//vrrLy1dulR16tSxny+pv4Pya+Pv788/EOWQXz/kpXv37pLk8PNAP1waDw8PNWnSRJ07d9aUKVPUvn17ffDBB/wclLH8+iEv/Bzkj8TJBB4eHurcubMWL15sP5eRkaHFixc7zDdFyUlISNCBAwdUs2ZNde7cWe7u7g5f/z179igiIsL+9Q8NDdW2bdscfoEMCwuTv7+/fWgbxdOwYUOFhIQ4fN3j4uK0Zs0ah697TEyMNmzYYG+zZMkSZWRk2P8iDw0N1bJly2Sz2extwsLC1Lx5c6aIXYSjR4/q9OnTqlmzpiT6oCQYhqH7779fs2fP1pIlS3JNayypv4NCQ0MdnpHVhv+PZCqsH/KyefNmSXL4eaAfSlZGRoZSUlL4OTBZVj/khZ+DAphdnaKy+umnnwyr1WpMmzbN2Llzp3HPPfcYgYGBDhVLcPEee+wxIzw83Dh48KCxYsUKY+DAgUZQUJBx4sQJwzAyS6DWq1fPWLJkibF+/XojNDTUCA0Ntd+fVXpz8ODBxubNm42///7bqF69OuXICxEfH29s2rTJ2LRpkyHJePfdd41NmzYZhw8fNgwjsxx5YGCg8fvvvxtbt241rr766jzLkXfs2NFYs2aNsXz5cqNp06YOpbBjYmKM4OBg47bbbjO2b99u/PTTT4a3tzelsM8rqA/i4+ONxx9/3Fi1apVx8OBBY9GiRUanTp2Mpk2bGsnJyfZn0AeXZvz48UZAQIARHh7uUN43KSnJ3qYk/g7KKv/7xBNPGLt27TI++eSTCln+92IV1g/79+83XnrpJWP9+vXGwYMHjd9//91o1KiR0adPH/sz6IdL8/TTTxv//POPcfDgQWPr1q3G008/bVgsFmPhwoWGYfBzUFYK6gd+DoqHxMlEH330kVGvXj3Dw8PD6Natm7F69WqzQ6owbrrpJqNmzZqGh4eHUbt2beOmm24y9u/fb79+7tw547777jOqVKlieHt7G9dcc40RGRnp8IxDhw4Zw4YNM7y8vIygoCDjscceM2w2W1l/lHJl6dKlhqRcf8aMGWMYRmZJ8ueff94IDg42rFarMWDAAGPPnj0Ozzh9+rQxatQow9fX1/D39zfuuOMOIz4+3qHNli1bjF69ehlWq9WoXbu28frrr5fVR3R6BfVBUlKSMXjwYKN69eqGu7u7Ub9+fWPcuHG5/sGGPrg0eX39JRnffvutvU1J/R20dOlSo0OHDoaHh4fRqFEjh/eo7Arrh4iICKNPnz5G1apVDavVajRp0sR44oknHPavMQz64VLceeedRv369Q0PDw+jevXqxoABA+xJk2Hwc1BWCuoHfg6Kx2IYhlF241sAAAAAUP6wxgkAAAAACkHiBAAAAACFIHECAAAAgEKQOAEAAABAIUicAAAAAKAQJE4AAAAAUAgSJwAAAAAoBIkTAAAAABSCxAkA4LQaNGig999/v8jtw8PDZbFYFBMTU2oxAQAqJxInAMAls1gsBf6ZNGnSRT133bp1uueee4rcvmfPnoqMjFRAQMBFvV9xfPnll2rfvr18fX0VGBiojh07asqUKfbrY8eO1ciRI0s9DgBA2XAzOwAAQPkXGRlpf/3zzz/rhRde0J49e+znfH197a8Nw1B6errc3Ar/X1D16tWLFYeHh4dCQkKKdc/F+Oabb/Twww/rww8/VN++fZWSkqKtW7dq+/btpf7eAABzMOIEALhkISEh9j8BAQGyWCz24927d8vPz0/z589X586dZbVatXz5ch04cEBXX321goOD5evrq65du2rRokUOz71wqp7FYtFXX32la665Rt7e3mratKn++OMP+/ULp+pNmzZNgYGBWrBggVq2bClfX18NHTrUIdFLS0vTgw8+qMDAQFWrVk1PPfWUxowZU+Bo0R9//KEbb7xRd911l5o0aaLWrVtr1KhRevXVVyVJkyZN0nfffafff//dPuoWHh4uSTpy5IhuvPFGBQYGqmrVqrr66qt16NAh+7OzRqomT56s6tWry9/fX/fee69SU1MvrnMAACWCxAkAUCaefvppvf7669q1a5fatWunhIQEDR8+XIsXL9amTZs0dOhQXXnllYqIiCjwOZMnT9aNN96orVu3avjw4Ro9erTOnDmTb/ukpCS9/fbbmj59upYtW6aIiAg9/vjj9utvvPGGfvjhB3377bdasWKF4uLiNGfOnAJjCAkJ0erVq3X48OE8rz/++OO68cYb7UlaZGSkevbsKZvNpiFDhsjPz0///vuvVqxYYU/mciZGixcv1q5duxQeHq4ff/xRs2bN0uTJkwuMCQBQygwAAErQt99+awQEBNiPly5dakgy5syZU+i9rVu3Nj766CP7cf369Y333nvPfizJeO655+zHCQkJhiRj/vz5Du919uxZeyySjP3799vv+eSTT4zg4GD7cXBwsPHWW2/Zj9PS0ox69eoZV199db5xHj9+3OjRo4chyWjWrJkxZswY4+effzbS09PtbcaMGZPrGdOnTzeaN29uZGRk2M+lpKQYXl5exoIFC+z3Va1a1UhMTLS3mTp1quHr6+vwfABA2WLECQBQJrp06eJwnJCQoMcff1wtW7ZUYGCgfH19tWvXrkJHnNq1a2d/7ePjI39/f504cSLf9t7e3mrcuLH9uGbNmvb2sbGxio6OVrdu3ezXXV1d1blz5wJjqFmzplatWqVt27bpoYceUlpamsaMGaOhQ4cqIyMj3/u2bNmi/fv3y8/PT76+vvL19VXVqlWVnJysAwcO2Nu1b99e3t7e9uPQ0FAlJCToyJEjBcYFACg9FIcAAJQJHx8fh+PHH39cYWFhevvtt9WkSRN5eXnp+uuvL3Qtj7u7u8OxxWIpMFnJq71hGMWMPm9t2rRRmzZtdN999+nee+9V79699c8//6h///55tk9ISFDnzp31ww8/5LpW3EIYAICyReIEADDFihUrNHbsWF1zzTWSMpOKnEUSykJAQICCg4O1bt069enTR5KUnp6ujRs3qkOHDsV6VqtWrSRJiYmJkjIr/KWnpzu06dSpk37++WfVqFFD/v7++T5ry5YtOnfunLy8vCRJq1evlq+vr+rWrVusmAAAJYepegAAUzRt2lSzZs3S5s2btWXLFt1yyy0FjhyVlgceeEBTpkzR77//rj179uihhx7S2bNnZbFY8r1n/Pjxevnll7VixQodPnxYq1ev1u23367q1asrNDRUUmZFwK1bt2rPnj06deqUbDabRo8eraD/b+8OWRULwjCOP3vSQSzitdpUThUNKmhQOEkFRUWDCAebWI0Gu8kP4KcwiIIogl2wHgQ/gFEN7raFDcvActHL3v+vz8ybzuFh3pn5+FC1WtVut5Pv+9psNhoOh7pcLr/nfzwe8jxPp9NJi8VC4/FYg8FAlsVvGwDehS8wAOAtptOpQqGQstmsyuWyXNdVMpl8eR2j0UjtdlvdbleZTEbBYFCu68q27b+OKZVKOhwOajQaisfjqtfrsm1b6/Va4XBYktTv95VIJJRKpRSJRLTf7xUIBLTdbhWNRlWr1eQ4jjzP0+12+2MHqlgsKhaLKZ/Pq9VqqVKp/PMjwgCAz/Hj52c1egMA8B94Pp9yHEfNZlOTyeTl6/d6PV2vV+OV6ACA1+KMEwDgWzufz1oulyoUCrrf75rNZvJ9X51O592lAQC+EFr1AADfmmVZms/nSqfTyuVyOh6PWq1Wchzn3aUBAL4QWvUAAAAAwIAdJwAAAAAwIDgBAAAAgAHBCQAAAAAMCE4AAAAAYEBwAgAAAAADghMAAAAAGBCcAAAAAMCA4AQAAAAABr8AYcKx9lrs2eQAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Training Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss over Steps\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Validation dataset + loader ===\n",
        "val_batch_size = 8     # tune: how many samples on GPU at once (dataset returns batch-shaped tensors)\n",
        "val_block_size = block_size\n",
        "val_dataset = GPUBatchDataset(val_ids, val_block_size, val_batch_size, device, pad_len=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0)  # dataset already returns batch-shaped tensors\n",
        "\n",
        "# === Eval function ===\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def evaluate_model(model, val_loader, eval_iters=None, device=device):\n",
        "    \"\"\"\n",
        "    Evaluate model over `eval_iters` batches from val_loader (if None: full val loader).\n",
        "    Returns average loss (float).\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "\n",
        "          logits, loss = model(xb[0], yb[0])\n",
        "          losses.append(float(loss.item()))\n",
        "\n",
        "          if eval_iters is not None and len(losses) >= eval_iters:\n",
        "              break\n",
        "\n",
        "    model.train()\n",
        "    if len(losses) == 0:\n",
        "        return float('nan')\n",
        "    return float(sum(losses) / len(losses))\n",
        "\n",
        "# === Run validation ===\n",
        "# Quick eval over e.g. 50 validation batches (adjust as desired)\n",
        "val_loss = evaluate_model(model, val_loader, eval_iters=50)\n",
        "print(f\"Validation loss (avg over 50 batches): {val_loss:.4f}\")\n",
        "\n",
        "# Or run over the entire val set (slower)\n",
        "# val_loss_full = evaluate_model(model, val_loader, eval_iters=None)\n",
        "# print(f\"Validation loss (full val set): {val_loss_full:.4f}\")\n",
        "\n",
        "# Optionally compute perplexity\n",
        "val_ppl = math.exp(val_loss) if not math.isinf(val_loss) else float('inf')\n",
        "print(f\"Validation perplexity (approx): {val_ppl:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPAnSm2UigIW",
        "outputId": "a3408333-62ac-4ea1-d35e-32585efc6791"
      },
      "id": "bPAnSm2UigIW",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss (avg over 50 batches): 1.7040\n",
            "Validation perplexity (approx): 5.4960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "de2df560-2ff1-441c-a178-228ec4ed13b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de2df560-2ff1-441c-a178-228ec4ed13b5",
        "outputId": "764e6675-ef17-405b-8cdf-e7992ea338d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "I lay, my humours: and which rise prize,\n",
            "It talk on all with us: I my leave a slain.\n",
            "\n",
            "This bayss am fullow; yest stindesteem:\n",
            "Mast; the mork voice: I have more come man?\n",
            "\n",
            "PETRUCHIO:\n",
            "Ay, on the gallant-waves Claudio taunts,\n",
            "As you have on to vencaster, that we you dic,\n",
            "May encerripe, and say you covether off.\n",
            "\n",
            "BENVOLIO:\n",
            "Stay your dwess'd, bring about, she\n",
            "hatten our foes at the prettiest do here.\n",
            "\n",
            "ESCALUS:\n",
            "Love, away: he is before: yet they will do.\n",
            "\n",
            "Messenger:\n",
            "And I have good morrow she has done, and tood couldsward;\n",
            "Once, sir, you have pay your adventure\n",
            "Henry little will to use.\n",
            "\n",
            "ESCALUS:\n",
            "any good day.\n",
            "\n",
            "FROLAN:\n",
            "Ay, ta' the choice!\n",
            "\n",
            "ELBOW:\n",
            "WAy nondron.\n",
            "\n",
            "SICINIUS:\n",
            "You play he will hear him now; but insolation, I'll enter your walls.\n",
            "\n",
            "ABOTHUMERLAND:\n",
            "I shout you him nigh, you have know your heart out,\n",
            "As if brotherhoyed as himself beloved him;\n",
            "Lest for a nobility,--sort are my concerns plain;\n",
            "Notion, V: because hyoung fair body's velve!\n",
            "\n",
            "Clown:\n",
            "So close, true! O sGones!\n",
            "\n",
            "MENENIUS:\n",
            "I promish you?\n",
            "\n",
            "MENENIUS:\n",
            "Not, he he did content. Quit up,\n",
            "All's by home but a tink you!\n",
            "\n",
            "CAYISLadtCalI:\n",
            "Ah, yourself you under here!\n",
            "\n",
            "Senator, Perceive yourself cannot lose your block, not to t yreater for your liege,\n",
            "As he must fall outsmnmombers you welcome, lady?\n",
            "Eitors from France: set to your lives? Here's your father;\n",
            "Claudio must have been your guests allied; but remains,\n",
            "and like you with purple patience creature's scrook your hands lodging sour.\n",
            "\n",
            "Clown:\n",
            "Indeed, to the Mercutio's.\n",
            "\n",
            "COMINIUS:\n",
            "Who are made her love drawn\n",
            "From Rome instruct her.\n",
            "\n",
            "ESCALUS:\n",
            "You are not so, farewell.\n",
            "\n",
            "MENENIUS:\n",
            "You are to-solemnitations an\n",
            "He cannot mutity? Once-banished friendly\n",
            "Unforce your pride. Marcius blood! and by! partake\n",
            "you so that you urge and your sword and twenty years all the house of Elies; marry, answer'd or chair, stand and be at myself.\n",
            "\n",
            "POMPEY:\n",
            "Pompey.\n",
            "I would not, sir, nor the bannibal.\n",
            "See, where despair at thy sweet lip, and then\n",
            "Be the of ane enlarcten thus.\n",
            "\n",
            "BRUTUS:\n",
            "Merry of them!\n",
            "Cannot ne, so aught no less.\n",
            "In depeal'd till,\n",
            "No, at a lechband, some other's sisters\n",
            "The new down to that.\n",
            "\n",
            "ANGENO:\n",
            "I complaint, bid your course, know their heart-prue.\n",
            "\n",
            "LUCIO:\n",
            "For what any her face to make a brawling teath\n",
            "Buckold's worship in revolt without it: it wishing here;\n",
            "well with the dead; some sole till my brother;\n",
            "nover and the swords o''ll a rejoice.\n",
            "But what unseen tlain! with request friends,\n",
            "Return time is doing. But ever the duke's truth:\n",
            "Or happy by that are hundred no greyt were there,\n",
            "then say that Perdita, poor home for Tybalt's dead;\n",
            "And it is something councils, pensiws for a league:\n",
            "And now in her met these-wouldst bed, seen,\n",
            "'I slew before our hands: come,' I pay a dust.\n",
            "Edward faith, petty your suints made soft again,\n",
            "Betweent thee as you. Tomercary receive, fair myself\n",
            "beseech your friar: 'tis never cheque he is believe\n",
            "not, and waken, and ssaint, it seems secret contrasing\n",
            "Herein exceet, respected\n",
            "Yourself against us all, that wilt being tell\n",
            "Their ruzards to use us. Courage to the procon that\n",
            "astlingalling; eyes, compell'd less; but that's\n",
            "edicucide these sorrah painting on his curbs well\n",
            "pleases, but rightly neck dey, being over-matics now,\n",
            "and as if bire his neck, had he not breed eyes,\n",
            "even since reprever a gentlerworn.\n",
            "Yet madam 'that mal feel, do the power and pays\n",
            "Before the impart, given all things fire,\n",
            "Which is enscuse him king. If these am I\n",
            "Than strentunation and\n",
            "An often have breather. He's dead lords made with\n",
            "signorance is in the streetness of their untind\n",
            "Of bids swift, scrept with such charity,\n",
            "Against the exmers may black a flattering,\n",
            "A crown trembing me wish'd; for our king;\n",
            "Make is o'er the prince: sent no other,\n",
            "O'ercolend, betructions, these longs proportion!\n",
            "O woful and exactly applied; not, where dangerous o'erwhel's place.\n",
            "\n",
            "Clown:\n",
            "makering good madam, sir?\n",
            "\n",
            "ELBOW:\n",
            "TATy: I hope is vein by voices false as stand\n",
            "By his used up.\n",
            "\n",
            "MENENIUS:\n",
            "Hath mady a prince's broating here,\n",
            "To slends the worthy right; or 'fore stopp'd\n",
            "A merry and gladly in her fault,\n",
            "Of hopeful seat,--\n",
            "\n",
            "First our tongue curses in Rome\n",
            "Shall be half a saint.\n",
            "\n",
            "MENENIUS:\n",
            "Margaret.\n",
            "\n",
            "COMINIUS:\n",
            "It is your face,\n",
            "Say; you are to church out\n",
            "With first, or else have lent hem die;\n",
            "And he's a lawful hovei-ly begin.\n",
            "If he as he did I till the allowing ride,\n",
            "Yet together to meet it do.\n",
            "\n",
            "PAULINA:\n",
            "Sir, I'll try when after this once,\n",
            "I hold attend my hat.\n",
            "\n",
            "COMINIUS:\n",
            "If, thus,\n",
            "Custuines something command, some set incline,--\n",
            "Have seizedness to the country here,\n",
            "Or else for I cannot to quit the officers,\n",
            "Measure of the city birth; who knows that loss\n",
            "Before the enemy instrument.\n",
            "\n",
            "First Citizen:\n",
            "Your battations and servants, take my love\n",
            "Unless a might as time it calling in work\n",
            "Shall know mine eyes to get tis fray,\n",
            "From me and the issue of louts that I did remember\n",
            "heavy at our love wife; but, be gone,'\n",
            "That cannot celer to bed, for rear their's privilege.\n",
            "\n",
            "CORIOLANUS:\n",
            "Bind take him hence; that English cheerfully\n",
            "That our Soverby thee: take another kin,\n",
            "Now creature to tumbling us: but we troubloud and\n",
            "down trains with a round report take a brawl.\n",
            "Now, to thy haten narr'd, to party my signans;\n",
            "I somewith no rets from our griefs may know\n",
            "Had been dear\n",
            "Suggest forbid its ill appear tods!\n",
            "See, stay but thou nea there, and two,\n",
            "To see if this, neighbourds unto myself.\n",
            "You are affections are but an estrained with\n",
            "His revenges about as is Caius Eearthly;\n",
            "Why, then, what thou these instancell'd thee; if\n",
            "The consisting of the town was no better:\n",
            "Selding in the new in the last from hence:\n",
            "He lent us suppositions; he speaks their love,\n",
            "And to give un, postersual impatience.\n",
            "Heaven already: counsels and haughter slain.\n",
            "Call him his welcome: Coriolanus a birigen cast,\n",
            "Doth at it yeter young fright should have lives\n",
            "When they have poisons of her expulsion:\n",
            "The people him in a his deposed;\n",
            "Our doubt theutous where the baser sobereign;\n",
            "And, if your provant to't,--let soul, with your blood\n",
            "Who other in that neck, not easy given out\n",
            "Lest up; whiles my excels that hath delectable.\n",
            "Which we call thee or ineforth my daughter. Then,\n",
            "Is desire pardon' take way swear to me not.\n",
            "\n",
            "YORK:\n",
            "So ppression the grave with the present up;\n",
            "For Warwick victure to the will-fase; he would not run,\n",
            "And am would think, Dusbanding and suffer'd.\n",
            "I'll were aweless what Ihomas tell thee:--\n",
            "My soul like nature, I, would not but the scale:\n",
            "For never did become as laughreased them that.\n",
            "\n",
            "Honour,Richard: the Oxbeth me, my lord, there entreaties to north sorrow back with no issue.\n",
            "A knight, the unaching on the year or dare the gold:\n",
            "then, as I, hence peradventure. What, court's hand, how\n",
            "to the lengtal bear crimets my taken, it is appeals\n",
            "memnagateful and deserves friends: nay, I love you the\n",
            "contradict; and yours, our dusting are grown penaing\n",
            "consciinge nothing have\n",
            "But lesser spite, let them you learn. Art thy faults,\n",
            "If he did rent their great petruchio I\n",
            "Till Bolingbroke: then but only shall be pluck as\n",
            "lade overcheken: therefore you minds in puriast;\n",
            "and stay thee in the time-joyful tongue-bred up;\n",
            "Nor many apparel of this lean as dream?\n",
            "Now, by that herein learnal and his reverence;\n",
            "Not with such dead my past it importune,\n",
            "Brown leads up the least their services;\n",
            "A man did for their estate thus.\n",
            "I perform me, have attending tale tell thee last,\n",
            "Should to heave the rooting rarecrow.\n",
            "Verona take it ourselves, my charity\n",
            "Let us sour people their wits\n",
            "Abate fished with aly done. As it we march!\n",
            "They but cannot think then to bids it to-morrows:\n",
            "And so stumble then, asones, as some words;\n",
            "And never will I like to come, so then so revirl.\n",
            "\n",
            "HASTINGS:\n",
            "O, then, my armour thou art that; by your eyes:\n",
            "He should be ruly: 'twere, to tire their learn\n",
            "That thou dost soon peril of this place\n",
            "At the expect their past time their land;\n",
            "And thus I there's and strength in a children\n",
            "Till steep us all could will ill fall out appeal.\n",
            "\n",
            "My words all the shame with this father did brongs together, pain. Triught, doth us good well\n",
            "Is truth them and in thee. But let your sweet as leading and\n",
            "A behavior, point-place to-morrow in all trachers\n",
            "From all the Volsces wrongs that the people,\n",
            "Noughts  remove his head in peace a grace,\n",
            "that these brief\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "def decode_chars(token_ids, itos):\n",
        "    \"\"\"\n",
        "    Decodes a list of character token IDs into a string.\n",
        "    \"\"\"\n",
        "    return ''.join([itos[i] for i in token_ids])\n",
        "\n",
        "def encode_chars(text, stoi):\n",
        "    \"\"\"\n",
        "    Encodes a string into a list of token IDs, one per character.\n",
        "    \"\"\"\n",
        "    return [stoi.get(c, 0) for c in text]\n",
        "\n",
        "\n",
        "def decode_sequence_char(\n",
        "    model, stoi, itos, prompt, max_new_tokens=100, block_size=256,\n",
        "    use_fenchel=False, tau=1.0, fenchel_iters=3, temperature=1.0\n",
        "):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    max_ctx = int(block_size)\n",
        "\n",
        "    # ?1 assume space token exists; fallback to 0 if missing\n",
        "    space_id = stoi.get(' ', 0)\n",
        "\n",
        "    # encode prompt\n",
        "    start_ids = torch.tensor([encode_chars(prompt, stoi)], dtype=torch.long, device=device)\n",
        "\n",
        "    # prepend the pad once; from now on the window just slides\n",
        "\n",
        "    idx = start_ids\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        context = idx[:, -max_ctx:]  # rotating buffer: last pad_len+block_size tokens\n",
        "        logits, _ = model(context)\n",
        "        last_logits = logits[:, -1, :]\n",
        "        probs = torch.softmax(last_logits / temperature, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "        idx = torch.cat([idx, next_token], dim=1)\n",
        "\n",
        "    # drop the initial pad when returning the string\n",
        "    out_tokens = idx[0].tolist()\n",
        "    return decode_chars(out_tokens, itos)\n",
        "with open(\"./babylm_char_tokenized/meta.pkl\", \"rb\") as f:\n",
        "    meta = pickle.load(f)\n",
        "stoi = meta[\"stoi\"]\n",
        "itos = meta[\"itos\"]\n",
        "\n",
        "prompt = \"ROMEO\"\n",
        "generated = decode_sequence_char(\n",
        "    model=model,\n",
        "    stoi=stoi,\n",
        "    itos=itos,\n",
        "    prompt=prompt,\n",
        "    max_new_tokens=8192,\n",
        "    block_size=1024,\n",
        "    use_fenchel=False,\n",
        "    tau=1.5,\n",
        "    fenchel_iters=2,\n",
        "    temperature=1.0\n",
        ")\n",
        "\n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "def decode_chars(token_ids, itos):\n",
        "    \"\"\"\n",
        "    Decodes a list of character token IDs into a string.\n",
        "    \"\"\"\n",
        "    return ''.join([itos[i] for i in token_ids])\n",
        "\n",
        "def encode_chars(text, stoi):\n",
        "    \"\"\"\n",
        "    Encodes a string into a list of token IDs, one per character.\n",
        "    \"\"\"\n",
        "    return [stoi.get(c, 0) for c in text]\n",
        "\n",
        "\n",
        "def decode_sequence_char(\n",
        "    model, stoi, itos, prompt, max_new_tokens=100, block_size=256,\n",
        "    use_fenchel=False, tau=1.0, fenchel_iters=3, temperature=1.0\n",
        "):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    max_ctx = int(block_size)\n",
        "\n",
        "    # ?1 assume space token exists; fallback to 0 if missing\n",
        "    space_id = stoi.get(' ', 0)\n",
        "\n",
        "    # encode prompt\n",
        "    start_ids = torch.tensor([encode_chars(prompt, stoi)], dtype=torch.long, device=device)\n",
        "\n",
        "    # prepend the pad once; from now on the window just slides\n",
        "\n",
        "    idx = start_ids\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        context = idx[:, -max_ctx:]  # rotating buffer: last pad_len+block_size tokens\n",
        "        logits, _ = model(context)\n",
        "        last_logits = logits[:, -1, :]\n",
        "        probs = torch.softmax(last_logits / temperature, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "        idx = torch.cat([idx, next_token], dim=1)\n",
        "\n",
        "    # drop the initial pad when returning the string\n",
        "    out_tokens = idx[0].tolist()\n",
        "    return decode_chars(out_tokens, itos)\n",
        "with open(\"./babylm_char_tokenized/meta.pkl\", \"rb\") as f:\n",
        "    meta = pickle.load(f)\n",
        "stoi = meta[\"stoi\"]\n",
        "itos = meta[\"itos\"]\n",
        "\n",
        "prompt = \"ROMEO\"\n",
        "generated = decode_sequence_char(\n",
        "    model=model,\n",
        "    stoi=stoi,\n",
        "    itos=itos,\n",
        "    prompt=prompt,\n",
        "    max_new_tokens=1024,\n",
        "    block_size=1024,\n",
        "    use_fenchel=False,\n",
        "    tau=1.5,\n",
        "    fenchel_iters=2,\n",
        "    temperature=0.0001\n",
        ")\n",
        "\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzIJQ5lGy0DB",
        "outputId": "4738acd9-d278-44cb-940d-3faa49264ba3"
      },
      "id": "MzIJQ5lGy0DB",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "O ROLENG:\n",
            "O God deny the prince that the orade\n",
            "Of wither the prince that would speak their seat stin stin seckerthy secke them.\n",
            "\n",
            "CLIFFORD:\n",
            "An I'll to the people fitted by the state,\n",
            "The world for some other rearming stain\n",
            "As enemy the worldiverch our fresrate,\n",
            "And the sea, and the sea root of him.\n",
            "\n",
            "ROMEO:\n",
            "And therefore the seat of the princes have seen\n",
            "so long shall be so study in all allest me,\n",
            "And he shall have the world and speak a present\n",
            "Than the seals of their spirits of his life,\n",
            "And then the seal of distress and here are not.\n",
            "\n",
            "KING RICHARD III:\n",
            "Then we have spent against your stain thee.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "And then I were said, and make haste,\n",
            "The law hath best a present death,\n",
            "And he should be hus a traitor of his presence\n",
            "Than the seal of death and deserves it that\n",
            "Be solel, and you shall have you are a bands\n",
            "And send him that you will reve away.\n",
            "\n",
            "CLAUDIO:\n",
            "I would they have a languance and your common\n",
            "penalty and your honour and his lipp'd his lands,\n",
            "and the air on my soul to the purpose.\n",
            "\n",
            "ROMEO:\n",
            "A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "def decode_chars(token_ids, itos):\n",
        "    \"\"\"\n",
        "    Decodes a list of character token IDs into a string.\n",
        "    \"\"\"\n",
        "    return ''.join([itos[i] for i in token_ids])\n",
        "\n",
        "def encode_chars(text, stoi):\n",
        "    \"\"\"\n",
        "    Encodes a string into a list of token IDs, one per character.\n",
        "    \"\"\"\n",
        "    return [stoi.get(c, 0) for c in text]\n",
        "\n",
        "\n",
        "def decode_sequence_char(\n",
        "    model, stoi, itos, prompt, max_new_tokens=100, block_size=256,\n",
        "    use_fenchel=False, tau=1.0, fenchel_iters=3, temperature=1.0\n",
        "):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    max_ctx = int(block_size)\n",
        "\n",
        "    # ?1 assume space token exists; fallback to 0 if missing\n",
        "    space_id = stoi.get(' ', 0)\n",
        "\n",
        "    # encode prompt\n",
        "    start_ids = torch.tensor([encode_chars(prompt, stoi)], dtype=torch.long, device=device)\n",
        "\n",
        "    # prepend the pad once; from now on the window just slides\n",
        "\n",
        "    idx = start_ids\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        context = idx[:, -max_ctx:]  # rotating buffer: last pad_len+block_size tokens\n",
        "        logits, _ = model(context)\n",
        "        last_logits = logits[:, -1, :]\n",
        "        probs = torch.softmax(last_logits / temperature, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "        idx = torch.cat([idx, next_token], dim=1)\n",
        "\n",
        "    # drop the initial pad when returning the string\n",
        "    out_tokens = idx[0].tolist()\n",
        "    return decode_chars(out_tokens, itos)\n",
        "with open(\"./babylm_char_tokenized/meta.pkl\", \"rb\") as f:\n",
        "    meta = pickle.load(f)\n",
        "stoi = meta[\"stoi\"]\n",
        "itos = meta[\"itos\"]\n",
        "\n",
        "prompt = \"ROMEO:\"\n",
        "generated = decode_sequence_char(\n",
        "    model=model,\n",
        "    stoi=stoi,\n",
        "    itos=itos,\n",
        "    prompt=prompt,\n",
        "    max_new_tokens=1024,\n",
        "    block_size=1024,\n",
        "    use_fenchel=False,\n",
        "    tau=1.5,\n",
        "    fenchel_iters=2,\n",
        "    temperature=2.5\n",
        ")\n",
        "\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiy3pndLy2-i",
        "outputId": "81176d17-32b2-46a4-ccfb-247c5b47872f"
      },
      "id": "aiy3pndLy2-i",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "AJSPAT:TINo, IO,;--\n",
            "W PThioh,<unk>LeO\n",
            "Tmap!\n",
            "Oh,lgoy;ou', wall:\n",
            "prief Roverlover,!No!\n",
            "AngscomXtXUet,Herule,\n",
            "INAO:\n",
            "TrOLLOUARk\n",
            "\n",
            "Thnrtok,UMBlusnd;\n",
            "Cwape timGorneTmurders bRain:\n",
            "ELnsby-came?\n",
            "\n",
            "DUCmoFher.then'd,eo; Somour'ds die:\n",
            "Trembthins!'\n",
            "Bield foute, ES3WhNowaluous C:C,re,\n",
            "thus st ethamWarwicvcoving bleckedn-a-tchilshs!'\n",
            "Alaume!\n",
            "Stop? aadops look;\n",
            "Devour can.! time equaIPritevablock liza you.You, ifr\n",
            "Your, hold'st MABY:\n",
            "'GFive you, AhZbetter; mock'st you, Rutabler!\n",
            "Voicinix!-juiMO?aked tRixen-whzhick.\n",
            "Beins of Hereford, 'tis motheBiddgeds hundred, you-jest-haFore hire;\n",
            "Make nine, or'sely nor,s,' ank,-:hominhoofty, way?evoleht!\n",
            "\n",
            "NO'leoulkeld-careiugrcexQuln.\n",
            "When, arty,-the hugh alone; or, for PerbewaHathing?\n",
            "I's hce I apitufre rich\n",
            "Of Pis:-Pomce\n",
            "Alas,vise. Wte-missasa ITEDSWAY N':\n",
            "RogeZned, gi.\n",
            "Lewisgly, hunktcher, I cour't,\n",
            "Now, his nhose\n",
            "Of Yowars, alieewe tdee:\n",
            "builIh madZo:'\n",
            "Listsin\n",
            "BXritomfetf'r Y BolYfulfful quicky; hhgWed\n",
            "\n",
            "MIUMIse!'ze hneWhat's  you, telm keewhing MO3K:\n",
            "3\n",
            "here? We shquT.\n",
            " Jule,fnixPlaur<unk>s t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model,\"model.pth\")"
      ],
      "metadata": {
        "id": "7qRpAz81DsJ9"
      },
      "id": "7qRpAz81DsJ9",
      "execution_count": 86,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}