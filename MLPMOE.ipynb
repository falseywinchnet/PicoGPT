{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7741bdf-98ab-4400-a0d1-4b831244ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# ----------------------------\n",
    "# Layers\n",
    "# ----------------------------\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm with optional learnable negative bias via -softplus(bias) \"\"\"\n",
    "    def __init__(self, ndim: int, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.use_bias = bias\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(ndim))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b = -F.softplus(self.bias) if self.use_bias else None\n",
    "        return F.layer_norm(x, self.weight.shape, self.weight, b, 1e-5)\n",
    "\n",
    "class LinearNegativeBias(nn.Module):\n",
    "    \"\"\" Linear with non-positive bias via -softplus() \"\"\"\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        nn.init.kaiming_uniform_(self.weight, a=5 ** 0.5)\n",
    "        self._bias_raw = nn.Parameter(torch.zeros(out_features))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return F.linear(x, self.weight, -F.softplus(self._bias_raw))\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = LinearNegativeBias(config.n_embd, 4 * config.n_embd)\n",
    "        self.scale = math.pi / math.sqrt(3.0)\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.c_fc(x)\n",
    "        x =   x * torch.sigmoid(self.scale * x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "def variance_scaled_softmax(scores, dim: int = -1, eps: float = 1e-6):\n",
    "    # scores may contain -inf from masking\n",
    "    finite = torch.isfinite(scores)\n",
    "    m = finite.to(scores.dtype)                     # 1 where valid, 0 where masked\n",
    "    n = m.sum(dim=dim, keepdim=True).clamp_min(1)  # count of valid entries per row\n",
    "\n",
    "    # mean/var over valid entries only (population var)\n",
    "    safe_scores = torch.where(finite, scores, torch.zeros_like(scores))\n",
    "    mean = (safe_scores * m).sum(dim=dim, keepdim=True) / n\n",
    "    var  = ((safe_scores - mean)**2 * m).sum(dim=dim, keepdim=True) / n\n",
    "    std  = var.clamp_min(eps).sqrt()\n",
    "\n",
    "    scaled = (safe_scores - mean) / std\n",
    "    scaled = torch.where(finite, scaled, float('-inf'))  # restore mask\n",
    "    out = torch.softmax(scaled, dim=dim)\n",
    "    out = torch.where(n == 0, torch.zeros_like(out), out)  # fully-masked rows -> zeros\n",
    "    return out\n",
    "\n",
    "# ----------------------------\n",
    "# 2D EM-like convective‚Äìdiffusive updater (time-causal; mixes across heads)\n",
    "# ----------------------------\n",
    "class EMDiffuse2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Evolve X on a (time T √ó heads H) grid using geometry G (same shape) to\n",
    "    produce per-position, per-channel coefficients:\n",
    "        a_t : advection speed along time (forward only, upwind in T)\n",
    "        d_t : diffusion along time (backward Laplacian in T)\n",
    "        d_h : diffusion across heads (nearest-neighbor Laplacian at t-1)\n",
    "\n",
    "    Update (per pass), for t>=0, h in [0..H-1]:\n",
    "        X^{new}_{t,h} = X_{t,h}\n",
    "                        + dt * [ -a_t * (X_{t,h} - X_{t-1,h})\n",
    "                                 + d_t * (X_{t,h} - 2 X_{t-1,h} + X_{t-2,h})\n",
    "                                 + d_h * (X_{t-1,h+1} + X_{t-1,h-1} - 2 X_{t-1,h}) ]\n",
    "\n",
    "    Notes:\n",
    "      ‚Ä¢ Causal in time: only uses t, t-1, t-2. No look-ahead.\n",
    "      ‚Ä¢ Cross-head mixing uses data from t-1, so effects manifest only downstream in time.\n",
    "      ‚Ä¢ Coeffs come from G via a small linear; clamped for stability.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int, n_passes: int = 1,\n",
    "                 a_max: float = 1.0, d_t_max: float = 0.35, d_h_max: float = 0.15):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.n_passes = max(1, int(n_passes))\n",
    "        self.a_max = float(a_max)\n",
    "        self.d_t_max = float(d_t_max)\n",
    "        self.d_h_max = float(d_h_max)\n",
    "\n",
    "        # geometry -> [a_t, d_t, d_h] per channel\n",
    "        self.coeff = nn.Linear(dim, 3*dim, bias=True)\n",
    "        nn.init.xavier_uniform_(self.coeff.weight)\n",
    "        nn.init.zeros_(self.coeff.bias)\n",
    "\n",
    "        # learnable global step in (0,1)\n",
    "        self._dt = nn.Parameter(torch.tensor(0.5))\n",
    "\n",
    "    def _pad_time(self, X, k=1):\n",
    "        # prepend k zeros along time\n",
    "        B, T, H, D = X.shape\n",
    "        z = torch.zeros(B, k, H, D, device=X.device, dtype=X.dtype)\n",
    "        return torch.cat([z, X[:, :T-k]], dim=1) if k <= T else torch.cat([z, z[:, :0]], dim=1)\n",
    "\n",
    "    def _lap_head_prev(self, X_tm1):\n",
    "        # head Laplacian at t-1 with zero boundary (minimal bleed at edges)\n",
    "        B, T, H, D = X_tm1.shape\n",
    "        left  = torch.cat([torch.zeros(B, T, 1, D, device=X_tm1.device, dtype=X_tm1.dtype),\n",
    "                           X_tm1[:, :, :-1]], dim=2)\n",
    "        right = torch.cat([X_tm1[:, :, 1:],\n",
    "                           torch.zeros(B, T, 1, D, device=X_tm1.device, dtype=X_tm1.dtype)], dim=2)\n",
    "        return left + right - 2.0 * X_tm1\n",
    "\n",
    "    def forward(self, X: torch.Tensor, G: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        X, G: (B*, T, H, D)\n",
    "        \"\"\"\n",
    "        assert X.shape == G.shape and X.dim() == 4, \"X,G must be (B*,T,H,D)\"\n",
    "        Bstar, T, H, D = X.shape\n",
    "        assert D == self.dim\n",
    "\n",
    "        # coefficients from geometry; clamp for stability\n",
    "        cg = self.coeff(G)                      # (B*, T, H, 3D)\n",
    "        a_raw, dt_raw, dh_raw = torch.chunk(cg, 3, dim=-1)\n",
    "        a_t  = torch.sigmoid(a_raw) * self.a_max           # [0, a_max]\n",
    "        d_t  = (F.softplus(dt_raw) / (1.0 + F.softplus(dt_raw))) * self.d_t_max  # [0, d_t_max]\n",
    "        d_h  = (F.softplus(dh_raw) / (1.0 + F.softplus(dh_raw))) * self.d_h_max  # [0, d_h_max]\n",
    "\n",
    "        # causal time neighbors\n",
    "        X_tm1 = self._pad_time(X, k=1)\n",
    "        X_tm2 = self._pad_time(X, k=2)\n",
    "\n",
    "        # head Laplacian taken at t-1 (so cross-head influence appears downstream only)\n",
    "        lap_h_prev = self._lap_head_prev(X_tm1)\n",
    "\n",
    "        # global causal step\n",
    "        dt = torch.sigmoid(self._dt)  # (0,1)\n",
    "\n",
    "        Xn = X\n",
    "        for _ in range(self.n_passes):\n",
    "            # recompute causal neighbors from current state\n",
    "            Xm1 = self._pad_time(Xn, k=1)\n",
    "            Xm2 = self._pad_time(Xn, k=2)\n",
    "            lap_h_prev = self._lap_head_prev(Xm1)\n",
    "\n",
    "            # upwind first difference in time, backward Laplacian in time\n",
    "            dx_t  = Xn - Xm1\n",
    "            lap_t = Xn - 2.0*Xm1 + Xm2\n",
    "\n",
    "            update = -a_t * dx_t + d_t * lap_t + d_h * lap_h_prev\n",
    "            Xn = Xn + dt * update\n",
    "\n",
    "        return Xn\n",
    "\n",
    "# ----------------------------\n",
    "# Wire into attention: evolve q with 2D EM-like updater using v as geometry\n",
    "# ----------------------------\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.head_dim = self.n_embd // self.n_head\n",
    "        assert self.n_embd % self.n_head == 0\n",
    "\n",
    "        self.c_q = nn.Linear(self.n_embd, self.n_head * self.head_dim, bias=False)\n",
    "        self.c_k = nn.Linear(self.n_embd, self.n_head * self.head_dim, bias=False)\n",
    "        self.c_v = nn.Linear(self.n_embd, self.n_head * self.head_dim, bias=False)\n",
    "        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "\n",
    "        # 2D time-causal updater: mixes across heads via (t-1) head-Laplacian\n",
    "        self.em2d = EMDiffuse2D(self.head_dim, n_passes=1,\n",
    "                                a_max=1.0, d_t_max=0.35, d_h_max=0.15)\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.tril(torch.ones(config.block_size, config.block_size)).view(1, 1, config.block_size, config.block_size)\n",
    "        )\n",
    "        # rope-like signifier: 2D phase over (time, head) mapped into head_dim\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        H, Dh = self.n_head, self.head_dim\n",
    "\n",
    "        # project\n",
    "        q = self.c_q(x).view(B, T, H, Dh)\n",
    "        k = self.c_k(x).view(B, T, H, Dh)\n",
    "        v = self.c_v(x).view(B, T, H, Dh)\n",
    "\n",
    "\n",
    "        # evolve q and k on (T x H) with their respective geometry\n",
    "        q = self.em2d(q, v)\n",
    "        k = self.em2d(k, v)\n",
    "        # attention expects (B, H, T, Dh)\n",
    "        q = q.permute(0, 2, 1, 3).contiguous()\n",
    "        k = k.permute(0, 2, 1, 3).contiguous()\n",
    "        v = v.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # scaled dot-product attention with causal mask\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float('-inf'))\n",
    "        att = variance_scaled_softmax(att, dim=-1)\n",
    "        y = att @ v\n",
    "\n",
    "        # merge heads\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, -1)\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Transformer Block\n",
    "# ----------------------------\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd, bias=None)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "         x = x + self.attn(self.ln_1(x))\n",
    "         x = x + self.mlp(self.ln_2(x))\n",
    "         return x\n",
    "\n",
    "def soft_ce(logits: torch.Tensor, target_probs: torch.Tensor) -> torch.Tensor:\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    loss = -(target_probs * logp).sum(dim=-1)\n",
    "    return loss.mean()\n",
    "\n",
    "def sharpen_distribution(idx: torch.Tensor, p: torch.Tensor, V: int, alpha: float) -> torch.Tensor:\n",
    "    B, T, K = idx.shape\n",
    "    out = torch.full((B, T, V), 0.0, dtype=p.dtype, device=p.device)\n",
    "    q = torch.clamp(p, min=1e-12) ** alpha\n",
    "    q = q / q.sum(dim=-1, keepdim=True)\n",
    "    out.scatter_add_(dim=-1, index=idx, src=q)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 66\n",
    "    n_layer: int = 4\n",
    "    n_head: int = 8\n",
    "    n_embd: int = 128\n",
    "    n_kv_head: int = 8\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict({\n",
    "            \"wte\": nn.Embedding(\n",
    "                config.vocab_size, config.n_embd),\n",
    "            \"h\": nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            \"ln_f\": LayerNorm(config.n_embd, bias=config.bias),\n",
    "        })\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.apply(self._init_weights)\n",
    "        # zero out classifier weights\n",
    "        torch.nn.init.zeros_(self.lm_head.weight)\n",
    "        # zero out c_proj weights in all blocks\n",
    "        for block in self.transformer.h:\n",
    "            torch.nn.init.zeros_(block.mlp.c_proj.weight)\n",
    "            torch.nn.init.zeros_(block.attn.c_proj.weight)\n",
    "        # init the rotary embeddings\n",
    "        head_dim = self.config.n_embd // self.config.n_head\n",
    "        # Cast the embeddings from fp32 to bf16: optim can tolerate it and it saves memory: both in the model and the activations\n",
    "        if self.transformer.wte.weight.device.type == \"cuda\":\n",
    "            self.transformer.wte.to(dtype=torch.bfloat16)\n",
    "\n",
    "    # ------------------------\n",
    "    # Forward\n",
    "    # ------------------------\n",
    "\n",
    "    def forward(self,\n",
    "                idx: torch.Tensor,\n",
    "                targets: Optional[torch.Tensor] = None,\n",
    "                zb: Optional[Tuple[torch.Tensor, torch.Tensor]] = None):\n",
    "        \"\"\"\n",
    "        idx: (B, T) Long\n",
    "        targets: (B, T) Long or None\n",
    "        zb: tuple (Z_idx, Z_p) for distributional aux \n",
    "       \n",
    "        \"\"\"\n",
    "        device = idx.device\n",
    "        B, T = idx.size()\n",
    "\n",
    "        T0 = 0 \n",
    "\n",
    "        tok_emb = self.transformer[\"wte\"](idx)                 # (B, T, D)\n",
    "        x = tok_emb\n",
    "\n",
    "        # defaults\n",
    "        L = len(self.transformer[\"h\"])\n",
    "        depth_alphas = [0.8 + 1.2 * (i/(L-1)) for i in range(L)] if L > 1 else [1.0]\n",
    "        x = norm(x)\n",
    "        # aux distribution pack\n",
    "        Z_idx, Z_p = zb if zb is not None else (None, None)\n",
    "        aux_loss = None\n",
    "\n",
    "        # blocks\n",
    "        for bidx, block in enumerate(self.transformer[\"h\"]):\n",
    "            x = block(x)                                       # (B, T, D)\n",
    "\n",
    "            # in-pass early head for self-teaching\n",
    "            #  Z-based distributional aux loss \n",
    "            if (Z_idx is not None) and (Z_p is not None):\n",
    "                V = self.lm_head.out_features\n",
    "                logits_b = self.lm_head(self.transformer[\"ln_f\"](x))\n",
    "                Z_dense = sharpen_distribution(Z_idx, Z_p, V, alpha=float(depth_alphas[bidx]))\n",
    "                aux_b = soft_ce(logits_b, Z_dense)\n",
    "                aux_loss = aux_b if aux_loss is None else aux_loss + aux_b\n",
    "\n",
    "        x = self.transformer[\"ln_f\"](x)\n",
    "        logits = self.lm_head(x)                               # (B, T, V)\n",
    "\n",
    "        # standard CE\n",
    "        ce_loss = None\n",
    "        if targets is not None:\n",
    "            ce_loss = F.cross_entropy(\n",
    "                logits.view(-1, logits.size(-1)),\n",
    "                targets.view(-1),\n",
    "                ignore_index=-100\n",
    "            )\n",
    "\n",
    "        # total\n",
    "        total = None\n",
    "        parts = []\n",
    "        if ce_loss is not None:\n",
    "            total = ce_loss\n",
    "        if aux_loss is not None:\n",
    "            total = aux_loss if total is None else total + aux_loss\n",
    "   \n",
    "        # generation convenience\n",
    "        if targets is None:\n",
    "            logits = logits[:, [-1], :]\n",
    "\n",
    "        return logits, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d76ace-c3c1-4a68-adce-851c842dbbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading aochildes.txt...\n",
      "üì• Downloading cbt.txt...\n",
      "üì• Downloading children_stories.txt...\n",
      "üì• Downloading gutenberg.txt...\n",
      "üì• Downloading qed.txt...\n",
      "üì• Downloading simple_wikipedia.txt...\n",
      "üì• Downloading switchboard.txt...\n",
      "üì• Downloading wikipedia.txt...\n",
      "üì• Downloading shakespeare.txt...\n",
      "‚úÖ Done. Files saved to ./babylm_10m_cleaned\n"
     ]
    }
   ],
   "source": [
    "import requests, os\n",
    "\n",
    "base_url = \"https://huggingface.co/datasets/cambridge-climb/BabyLM/resolve/main/clean/10M/\"\n",
    "target_dir = \"./babylm_10m_cleaned\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "file_names = [\n",
    "    \"aochildes.txt\",\n",
    "    \"cbt.txt\",\n",
    "    \"children_stories.txt\",\n",
    "    \"gutenberg.txt\",\n",
    "    \"qed.txt\",\n",
    "    \"simple_wikipedia.txt\",\n",
    "    \"switchboard.txt\",\n",
    "    \"wikipedia.txt\"\n",
    "]\n",
    "\n",
    "# Optional addition: Shakespeare from another dataset\n",
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/refs/heads/master/data/tinyshakespeare/input.txt\"\n",
    "shakespeare_fname = \"shakespeare.txt\"\n",
    "\n",
    "# Combined download logic\n",
    "all_files = [(base_url + fname, fname) for fname in file_names]\n",
    "all_files.append((shakespeare_url, shakespeare_fname))  # Add Shakespeare\n",
    "\n",
    "\n",
    "# Download loop\n",
    "for url, fname in all_files:\n",
    "    out_path = os.path.join(target_dir, fname)\n",
    "    print(f\"üì• Downloading {fname}...\")\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(resp.text)\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to download {fname} ({resp.status_code})\")\n",
    "\n",
    "print(f\"‚úÖ Done. Files saved to {target_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a695ab-753c-4b35-8834-a1d4f59859bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Char tokenizer finalized.\n",
      "üßæ Train tokens: 1016242 | Val tokens: 99152\n",
      "üî§ Vocab size: 66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# === Paths ===\n",
    "source_dir = \"./babylm_10m_cleaned\"\n",
    "out_dir    = \"./babylm_char_tokenized\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "file_names = [\n",
    "    \"shakespeare.txt\"#,\"aochildes.txt\", \"cbt.txt\", \"children_stories.txt\", \"gutenberg.txt\",\n",
    "    #\"qed.txt\", \"simple_wikipedia.txt\", \"switchboard.txt\", \"wikipedia.txt\"\n",
    "]\n",
    "\n",
    "# === Load and split ===\n",
    "train_texts, val_texts = [], []\n",
    "char_set = set()\n",
    "\n",
    "for fname in file_names:\n",
    "    with open(os.path.join(source_dir, fname), encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        n = len(lines)\n",
    "        split = int(0.9 * n)\n",
    "        train_part = \"\".join(lines[:split])\n",
    "        val_part   = \"\".join(lines[split:])\n",
    "        train_texts.append(train_part)\n",
    "        val_texts.append(val_part)\n",
    "        char_set.update(train_part)\n",
    "        char_set.update(val_part)\n",
    "\n",
    "full_train = \"\\n\".join(train_texts)\n",
    "full_val   = \"\\n\".join(val_texts)\n",
    "\n",
    "# === Final vocab ===\n",
    "char_set = sorted(set(char_set))\n",
    "vocab_chars = [\"<unk>\"] + [c for c in char_set if c != \"<unk>\"]\n",
    "\n",
    "stoi = {ch: i for i, ch in enumerate(vocab_chars)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "\n",
    "# === Encode function ===\n",
    "def encode(text):\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "train_ids = np.array(encode(full_train), dtype=np.uint16)\n",
    "val_ids   = np.array(encode(full_val),   dtype=np.uint16)\n",
    "\n",
    "# === Save ===\n",
    "train_ids.tofile(os.path.join(out_dir, \"train.bin\"))\n",
    "val_ids.tofile(os.path.join(out_dir, \"val.bin\"))\n",
    "\n",
    "with open(os.path.join(out_dir, \"meta.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"vocab_size\": len(stoi),\n",
    "        \"stoi\": stoi,\n",
    "        \"itos\": itos\n",
    "    }, f)\n",
    "\n",
    "print(f\"‚úÖ Char tokenizer finalized.\")\n",
    "print(f\"üßæ Train tokens: {len(train_ids)} | Val tokens: {len(val_ids)}\")\n",
    "print(f\"üî§ Vocab size: {len(stoi)}\")\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "\n",
    "data_dir = \"./babylm_char_tokenized\"\n",
    "train_path = os.path.join(data_dir, \"train.bin\")\n",
    "val_path   = os.path.join(data_dir, \"val.bin\")\n",
    "meta_path  = os.path.join(data_dir, \"meta.pkl\")\n",
    "train_ids = np.fromfile(train_path, dtype=np.uint16)\n",
    "val_ids   = np.fromfile(val_path,   dtype=np.uint16)\n",
    "\n",
    "with open(os.path.join(data_dir, 'meta.pkl'), 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "vocab_size = meta[\"vocab_size\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e48b14-a88f-48b6-b3e6-5507e3990262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Char tokenizer finalized.\n",
      "üßæ Train tokens: 1016242 | Val tokens: 99152\n",
      "üî§ Vocab size: 66\n",
      "Loaded 1016242 train tokens and 99152 val tokens | vocab=66\n",
      "Building order-2 Markov...\n",
      "Building order-4 Markov...\n",
      "Building order-8 Markov...\n",
      "Building order-16 Markov...\n",
      "Building order-32 Markov...\n",
      "Building order-64 Markov...\n",
      "Building bigram db...\n",
      "‚úÖ Markov and Bigram models saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# === Paths ===\n",
    "source_dir = \"./babylm_10m_cleaned\"\n",
    "out_dir    = \"./babylm_char_tokenized\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "file_names = [\n",
    "    \"shakespeare.txt\"#,\"aochildes.txt\", \"cbt.txt\", \"children_stories.txt\", \"gutenberg.txt\",\n",
    "    #\"qed.txt\", \"simple_wikipedia.txt\", \"switchboard.txt\", \"wikipedia.txt\"\n",
    "]\n",
    "\n",
    "# === Load and split ===\n",
    "train_texts, val_texts = [], []\n",
    "char_set = set()\n",
    "\n",
    "for fname in file_names:\n",
    "    with open(os.path.join(source_dir, fname), encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        n = len(lines)\n",
    "        split = int(0.9 * n)\n",
    "        train_part = \"\".join(lines[:split])\n",
    "        val_part   = \"\".join(lines[split:])\n",
    "        train_texts.append(train_part)\n",
    "        val_texts.append(val_part)\n",
    "        char_set.update(train_part)\n",
    "        char_set.update(val_part)\n",
    "\n",
    "full_train = \"\\n\".join(train_texts)\n",
    "full_val   = \"\\n\".join(val_texts)\n",
    "\n",
    "# === Final vocab ===\n",
    "char_set = sorted(set(char_set))\n",
    "vocab_chars = [\"<unk>\"] + [c for c in char_set if c != \"<unk>\"]\n",
    "\n",
    "stoi = {ch: i for i, ch in enumerate(vocab_chars)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "\n",
    "# === Encode function ===\n",
    "def encode(text):\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "train_ids = np.array(encode(full_train), dtype=np.uint16)\n",
    "val_ids   = np.array(encode(full_val),   dtype=np.uint16)\n",
    "\n",
    "# === Save ===\n",
    "train_ids.tofile(os.path.join(out_dir, \"train.bin\"))\n",
    "val_ids.tofile(os.path.join(out_dir, \"val.bin\"))\n",
    "\n",
    "with open(os.path.join(out_dir, \"meta.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"vocab_size\": len(stoi),\n",
    "        \"stoi\": stoi,\n",
    "        \"itos\": itos\n",
    "    }, f)\n",
    "\n",
    "print(f\"‚úÖ Char tokenizer finalized.\")\n",
    "print(f\"üßæ Train tokens: {len(train_ids)} | Val tokens: {len(val_ids)}\")\n",
    "print(f\"üî§ Vocab size: {len(stoi)}\")\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "\n",
    "data_dir = \"./babylm_char_tokenized\"\n",
    "train_path = os.path.join(data_dir, \"train.bin\")\n",
    "val_path   = os.path.join(data_dir, \"val.bin\")\n",
    "meta_path  = os.path.join(data_dir, \"meta.pkl\")\n",
    "train_ids = np.fromfile(train_path, dtype=np.uint16)\n",
    "val_ids   = np.fromfile(val_path,   dtype=np.uint16)\n",
    "\n",
    "with open(os.path.join(data_dir, 'meta.pkl'), 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "vocab_size = meta[\"vocab_size\"]\n",
    "\n",
    "def global_freqs(ids: np.ndarray, V: int) -> np.ndarray:\n",
    "    cnt = np.bincount(ids.astype(np.int64), minlength=V)\n",
    "    # normalize to probability (avoid zero)\n",
    "    p = cnt.astype(np.float64)\n",
    "    p = p / max(1.0, p.sum())\n",
    "    return p\n",
    "print(f\"Loaded {len(train_ids)} train tokens and {len(val_ids)} val tokens | vocab={vocab_size}\")\n",
    "p_global = global_freqs(train_ids, vocab_size)  # used for disciplined fill only\n",
    "\n",
    "def build_markov_chain(data: np.ndarray, window: int) -> Dict[Tuple[int, ...], Counter]:\n",
    "    chain = defaultdict(Counter)\n",
    "    for i in range(len(data) - window):\n",
    "        ctx = tuple(map(int, data[i:i+window]))\n",
    "        nxt = int(data[i+window])\n",
    "        chain[ctx][nxt] += 1\n",
    "    return chain\n",
    "\n",
    "ngram_orders = [2,4,8,16,32,64]\n",
    "markov_models: Dict[int, Dict[Tuple[int,...], Counter]] = {}\n",
    "for w in ngram_orders:\n",
    "    print(f\"Building order-{w} Markov...\")\n",
    "    markov_models[w] = build_markov_chain(train_ids, w)\n",
    "\n",
    "def build_bigram_db(data: np.ndarray, V: int, top_k=16, epsilon=1e-6, seed=1337):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    counts = np.zeros((V, V), dtype=np.int64)\n",
    "    a = data[:-1].astype(np.int64)\n",
    "    b = data[1:].astype(np.int64)\n",
    "    np.add.at(counts, (a, b), 1)\n",
    "    out = {}\n",
    "    all_ids = np.arange(V, dtype=np.int64)\n",
    "    for t in range(V):\n",
    "        row = counts[t]\n",
    "        tot = row.sum()\n",
    "        if tot == 0:\n",
    "            idx = rng.choice(V, size=top_k, replace=False)\n",
    "            p = np.full(top_k, 1.0/top_k, dtype=np.float32)\n",
    "        else:\n",
    "            pr = row.astype(np.float64) / float(tot)\n",
    "            obs = np.flatnonzero(row)\n",
    "            if len(obs) >= top_k:\n",
    "                sel = np.argpartition(pr[obs], -top_k)[-top_k:]\n",
    "                idx = obs[sel]\n",
    "                p = pr[idx].astype(np.float32)\n",
    "                s = p.sum()\n",
    "                p = p/s if s > 0 else np.full(top_k, 1.0/top_k, dtype=np.float32)\n",
    "            else:\n",
    "                need = top_k - len(obs)\n",
    "                mask = np.ones(V, dtype=bool); mask[obs] = False\n",
    "                extra = np.random.default_rng(seed+t).choice(np.nonzero(mask)[0], size=need, replace=False)\n",
    "                idx = np.concatenate([obs, extra])\n",
    "                p   = pr[idx].astype(np.float32)\n",
    "                # give epsilon to never-seen extras\n",
    "                unseen = (row[idx] == 0)\n",
    "                if unseen.any():\n",
    "                    p = p + unseen.astype(np.float32) * epsilon\n",
    "                p = p / p.sum()\n",
    "        order = np.argsort(-p)\n",
    "        out[t] = (idx[order].astype(np.int64), p[order])\n",
    "    return out\n",
    "\n",
    "print(\"Building bigram db...\")\n",
    "bigram_db = build_bigram_db(train_ids, vocab_size, top_k=64)  # collect a bit wider; we'll cap later\n",
    "\n",
    "# === Save ===\n",
    "model_dir = \"./markov_bigram_models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    \n",
    "with open(os.path.join(model_dir, \"markov_models.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(markov_models, f)\n",
    "\n",
    "with open(os.path.join(model_dir, \"bigram_db.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(bigram_db, f)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Markov and Bigram models saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4dd64a-8f8e-471e-97f2-7ffd1df4c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# === Config ===\n",
    "data_dir = \"./babylm_char_tokenized\"  # <- char-tokenized data\n",
    "block_size = 1024\n",
    "batch_size = 8\n",
    "\n",
    "# === Replacement dataloader that uses SAVED bigram + markov models and yields (X, Y, Z) ===\n",
    "import os, pickle, numpy as np, torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# expects `vocab_size` and `device` already defined in the outer scope\n",
    "# expects saved models at ./markov_bigram_models/{bigram_db.pkl, markov_models.pkl}\n",
    "\n",
    "class DisciplinedZ:\n",
    "    def __init__(self, markov_models: Dict[int, Dict[Tuple[int,...], Counter]],\n",
    "                 bigram_db: Dict[int, Tuple[np.ndarray, np.ndarray]],\n",
    "                 p_global: np.ndarray,\n",
    "                 vocab_size: int,\n",
    "                 top_k: int = 32,\n",
    "                 epsilon: float = 1e-6):\n",
    "        self.models = markov_models\n",
    "        self.bigram_db = bigram_db\n",
    "        self.p_global = p_global.astype(np.float64)\n",
    "        self.V = vocab_size\n",
    "        self.K = top_k\n",
    "        self.eps = float(epsilon)\n",
    "        # global sort for fill\n",
    "        self.global_order = np.argsort(-self.p_global)\n",
    "\n",
    "    def _cands_from_counter(self, ctr: Optional[Counter]) -> Optional[np.ndarray]:\n",
    "        if not ctr:\n",
    "            return None\n",
    "        return np.fromiter((int(t) for t,_ in ctr.items()), dtype=np.int64)\n",
    "\n",
    "    def _probs_from_counter(self, ctr: Optional[Counter]) -> Optional[Dict[int, float]]:\n",
    "        if not ctr:\n",
    "            return None\n",
    "        tot = sum(ctr.values())\n",
    "        if tot == 0:\n",
    "            return None\n",
    "        return {int(t): c/tot for t, c in ctr.items()}\n",
    "\n",
    "    def _bigram_top(self, tok: int, limit: int) -> np.ndarray:\n",
    "        idx, prob = self.bigram_db.get(int(tok), (None, None))\n",
    "        if idx is None:\n",
    "            return np.array([], dtype=np.int64)\n",
    "        return idx[:limit]\n",
    "\n",
    "    def _btree_candidates(self, contexts: Dict[int, Tuple[Tuple[int,...], Optional[Counter]]], backoff_tok: int) -> np.ndarray:\n",
    "        # collect candidate sets from each available context\n",
    "        sets = []\n",
    "        for n, (_, ctr) in contexts.items():\n",
    "            c = self._cands_from_counter(ctr)\n",
    "            if c is not None and c.size > 0:\n",
    "                sets.append(set(c.tolist()))\n",
    "        if len(sets) == 0:\n",
    "            # no ctx ‚Üí use bigram set as starting point\n",
    "            return self._bigram_top(backoff_tok, self.K)\n",
    "\n",
    "        # try full intersection; if empty, progressively intersect strongest contexts first\n",
    "        inter = set.intersection(*sets) if len(sets) > 1 else sets[0]\n",
    "        if len(inter) == 0:\n",
    "            # heuristic: sort by context order (longest first), intersect greedily\n",
    "            sets_sorted = sorted(sets, key=lambda s: -len(s))\n",
    "            inter = sets_sorted[0].copy()\n",
    "            for s in sets_sorted[1:]:\n",
    "                new_inter = inter.intersection(s)\n",
    "                if len(new_inter) > 0:\n",
    "                    inter = new_inter\n",
    "        if len(inter) == 0:\n",
    "            # last resort: union (still disciplined; no random injection)\n",
    "            union = set()\n",
    "            for s in sets:\n",
    "                union |= s\n",
    "            inter = union\n",
    "\n",
    "        arr = np.fromiter(inter, dtype=np.int64)\n",
    "        if arr.size == 0:\n",
    "            return self._bigram_top(backoff_tok, self.K)\n",
    "        return arr\n",
    "\n",
    "    def _score_candidates(self, cands: np.ndarray, contexts: Dict[int, Tuple[Tuple[int,...], Optional[Counter]]]) -> np.ndarray:\n",
    "        # score = sum over contexts of presence * local prob\n",
    "        # local prob from per-context normalized counts\n",
    "        scores = np.zeros(cands.size, dtype=np.float64)\n",
    "        idxmap = {int(t): i for i, t in enumerate(cands)}\n",
    "        for n, (_, ctr) in contexts.items():\n",
    "            probs = self._probs_from_counter(ctr)\n",
    "            if probs is None:\n",
    "                continue\n",
    "            for t, p in probs.items():\n",
    "                if t in idxmap:\n",
    "                    scores[idxmap[t]] += float(p)\n",
    "        # tiny floor to avoid zeros\n",
    "        scores = scores + (scores == 0) * self.eps\n",
    "        return scores\n",
    "\n",
    "    def build_Z_for_sequence(self, seq: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        seq: array of length L = block_size (+optional pad)\n",
    "        returns:\n",
    "          topk_idx: (L, K) int64\n",
    "          topk_p:   (L, K) float32  (row-normalized)\n",
    "        \"\"\"\n",
    "        L = len(seq)\n",
    "        topk_idx = np.zeros((L, self.K), dtype=np.int64)\n",
    "        topk_p   = np.zeros((L, self.K), dtype=np.float32)\n",
    "        for j in range(L):\n",
    "            back_tok = int(seq[j])\n",
    "            # collect contexts\n",
    "            contexts = {}\n",
    "            for n in ngram_orders:\n",
    "                if j - (n-1) < 0:\n",
    "                    continue\n",
    "                ctx = tuple(int(x) for x in seq[j-(n-1):j+1])\n",
    "                ctr = self.models[n].get(ctx, None)\n",
    "                contexts[n] = (ctx, ctr)\n",
    "\n",
    "            # disciplined candidate set\n",
    "            cands = self._btree_candidates(contexts, back_tok)\n",
    "\n",
    "            # cap K by candidate count\n",
    "            if cands.size >= self.K:\n",
    "                # score & take best K\n",
    "                scores = self._score_candidates(cands, contexts)\n",
    "                order = np.argsort(-scores)[:self.K]\n",
    "                idx = cands[order]\n",
    "                sc  = scores[order]\n",
    "            else:\n",
    "                # we must fill with globally-most-common tokens (no randoms), excluding existing\n",
    "                scores = self._score_candidates(cands, contexts) if cands.size > 0 else np.array([], dtype=np.float64)\n",
    "                missing = self.K - cands.size\n",
    "                mask = np.ones(vocab_size, dtype=bool)\n",
    "                mask[cands] = False\n",
    "                fill = []\n",
    "                for t in self.global_order:\n",
    "                    if mask[t]:\n",
    "                        fill.append(int(t))\n",
    "                        if len(fill) == missing:\n",
    "                            break\n",
    "                if cands.size == 0:\n",
    "                    idx = np.array(fill, dtype=np.int64)\n",
    "                    sc  = np.full(len(fill), self.eps, dtype=np.float64)\n",
    "                else:\n",
    "                    idx = np.concatenate([cands, np.array(fill, dtype=np.int64)])\n",
    "                    sc  = np.concatenate([scores, np.full(missing, self.eps, dtype=np.float64)])\n",
    "\n",
    "            # normalize to prob\n",
    "            p = sc.astype(np.float64)\n",
    "            p = p / p.sum() if p.sum() > 0 else np.full_like(p, 1.0/len(p))\n",
    "            topk_idx[j, :] = idx\n",
    "            topk_p[j, :]   = p.astype(np.float32)\n",
    "        return topk_idx, topk_p\n",
    "\n",
    "discZ = DisciplinedZ(markov_models, bigram_db, p_global, vocab_size, top_k=32, epsilon=1e-6)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class GPUDataset(Dataset):\n",
    "    def __init__(self, mmap_file, block_size: int, batch_size: int, builder: DisciplinedZ, pad_len:int=0, jitter:int=63, p_aligned:float=0.5, seed:int=1337):\n",
    "        self.data = mmap_file\n",
    "        self.block_size = int(block_size)\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.pad_len    = int(pad_len)\n",
    "        self.sample_len = self.block_size + self.pad_len\n",
    "        self.total = len(self.data) - self.sample_len - 1\n",
    "        self.n_blocks = max(1, self.total // self.sample_len)\n",
    "        self.jitter = int(jitter)\n",
    "        self.p_aligned = float(p_aligned)\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.builder = builder\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total // self.batch_size\n",
    "\n",
    "    def _sample_block(self):\n",
    "        base_block = self.rng.integers(0, self.n_blocks)\n",
    "        start = base_block * self.sample_len\n",
    "        if self.rng.random() > self.p_aligned:\n",
    "            j = self.rng.integers(0, self.jitter + 1)\n",
    "            start = min(start + j, self.total)\n",
    "        return start\n",
    "\n",
    "    def __getitem__(self, _):\n",
    "        B, T = self.batch_size, self.block_size\n",
    "        X = np.empty((B, self.sample_len), dtype=np.int64)\n",
    "        Y = np.empty((B, T), dtype=np.int64)\n",
    "        Z_idx = np.empty((B, T, self.builder.K), dtype=np.int64)\n",
    "        Z_p   = np.empty((B, T, self.builder.K), dtype=np.float32)\n",
    "        for i in range(B):\n",
    "            start = self._sample_block()\n",
    "            xseq = self.data[start : start + self.sample_len].astype(np.int64)\n",
    "            yseq = self.data[start + 1 + self.pad_len : start + 1 + self.pad_len + T].astype(np.int64)\n",
    "            X[i] = xseq\n",
    "            Y[i] = yseq\n",
    "            idxs, probs = self.builder.build_Z_for_sequence(xseq[:T])\n",
    "            Z_idx[i] = idxs\n",
    "            Z_p[i]   = probs\n",
    "        # torch tensors\n",
    "        X = torch.from_numpy(X[:, :T]).to(device)\n",
    "        Y = torch.from_numpy(Y).to(device)\n",
    "        Z_idx = torch.from_numpy(Z_idx).to(device)\n",
    "        Z_p   = torch.from_numpy(Z_p).to(device)\n",
    "        return X, Y, (Z_idx, Z_p)\n",
    "\n",
    "def collate_identity(batch):\n",
    "    Xs, Ys, Zs = zip(*batch)\n",
    "    X = torch.cat(Xs, dim=0)\n",
    "    Y = torch.cat(Ys, dim=0)\n",
    "    Zi = torch.cat([z[0] for z in Zs], dim=0)\n",
    "    Zp = torch.cat([z[1] for z in Zs], dim=0)\n",
    "    return X, Y, (Zi, Zp)\n",
    "\n",
    "block_size = 1024\n",
    "batch_size = 8\n",
    "\n",
    "GPU_DATASET = GPUDataset(\n",
    "    np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r'),\n",
    "    block_size=block_size,\n",
    "    batch_size=batch_size,\n",
    "    builder=discZ,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    GPU_DATASET,\n",
    "    batch_size=1,            # keep outer loader at 1; inner dataset batches on GPU\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_identity\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "efacb560-8e61-4e4e-9399-3c1611b476ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# === Config ===\n",
    "data_dir = \"./babylm_char_tokenized\"  # <- char-tokenized data\n",
    "block_size = 1024\n",
    "batch_size = 8\n",
    "\n",
    "config =  GPTConfig(\n",
    "    block_size,\n",
    "    vocab_size,\n",
    "    n_layer=4,      \n",
    "    n_head = 8,\n",
    "    n_embd =128)\n",
    "\n",
    "model = GPT(config).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
    "losses = []\n",
    "model = torch.compile(model)\n",
    "model = model.to(device)\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for xb, yb, zb in train_loader:\n",
    "        # xb: (B, T), yb: (B, T), zb: (Z_idx, Z_p) with shapes (B,T,K)\n",
    "        logits, loss = model(xb, None,zb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        total += loss.item()\n",
    "        print(loss.item())\n",
    "        losses.append(loss.item())\n",
    "    return total / len(train_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c43d3e5c-ba7e-4a1e-9b59-1b593316e2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810948\n"
     ]
    }
   ],
   "source": [
    "print(sum(param.numel() for param in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742f12d-294f-4bcf-8b15-e447dffa45d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6451f-1367-40a2-9fb9-85a5085ef5bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.546863555908203\n",
      "15.54607105255127\n",
      "14.298829078674316\n",
      "13.532638549804688\n",
      "13.057798385620117\n",
      "12.784690856933594\n",
      "12.471915245056152\n",
      "12.023216247558594\n",
      "11.683206558227539\n",
      "11.668705940246582\n",
      "11.311534881591797\n",
      "11.132368087768555\n",
      "11.030189514160156\n",
      "10.885516166687012\n",
      "10.647764205932617\n",
      "10.760369300842285\n",
      "10.542865753173828\n",
      "10.434457778930664\n",
      "10.320241928100586\n",
      "10.258931159973145\n",
      "10.10069751739502\n",
      "10.059616088867188\n",
      "10.104236602783203\n",
      "9.942100524902344\n",
      "9.930137634277344\n",
      "9.792644500732422\n",
      "9.896472930908203\n",
      "9.84722900390625\n",
      "9.710550308227539\n",
      "9.685951232910156\n",
      "9.70374584197998\n",
      "9.572988510131836\n",
      "9.60679817199707\n",
      "9.535858154296875\n",
      "9.67034912109375\n",
      "9.42105484008789\n",
      "9.483288764953613\n",
      "9.456947326660156\n",
      "9.439483642578125\n",
      "9.349170684814453\n",
      "9.461962699890137\n",
      "9.243558883666992\n",
      "9.292861938476562\n",
      "9.38984489440918\n",
      "9.413627624511719\n",
      "9.388729095458984\n",
      "9.126819610595703\n",
      "9.192964553833008\n",
      "9.245929718017578\n",
      "9.327198028564453\n",
      "9.137788772583008\n",
      "9.317914009094238\n",
      "9.166030883789062\n",
      "9.283447265625\n",
      "9.144499778747559\n",
      "9.047523498535156\n",
      "9.29294490814209\n",
      "9.080195426940918\n",
      "9.096529006958008\n",
      "9.039407730102539\n",
      "8.98055648803711\n",
      "8.96670913696289\n",
      "8.973384857177734\n",
      "8.968732833862305\n",
      "9.022905349731445\n",
      "9.040925979614258\n",
      "8.966503143310547\n",
      "8.902434349060059\n",
      "8.950235366821289\n",
      "8.948753356933594\n",
      "8.830657958984375\n",
      "8.81385612487793\n",
      "8.834178924560547\n",
      "8.781957626342773\n",
      "8.971596717834473\n",
      "8.694766998291016\n",
      "8.765115737915039\n",
      "8.901571273803711\n",
      "8.744200706481934\n",
      "8.724735260009766\n",
      "8.877878189086914\n",
      "8.695808410644531\n",
      "8.920856475830078\n",
      "8.832693099975586\n",
      "8.735217094421387\n",
      "8.829166412353516\n",
      "8.726040840148926\n",
      "8.681915283203125\n",
      "8.752092361450195\n",
      "8.704647064208984\n",
      "8.683646202087402\n",
      "8.729621887207031\n",
      "8.601568222045898\n",
      "8.605241775512695\n",
      "8.49258804321289\n",
      "8.520248413085938\n",
      "8.691429138183594\n",
      "8.716514587402344\n",
      "8.518661499023438\n",
      "8.489508628845215\n",
      "8.54985237121582\n",
      "8.732162475585938\n",
      "8.539106369018555\n",
      "8.482677459716797\n",
      "8.4990234375\n",
      "8.567550659179688\n",
      "8.449118614196777\n",
      "8.427671432495117\n",
      "8.665594100952148\n",
      "8.422283172607422\n",
      "8.30686092376709\n",
      "8.509511947631836\n",
      "8.477629661560059\n",
      "8.365087509155273\n",
      "8.237817764282227\n",
      "8.556581497192383\n",
      "8.361740112304688\n",
      "8.42768669128418\n",
      "8.357002258300781\n",
      "8.454764366149902\n",
      "8.377426147460938\n",
      "8.395331382751465\n",
      "8.45911693572998\n",
      "8.393412590026855\n",
      "8.388257026672363\n",
      "8.36453914642334\n",
      "8.41759204864502\n",
      "8.197482109069824\n",
      "8.388553619384766\n",
      "8.373261451721191\n",
      "8.422612190246582\n",
      "8.281692504882812\n",
      "8.34893798828125\n",
      "8.188581466674805\n",
      "8.323747634887695\n",
      "8.04329776763916\n"
     ]
    }
   ],
   "source": [
    "# === Run Training ===\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch()\n",
    "    print(f\"Epoch {epoch:2d} | Train loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "36c6dd9b-dafc-4c7e-94e9-fde8dd10f186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x38dea4fb0>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fe76faa0-3933-416d-b923-993c67cfcf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "IUSer en thrist ch, sirraw's my may thot that that enTIIIIIIIIIIII:\n",
      "\n",
      "Getmence sayhf Romer, roingmught?\n",
      "\n",
      "First:\n",
      "\n",
      "MENENIUS:\n",
      "Though now the would shall!\n",
      "Where our servost command I becond to ento that. Lesence; nights myse and I world reprow if thou let's pricause me he her; headles. Harces, mucclingharge.\n",
      "\n",
      "First Rofe, that, ear, geny's that evermen, of if in this.\n",
      "\n",
      "ISABY:\n",
      "Your lisdance as our send hear note: 'tisgrolle thirry that be in the go Have and as than nost my fellowst and Jay speak of inswer-da\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def decode_chars(token_ids, itos):\n",
    "    \"\"\"\n",
    "    Decodes a list of character token IDs into a string.\n",
    "    \"\"\"\n",
    "    return ''.join([itos[i] for i in token_ids])\n",
    "\n",
    "def encode_chars(text, stoi):\n",
    "    \"\"\"\n",
    "    Encodes a string into a list of token IDs, one per character.\n",
    "    \"\"\"\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "\n",
    "def decode_sequence_char(\n",
    "    model, stoi, itos, prompt, max_new_tokens=100, block_size=256,\n",
    "    use_fenchel=False, tau=1.0, fenchel_iters=3, temperature=1.0\n",
    "):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    max_ctx = int(block_size)\n",
    "\n",
    "    # ?1 assume space token exists; fallback to 0 if missing\n",
    "    space_id = stoi.get(' ', 0)\n",
    "\n",
    "    # encode prompt\n",
    "    start_ids = torch.tensor([encode_chars(prompt, stoi)], dtype=torch.long, device=device)\n",
    "\n",
    "    # prepend the pad once; from now on the window just slides\n",
    "\n",
    "    idx = start_ids\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        context = idx[:, -max_ctx:]  # rotating buffer: last pad_len+block_size tokens\n",
    "        logits, _ = model(context, None)\n",
    "        last_logits = logits[:, -1, :]\n",
    "        probs = torch.softmax(last_logits / temperature, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_token], dim=1)\n",
    "\n",
    "    # drop the initial pad when returning the string\n",
    "    out_tokens = idx[0].tolist()\n",
    "    return decode_chars(out_tokens, itos)\n",
    "with open(\"./babylm_char_tokenized/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi = meta[\"stoi\"]\n",
    "itos = meta[\"itos\"]\n",
    "\n",
    "prompt = \"ROMEO:\"\n",
    "generated = decode_sequence_char(\n",
    "    model=model,\n",
    "    stoi=stoi,\n",
    "    itos=itos,\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=512,\n",
    "    block_size=1024,\n",
    "    use_fenchel=False,\n",
    "    tau=1.5,\n",
    "    fenchel_iters=2,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b2490-4fda-4d68-9385-6df58b9d06d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5766b-6947-4fbe-8704-8ea7c19c5afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37109166-b414-4e08-964d-be55048c9d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef652df0-c07e-4e14-8180-0cc75de9863e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60132cb-cf65-49c7-a481-c7a29c0fdf60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc7743d-0569-49ca-a2eb-a0d971455f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa366c-2133-4865-a7a4-ebce14ac2533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e4eaa6-9fea-464f-92dc-0036a4ece7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89689e67-ff91-4fc0-a0e4-79e4330d4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"fuzzy.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72509ed-bff1-43e2-a08a-4aad880fb293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
