{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c7741bdf-98ab-4400-a0d1-4b831244ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# ----------------------------\n",
    "# Layers\n",
    "# ----------------------------\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm with optional learnable negative bias via -softplus(bias) \"\"\"\n",
    "    def __init__(self, ndim: int, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.use_bias = bias\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(ndim))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b = -F.softplus(self.bias) if self.use_bias else None\n",
    "        return F.layer_norm(x, self.weight.shape, self.weight, b, 1e-5)\n",
    "\n",
    "class LinearNegativeBias(nn.Module):\n",
    "    \"\"\" Linear with non-positive bias via -softplus() \"\"\"\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        nn.init.kaiming_uniform_(self.weight, a=5 ** 0.5)\n",
    "        self._bias_raw = nn.Parameter(torch.zeros(out_features))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return F.linear(x, self.weight, -F.softplus(self._bias_raw))\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = LinearNegativeBias(config.n_embd, 4 * config.n_embd)\n",
    "        self.scale = math.pi / math.sqrt(3.0)\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.c_fc(x)\n",
    "        x =   x * torch.sigmoid(self.scale * x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "def variance_scaled_softmax(scores, dim: int = -1, eps: float = 1e-6):\n",
    "    # scores may contain -inf from masking\n",
    "    finite = torch.isfinite(scores)\n",
    "    m = finite.to(scores.dtype)                     # 1 where valid, 0 where masked\n",
    "    n = m.sum(dim=dim, keepdim=True).clamp_min(1)  # count of valid entries per row\n",
    "\n",
    "    # mean/var over valid entries only (population var)\n",
    "    safe_scores = torch.where(finite, scores, torch.zeros_like(scores))\n",
    "    mean = (safe_scores * m).sum(dim=dim, keepdim=True) / n\n",
    "    var  = ((safe_scores - mean)**2 * m).sum(dim=dim, keepdim=True) / n\n",
    "    std  = var.clamp_min(eps).sqrt()\n",
    "\n",
    "    scaled = (safe_scores - mean) / std\n",
    "    scaled = torch.where(finite, scaled, float('-inf'))  # restore mask\n",
    "    out = torch.softmax(scaled, dim=dim)\n",
    "    out = torch.where(n == 0, torch.zeros_like(out), out)  # fully-masked rows -> zeros\n",
    "    return out\n",
    "\n",
    "# ----------------------------\n",
    "# 2D EM-like convective‚Äìdiffusive updater (time-causal; mixes across heads)\n",
    "# ----------------------------\n",
    "class EMDiffuse2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Evolve X on a (time T √ó heads H) grid using geometry G (same shape) to\n",
    "    produce per-position, per-channel coefficients:\n",
    "        a_t : advection speed along time (forward only, upwind in T)\n",
    "        d_t : diffusion along time (backward Laplacian in T)\n",
    "        d_h : diffusion across heads (nearest-neighbor Laplacian at t-1)\n",
    "\n",
    "    Update (per pass), for t>=0, h in [0..H-1]:\n",
    "        X^{new}_{t,h} = X_{t,h}\n",
    "                        + dt * [ -a_t * (X_{t,h} - X_{t-1,h})\n",
    "                                 + d_t * (X_{t,h} - 2 X_{t-1,h} + X_{t-2,h})\n",
    "                                 + d_h * (X_{t-1,h+1} + X_{t-1,h-1} - 2 X_{t-1,h}) ]\n",
    "\n",
    "    Notes:\n",
    "      ‚Ä¢ Causal in time: only uses t, t-1, t-2. No look-ahead.\n",
    "      ‚Ä¢ Cross-head mixing uses data from t-1, so effects manifest only downstream in time.\n",
    "      ‚Ä¢ Coeffs come from G via a small linear; clamped for stability.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int, n_passes: int = 1,\n",
    "                 a_max: float = 1.0, d_t_max: float = 0.35, d_h_max: float = 0.15):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.n_passes = max(1, int(n_passes))\n",
    "        self.a_max = float(a_max)\n",
    "        self.d_t_max = float(d_t_max)\n",
    "        self.d_h_max = float(d_h_max)\n",
    "\n",
    "        # geometry -> [a_t, d_t, d_h] per channel\n",
    "        self.coeff = nn.Linear(dim, 3*dim, bias=True)\n",
    "        nn.init.xavier_uniform_(self.coeff.weight)\n",
    "        nn.init.zeros_(self.coeff.bias)\n",
    "\n",
    "        # learnable global step in (0,1)\n",
    "        self._dt = nn.Parameter(torch.tensor(0.5))\n",
    "\n",
    "    def _pad_time(self, X, k=1):\n",
    "        # prepend k zeros along time\n",
    "        B, T, H, D = X.shape\n",
    "        z = torch.zeros(B, k, H, D, device=X.device, dtype=X.dtype)\n",
    "        return torch.cat([z, X[:, :T-k]], dim=1) if k <= T else torch.cat([z, z[:, :0]], dim=1)\n",
    "\n",
    "    def _lap_head_prev(self, X_tm1):\n",
    "        # head Laplacian at t-1 with zero boundary (minimal bleed at edges)\n",
    "        B, T, H, D = X_tm1.shape\n",
    "        left  = torch.cat([torch.zeros(B, T, 1, D, device=X_tm1.device, dtype=X_tm1.dtype),\n",
    "                           X_tm1[:, :, :-1]], dim=2)\n",
    "        right = torch.cat([X_tm1[:, :, 1:],\n",
    "                           torch.zeros(B, T, 1, D, device=X_tm1.device, dtype=X_tm1.dtype)], dim=2)\n",
    "        return left + right - 2.0 * X_tm1\n",
    "\n",
    "    def forward(self, X: torch.Tensor, G: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        X, G: (B*, T, H, D)\n",
    "        \"\"\"\n",
    "        assert X.shape == G.shape and X.dim() == 4, \"X,G must be (B*,T,H,D)\"\n",
    "        Bstar, T, H, D = X.shape\n",
    "        assert D == self.dim\n",
    "\n",
    "        # coefficients from geometry; clamp for stability\n",
    "        cg = self.coeff(G)                      # (B*, T, H, 3D)\n",
    "        a_raw, dt_raw, dh_raw = torch.chunk(cg, 3, dim=-1)\n",
    "        a_t  = torch.sigmoid(a_raw) * self.a_max           # [0, a_max]\n",
    "        d_t  = (F.softplus(dt_raw) / (1.0 + F.softplus(dt_raw))) * self.d_t_max  # [0, d_t_max]\n",
    "        d_h  = (F.softplus(dh_raw) / (1.0 + F.softplus(dh_raw))) * self.d_h_max  # [0, d_h_max]\n",
    "\n",
    "        # causal time neighbors\n",
    "        X_tm1 = self._pad_time(X, k=1)\n",
    "        X_tm2 = self._pad_time(X, k=2)\n",
    "\n",
    "        # head Laplacian taken at t-1 (so cross-head influence appears downstream only)\n",
    "        lap_h_prev = self._lap_head_prev(X_tm1)\n",
    "\n",
    "        # global causal step\n",
    "        dt = torch.sigmoid(self._dt)  # (0,1)\n",
    "\n",
    "        Xn = X\n",
    "        for _ in range(self.n_passes):\n",
    "            # recompute causal neighbors from current state\n",
    "            Xm1 = self._pad_time(Xn, k=1)\n",
    "            Xm2 = self._pad_time(Xn, k=2)\n",
    "            lap_h_prev = self._lap_head_prev(Xm1)\n",
    "\n",
    "            # upwind first difference in time, backward Laplacian in time\n",
    "            dx_t  = Xn - Xm1\n",
    "            lap_t = Xn - 2.0*Xm1 + Xm2\n",
    "\n",
    "            update = -a_t * dx_t + d_t * lap_t + d_h * lap_h_prev\n",
    "            Xn = Xn + dt * update\n",
    "\n",
    "        return Xn\n",
    "\n",
    "# ----------------------------\n",
    "# Wire into attention: evolve q with 2D EM-like updater using v as geometry\n",
    "# ----------------------------\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.head_dim = self.n_embd // self.n_head\n",
    "        assert self.n_embd % self.n_head == 0\n",
    "\n",
    "        self.c_q = nn.Linear(self.n_embd, self.n_head * self.head_dim, bias=False)\n",
    "        self.c_k = nn.Linear(self.n_embd, self.n_head * self.head_dim, bias=False)\n",
    "        self.c_v = nn.Linear(self.n_embd, self.n_head * self.head_dim, bias=False)\n",
    "        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
    "\n",
    "        # 2D time-causal updater: mixes across heads via (t-1) head-Laplacian\n",
    "        self.em2d = EMDiffuse2D(self.head_dim, n_passes=1,\n",
    "                                a_max=1.0, d_t_max=0.35, d_h_max=0.15)\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.tril(torch.ones(config.block_size, config.block_size)).view(1, 1, config.block_size, config.block_size)\n",
    "        )\n",
    "        # rope-like signifier: 2D phase over (time, head) mapped into head_dim\n",
    "        self.omega_t = nn.Parameter(torch.tensor(0.01))   # time twist\n",
    "        self.omega_h = nn.Parameter(torch.tensor(0.10))   # head twist\n",
    "\n",
    "        self.rope_proj = nn.Linear(4, self.head_dim, bias=False)\n",
    "        nn.init.normal_(self.rope_proj.weight, mean=0.0, std=1e-2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        H, Dh = self.n_head, self.head_dim\n",
    "\n",
    "        # project\n",
    "        q = self.c_q(x).view(B, T, H, Dh)\n",
    "        k = self.c_k(x).view(B, T, H, Dh)\n",
    "        v = self.c_v(x).view(B, T, H, Dh)\n",
    "\n",
    "        # build rope feature R(t,h) : proper broadcast to (1, T, H, 4)\n",
    "        t_idx = torch.arange(T, device=x.device, dtype=x.dtype).view(1, T, 1, 1)\n",
    "        h_idx = torch.arange(H, device=x.device, dtype=x.dtype).view(1, 1, H, 1)\n",
    "\n",
    "        # expand to full grid so concat works\n",
    "        phase_t = t_idx.expand(1, T, H, 1) * self.omega_t\n",
    "        phase_h = h_idx.expand(1, T, H, 1) * self.omega_h\n",
    "\n",
    "        R = torch.cat([\n",
    "            torch.sin(phase_t),   # (1,T,H,1)\n",
    "            torch.cos(phase_t),   # (1,T,H,1)\n",
    "            torch.sin(phase_h),   # (1,T,H,1)\n",
    "            torch.cos(phase_h),   # (1,T,H,1)\n",
    "        ], dim=-1)  # final shape (1, T, H, 4)\n",
    "\n",
    "        # map rope feature into head_dim and broadcast over batch\n",
    "        rope_emb = self.rope_proj(R)              # (1, T, H, Dh)\n",
    "        rope_emb = rope_emb.expand(B, -1, -1, -1) # (B, T, H, Dh)\n",
    "\n",
    "        # two geometry copies derived from V : differential signal\n",
    "        G_q = v + rope_emb\n",
    "        G_k = v - rope_emb\n",
    "\n",
    "        # evolve q and k on (T x H) with their respective geometry\n",
    "        q = self.em2d(q, G_q)\n",
    "        k = self.em2d(k, G_k)\n",
    "        # attention expects (B, H, T, Dh)\n",
    "        q = q.permute(0, 2, 1, 3).contiguous()\n",
    "        k = k.permute(0, 2, 1, 3).contiguous()\n",
    "        v = v.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # scaled dot-product attention with causal mask\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float('-inf'))\n",
    "        att = variance_scaled_softmax(att, dim=-1)\n",
    "        y = att @ v\n",
    "\n",
    "        # merge heads\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, -1)\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Transformer Block\n",
    "# ----------------------------\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd, bias=None)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "         x = x + self.attn(self.ln_1(x))\n",
    "         x = x + self.mlp(self.ln_2(x))\n",
    "         return x\n",
    "\n",
    "def soft_ce(logits: torch.Tensor, target_probs: torch.Tensor) -> torch.Tensor:\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    loss = -(target_probs * logp).sum(dim=-1)\n",
    "    return loss.mean()\n",
    "\n",
    "def sharpen_distribution(idx: torch.Tensor, p: torch.Tensor, V: int, alpha: float) -> torch.Tensor:\n",
    "    B, T, K = idx.shape\n",
    "    out = torch.full((B, T, V), 0.0, dtype=p.dtype, device=p.device)\n",
    "    q = torch.clamp(p, min=1e-12) ** alpha\n",
    "    q = q / q.sum(dim=-1, keepdim=True)\n",
    "    out.scatter_add_(dim=-1, index=idx, src=q)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 66\n",
    "    n_layer: int = 4\n",
    "    n_head: int = 8\n",
    "    n_embd: int = 128\n",
    "    n_kv_head: int = 8\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict({\n",
    "            \"wte\": nn.Embedding(\n",
    "                config.vocab_size, config.n_embd),\n",
    "            \"h\": nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            \"ln_f\": LayerNorm(config.n_embd, bias=config.bias),\n",
    "        })\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.apply(self._init_weights)\n",
    "        # zero out classifier weights\n",
    "        torch.nn.init.zeros_(self.lm_head.weight)\n",
    "        # zero out c_proj weights in all blocks\n",
    "        for block in self.transformer.h:\n",
    "            torch.nn.init.zeros_(block.mlp.c_proj.weight)\n",
    "            torch.nn.init.zeros_(block.attn.c_proj.weight)\n",
    "        # init the rotary embeddings\n",
    "        head_dim = self.config.n_embd // self.config.n_head\n",
    "        # Cast the embeddings from fp32 to bf16: optim can tolerate it and it saves memory: both in the model and the activations\n",
    "        if self.transformer.wte.weight.device.type == \"cuda\":\n",
    "            self.transformer.wte.to(dtype=torch.bfloat16)\n",
    "\n",
    "    # ------------------------\n",
    "    # Forward\n",
    "    # ------------------------\n",
    "\n",
    "    def forward(self,\n",
    "                idx: torch.Tensor,\n",
    "                targets: Optional[torch.Tensor] = None,\n",
    "                zb: Optional[Tuple[torch.Tensor, torch.Tensor]] = None):\n",
    "        \"\"\"\n",
    "        idx: (B, T) Long\n",
    "        targets: (B, T) Long or None\n",
    "        zb: tuple (Z_idx, Z_p) for distributional aux \n",
    "       \n",
    "        \"\"\"\n",
    "        device = idx.device\n",
    "        B, T = idx.size()\n",
    "\n",
    "        T0 = 0 \n",
    "\n",
    "        tok_emb = self.transformer[\"wte\"](idx)                 # (B, T, D)\n",
    "        x = tok_emb\n",
    "\n",
    "        # defaults\n",
    "        L = len(self.transformer[\"h\"])\n",
    "        depth_alphas = [0.8 + 1.2 * (i/(L-1)) for i in range(L)] if L > 1 else [1.0]\n",
    "        x = norm(x)\n",
    "        # aux distribution pack\n",
    "        Z_idx, Z_p = zb if zb is not None else (None, None)\n",
    "        aux_loss = None\n",
    "\n",
    "        # blocks\n",
    "        for bidx, block in enumerate(self.transformer[\"h\"]):\n",
    "            x = block(x)                                       # (B, T, D)\n",
    "\n",
    "            # in-pass early head for self-teaching\n",
    "            #  Z-based distributional aux loss \n",
    "            if (Z_idx is not None) and (Z_p is not None):\n",
    "                V = self.lm_head.out_features\n",
    "                logits_b = self.lm_head(self.transformer[\"ln_f\"](x))\n",
    "                Z_dense = sharpen_distribution(Z_idx, Z_p, V, alpha=float(depth_alphas[bidx]))\n",
    "                aux_b = soft_ce(logits_b, Z_dense)\n",
    "                aux_loss = aux_b if aux_loss is None else aux_loss + aux_b\n",
    "\n",
    "        x = self.transformer[\"ln_f\"](x)\n",
    "        logits = self.lm_head(x)                               # (B, T, V)\n",
    "\n",
    "        # standard CE\n",
    "        ce_loss = None\n",
    "        if targets is not None:\n",
    "            ce_loss = F.cross_entropy(\n",
    "                logits.view(-1, logits.size(-1)),\n",
    "                targets.view(-1),\n",
    "                ignore_index=-100\n",
    "            )\n",
    "\n",
    "        # total\n",
    "        total = None\n",
    "        parts = []\n",
    "        if ce_loss is not None:\n",
    "            total = ce_loss\n",
    "        if aux_loss is not None:\n",
    "            total = aux_loss if total is None else total + aux_loss\n",
    "   \n",
    "        # generation convenience\n",
    "        if targets is None:\n",
    "            logits = logits[:, [-1], :]\n",
    "\n",
    "        return logits, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d76ace-c3c1-4a68-adce-851c842dbbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading aochildes.txt...\n",
      "üì• Downloading cbt.txt...\n",
      "üì• Downloading children_stories.txt...\n",
      "üì• Downloading gutenberg.txt...\n",
      "üì• Downloading qed.txt...\n",
      "üì• Downloading simple_wikipedia.txt...\n",
      "üì• Downloading switchboard.txt...\n",
      "üì• Downloading wikipedia.txt...\n",
      "üì• Downloading shakespeare.txt...\n",
      "‚úÖ Done. Files saved to ./babylm_10m_cleaned\n"
     ]
    }
   ],
   "source": [
    "import requests, os\n",
    "\n",
    "base_url = \"https://huggingface.co/datasets/cambridge-climb/BabyLM/resolve/main/clean/10M/\"\n",
    "target_dir = \"./babylm_10m_cleaned\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "file_names = [\n",
    "    \"aochildes.txt\",\n",
    "    \"cbt.txt\",\n",
    "    \"children_stories.txt\",\n",
    "    \"gutenberg.txt\",\n",
    "    \"qed.txt\",\n",
    "    \"simple_wikipedia.txt\",\n",
    "    \"switchboard.txt\",\n",
    "    \"wikipedia.txt\"\n",
    "]\n",
    "\n",
    "# Optional addition: Shakespeare from another dataset\n",
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/refs/heads/master/data/tinyshakespeare/input.txt\"\n",
    "shakespeare_fname = \"shakespeare.txt\"\n",
    "\n",
    "# Combined download logic\n",
    "all_files = [(base_url + fname, fname) for fname in file_names]\n",
    "all_files.append((shakespeare_url, shakespeare_fname))  # Add Shakespeare\n",
    "\n",
    "\n",
    "# Download loop\n",
    "for url, fname in all_files:\n",
    "    out_path = os.path.join(target_dir, fname)\n",
    "    print(f\"üì• Downloading {fname}...\")\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(resp.text)\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to download {fname} ({resp.status_code})\")\n",
    "\n",
    "print(f\"‚úÖ Done. Files saved to {target_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a695ab-753c-4b35-8834-a1d4f59859bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Char tokenizer finalized.\n",
      "üßæ Train tokens: 1016242 | Val tokens: 99152\n",
      "üî§ Vocab size: 66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# === Paths ===\n",
    "source_dir = \"./babylm_10m_cleaned\"\n",
    "out_dir    = \"./babylm_char_tokenized\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "file_names = [\n",
    "    \"shakespeare.txt\"#,\"aochildes.txt\", \"cbt.txt\", \"children_stories.txt\", \"gutenberg.txt\",\n",
    "    #\"qed.txt\", \"simple_wikipedia.txt\", \"switchboard.txt\", \"wikipedia.txt\"\n",
    "]\n",
    "\n",
    "# === Load and split ===\n",
    "train_texts, val_texts = [], []\n",
    "char_set = set()\n",
    "\n",
    "for fname in file_names:\n",
    "    with open(os.path.join(source_dir, fname), encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        n = len(lines)\n",
    "        split = int(0.9 * n)\n",
    "        train_part = \"\".join(lines[:split])\n",
    "        val_part   = \"\".join(lines[split:])\n",
    "        train_texts.append(train_part)\n",
    "        val_texts.append(val_part)\n",
    "        char_set.update(train_part)\n",
    "        char_set.update(val_part)\n",
    "\n",
    "full_train = \"\\n\".join(train_texts)\n",
    "full_val   = \"\\n\".join(val_texts)\n",
    "\n",
    "# === Final vocab ===\n",
    "char_set = sorted(set(char_set))\n",
    "vocab_chars = [\"<unk>\"] + [c for c in char_set if c != \"<unk>\"]\n",
    "\n",
    "stoi = {ch: i for i, ch in enumerate(vocab_chars)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "\n",
    "# === Encode function ===\n",
    "def encode(text):\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "train_ids = np.array(encode(full_train), dtype=np.uint16)\n",
    "val_ids   = np.array(encode(full_val),   dtype=np.uint16)\n",
    "\n",
    "# === Save ===\n",
    "train_ids.tofile(os.path.join(out_dir, \"train.bin\"))\n",
    "val_ids.tofile(os.path.join(out_dir, \"val.bin\"))\n",
    "\n",
    "with open(os.path.join(out_dir, \"meta.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"vocab_size\": len(stoi),\n",
    "        \"stoi\": stoi,\n",
    "        \"itos\": itos\n",
    "    }, f)\n",
    "\n",
    "print(f\"‚úÖ Char tokenizer finalized.\")\n",
    "print(f\"üßæ Train tokens: {len(train_ids)} | Val tokens: {len(val_ids)}\")\n",
    "print(f\"üî§ Vocab size: {len(stoi)}\")\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "\n",
    "data_dir = \"./babylm_char_tokenized\"\n",
    "train_path = os.path.join(data_dir, \"train.bin\")\n",
    "val_path   = os.path.join(data_dir, \"val.bin\")\n",
    "meta_path  = os.path.join(data_dir, \"meta.pkl\")\n",
    "train_ids = np.fromfile(train_path, dtype=np.uint16)\n",
    "val_ids   = np.fromfile(val_path,   dtype=np.uint16)\n",
    "\n",
    "with open(os.path.join(data_dir, 'meta.pkl'), 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "vocab_size = meta[\"vocab_size\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e48b14-a88f-48b6-b3e6-5507e3990262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Char tokenizer finalized.\n",
      "üßæ Train tokens: 1016242 | Val tokens: 99152\n",
      "üî§ Vocab size: 66\n",
      "Loaded 1016242 train tokens and 99152 val tokens | vocab=66\n",
      "Building order-2 Markov...\n",
      "Building order-4 Markov...\n",
      "Building order-8 Markov...\n",
      "Building order-16 Markov...\n",
      "Building order-32 Markov...\n",
      "Building order-64 Markov...\n",
      "Building bigram db...\n",
      "‚úÖ Markov and Bigram models saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# === Paths ===\n",
    "source_dir = \"./babylm_10m_cleaned\"\n",
    "out_dir    = \"./babylm_char_tokenized\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "file_names = [\n",
    "    \"shakespeare.txt\"#,\"aochildes.txt\", \"cbt.txt\", \"children_stories.txt\", \"gutenberg.txt\",\n",
    "    #\"qed.txt\", \"simple_wikipedia.txt\", \"switchboard.txt\", \"wikipedia.txt\"\n",
    "]\n",
    "\n",
    "# === Load and split ===\n",
    "train_texts, val_texts = [], []\n",
    "char_set = set()\n",
    "\n",
    "for fname in file_names:\n",
    "    with open(os.path.join(source_dir, fname), encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        n = len(lines)\n",
    "        split = int(0.9 * n)\n",
    "        train_part = \"\".join(lines[:split])\n",
    "        val_part   = \"\".join(lines[split:])\n",
    "        train_texts.append(train_part)\n",
    "        val_texts.append(val_part)\n",
    "        char_set.update(train_part)\n",
    "        char_set.update(val_part)\n",
    "\n",
    "full_train = \"\\n\".join(train_texts)\n",
    "full_val   = \"\\n\".join(val_texts)\n",
    "\n",
    "# === Final vocab ===\n",
    "char_set = sorted(set(char_set))\n",
    "vocab_chars = [\"<unk>\"] + [c for c in char_set if c != \"<unk>\"]\n",
    "\n",
    "stoi = {ch: i for i, ch in enumerate(vocab_chars)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "\n",
    "# === Encode function ===\n",
    "def encode(text):\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "train_ids = np.array(encode(full_train), dtype=np.uint16)\n",
    "val_ids   = np.array(encode(full_val),   dtype=np.uint16)\n",
    "\n",
    "# === Save ===\n",
    "train_ids.tofile(os.path.join(out_dir, \"train.bin\"))\n",
    "val_ids.tofile(os.path.join(out_dir, \"val.bin\"))\n",
    "\n",
    "with open(os.path.join(out_dir, \"meta.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"vocab_size\": len(stoi),\n",
    "        \"stoi\": stoi,\n",
    "        \"itos\": itos\n",
    "    }, f)\n",
    "\n",
    "print(f\"‚úÖ Char tokenizer finalized.\")\n",
    "print(f\"üßæ Train tokens: {len(train_ids)} | Val tokens: {len(val_ids)}\")\n",
    "print(f\"üî§ Vocab size: {len(stoi)}\")\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "\n",
    "data_dir = \"./babylm_char_tokenized\"\n",
    "train_path = os.path.join(data_dir, \"train.bin\")\n",
    "val_path   = os.path.join(data_dir, \"val.bin\")\n",
    "meta_path  = os.path.join(data_dir, \"meta.pkl\")\n",
    "train_ids = np.fromfile(train_path, dtype=np.uint16)\n",
    "val_ids   = np.fromfile(val_path,   dtype=np.uint16)\n",
    "\n",
    "with open(os.path.join(data_dir, 'meta.pkl'), 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "vocab_size = meta[\"vocab_size\"]\n",
    "\n",
    "def global_freqs(ids: np.ndarray, V: int) -> np.ndarray:\n",
    "    cnt = np.bincount(ids.astype(np.int64), minlength=V)\n",
    "    # normalize to probability (avoid zero)\n",
    "    p = cnt.astype(np.float64)\n",
    "    p = p / max(1.0, p.sum())\n",
    "    return p\n",
    "print(f\"Loaded {len(train_ids)} train tokens and {len(val_ids)} val tokens | vocab={vocab_size}\")\n",
    "p_global = global_freqs(train_ids, vocab_size)  # used for disciplined fill only\n",
    "\n",
    "def build_markov_chain(data: np.ndarray, window: int) -> Dict[Tuple[int, ...], Counter]:\n",
    "    chain = defaultdict(Counter)\n",
    "    for i in range(len(data) - window):\n",
    "        ctx = tuple(map(int, data[i:i+window]))\n",
    "        nxt = int(data[i+window])\n",
    "        chain[ctx][nxt] += 1\n",
    "    return chain\n",
    "\n",
    "ngram_orders = [2,4,8,16,32,64]\n",
    "markov_models: Dict[int, Dict[Tuple[int,...], Counter]] = {}\n",
    "for w in ngram_orders:\n",
    "    print(f\"Building order-{w} Markov...\")\n",
    "    markov_models[w] = build_markov_chain(train_ids, w)\n",
    "\n",
    "def build_bigram_db(data: np.ndarray, V: int, top_k=16, epsilon=1e-6, seed=1337):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    counts = np.zeros((V, V), dtype=np.int64)\n",
    "    a = data[:-1].astype(np.int64)\n",
    "    b = data[1:].astype(np.int64)\n",
    "    np.add.at(counts, (a, b), 1)\n",
    "    out = {}\n",
    "    all_ids = np.arange(V, dtype=np.int64)\n",
    "    for t in range(V):\n",
    "        row = counts[t]\n",
    "        tot = row.sum()\n",
    "        if tot == 0:\n",
    "            idx = rng.choice(V, size=top_k, replace=False)\n",
    "            p = np.full(top_k, 1.0/top_k, dtype=np.float32)\n",
    "        else:\n",
    "            pr = row.astype(np.float64) / float(tot)\n",
    "            obs = np.flatnonzero(row)\n",
    "            if len(obs) >= top_k:\n",
    "                sel = np.argpartition(pr[obs], -top_k)[-top_k:]\n",
    "                idx = obs[sel]\n",
    "                p = pr[idx].astype(np.float32)\n",
    "                s = p.sum()\n",
    "                p = p/s if s > 0 else np.full(top_k, 1.0/top_k, dtype=np.float32)\n",
    "            else:\n",
    "                need = top_k - len(obs)\n",
    "                mask = np.ones(V, dtype=bool); mask[obs] = False\n",
    "                extra = np.random.default_rng(seed+t).choice(np.nonzero(mask)[0], size=need, replace=False)\n",
    "                idx = np.concatenate([obs, extra])\n",
    "                p   = pr[idx].astype(np.float32)\n",
    "                # give epsilon to never-seen extras\n",
    "                unseen = (row[idx] == 0)\n",
    "                if unseen.any():\n",
    "                    p = p + unseen.astype(np.float32) * epsilon\n",
    "                p = p / p.sum()\n",
    "        order = np.argsort(-p)\n",
    "        out[t] = (idx[order].astype(np.int64), p[order])\n",
    "    return out\n",
    "\n",
    "print(\"Building bigram db...\")\n",
    "bigram_db = build_bigram_db(train_ids, vocab_size, top_k=64)  # collect a bit wider; we'll cap later\n",
    "\n",
    "# === Save ===\n",
    "model_dir = \"./markov_bigram_models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    \n",
    "with open(os.path.join(model_dir, \"markov_models.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(markov_models, f)\n",
    "\n",
    "with open(os.path.join(model_dir, \"bigram_db.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(bigram_db, f)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Markov and Bigram models saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4dd64a-8f8e-471e-97f2-7ffd1df4c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# === Config ===\n",
    "data_dir = \"./babylm_char_tokenized\"  # <- char-tokenized data\n",
    "block_size = 1024\n",
    "batch_size = 8\n",
    "\n",
    "# === Replacement dataloader that uses SAVED bigram + markov models and yields (X, Y, Z) ===\n",
    "import os, pickle, numpy as np, torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# expects `vocab_size` and `device` already defined in the outer scope\n",
    "# expects saved models at ./markov_bigram_models/{bigram_db.pkl, markov_models.pkl}\n",
    "\n",
    "class DisciplinedZ:\n",
    "    def __init__(self, markov_models: Dict[int, Dict[Tuple[int,...], Counter]],\n",
    "                 bigram_db: Dict[int, Tuple[np.ndarray, np.ndarray]],\n",
    "                 p_global: np.ndarray,\n",
    "                 vocab_size: int,\n",
    "                 top_k: int = 32,\n",
    "                 epsilon: float = 1e-6):\n",
    "        self.models = markov_models\n",
    "        self.bigram_db = bigram_db\n",
    "        self.p_global = p_global.astype(np.float64)\n",
    "        self.V = vocab_size\n",
    "        self.K = top_k\n",
    "        self.eps = float(epsilon)\n",
    "        # global sort for fill\n",
    "        self.global_order = np.argsort(-self.p_global)\n",
    "\n",
    "    def _cands_from_counter(self, ctr: Optional[Counter]) -> Optional[np.ndarray]:\n",
    "        if not ctr:\n",
    "            return None\n",
    "        return np.fromiter((int(t) for t,_ in ctr.items()), dtype=np.int64)\n",
    "\n",
    "    def _probs_from_counter(self, ctr: Optional[Counter]) -> Optional[Dict[int, float]]:\n",
    "        if not ctr:\n",
    "            return None\n",
    "        tot = sum(ctr.values())\n",
    "        if tot == 0:\n",
    "            return None\n",
    "        return {int(t): c/tot for t, c in ctr.items()}\n",
    "\n",
    "    def _bigram_top(self, tok: int, limit: int) -> np.ndarray:\n",
    "        idx, prob = self.bigram_db.get(int(tok), (None, None))\n",
    "        if idx is None:\n",
    "            return np.array([], dtype=np.int64)\n",
    "        return idx[:limit]\n",
    "\n",
    "    def _btree_candidates(self, contexts: Dict[int, Tuple[Tuple[int,...], Optional[Counter]]], backoff_tok: int) -> np.ndarray:\n",
    "        # collect candidate sets from each available context\n",
    "        sets = []\n",
    "        for n, (_, ctr) in contexts.items():\n",
    "            c = self._cands_from_counter(ctr)\n",
    "            if c is not None and c.size > 0:\n",
    "                sets.append(set(c.tolist()))\n",
    "        if len(sets) == 0:\n",
    "            # no ctx ‚Üí use bigram set as starting point\n",
    "            return self._bigram_top(backoff_tok, self.K)\n",
    "\n",
    "        # try full intersection; if empty, progressively intersect strongest contexts first\n",
    "        inter = set.intersection(*sets) if len(sets) > 1 else sets[0]\n",
    "        if len(inter) == 0:\n",
    "            # heuristic: sort by context order (longest first), intersect greedily\n",
    "            sets_sorted = sorted(sets, key=lambda s: -len(s))\n",
    "            inter = sets_sorted[0].copy()\n",
    "            for s in sets_sorted[1:]:\n",
    "                new_inter = inter.intersection(s)\n",
    "                if len(new_inter) > 0:\n",
    "                    inter = new_inter\n",
    "        if len(inter) == 0:\n",
    "            # last resort: union (still disciplined; no random injection)\n",
    "            union = set()\n",
    "            for s in sets:\n",
    "                union |= s\n",
    "            inter = union\n",
    "\n",
    "        arr = np.fromiter(inter, dtype=np.int64)\n",
    "        if arr.size == 0:\n",
    "            return self._bigram_top(backoff_tok, self.K)\n",
    "        return arr\n",
    "\n",
    "    def _score_candidates(self, cands: np.ndarray, contexts: Dict[int, Tuple[Tuple[int,...], Optional[Counter]]]) -> np.ndarray:\n",
    "        # score = sum over contexts of presence * local prob\n",
    "        # local prob from per-context normalized counts\n",
    "        scores = np.zeros(cands.size, dtype=np.float64)\n",
    "        idxmap = {int(t): i for i, t in enumerate(cands)}\n",
    "        for n, (_, ctr) in contexts.items():\n",
    "            probs = self._probs_from_counter(ctr)\n",
    "            if probs is None:\n",
    "                continue\n",
    "            for t, p in probs.items():\n",
    "                if t in idxmap:\n",
    "                    scores[idxmap[t]] += float(p)\n",
    "        # tiny floor to avoid zeros\n",
    "        scores = scores + (scores == 0) * self.eps\n",
    "        return scores\n",
    "\n",
    "    def build_Z_for_sequence(self, seq: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        seq: array of length L = block_size (+optional pad)\n",
    "        returns:\n",
    "          topk_idx: (L, K) int64\n",
    "          topk_p:   (L, K) float32  (row-normalized)\n",
    "        \"\"\"\n",
    "        L = len(seq)\n",
    "        topk_idx = np.zeros((L, self.K), dtype=np.int64)\n",
    "        topk_p   = np.zeros((L, self.K), dtype=np.float32)\n",
    "        for j in range(L):\n",
    "            back_tok = int(seq[j])\n",
    "            # collect contexts\n",
    "            contexts = {}\n",
    "            for n in ngram_orders:\n",
    "                if j - (n-1) < 0:\n",
    "                    continue\n",
    "                ctx = tuple(int(x) for x in seq[j-(n-1):j+1])\n",
    "                ctr = self.models[n].get(ctx, None)\n",
    "                contexts[n] = (ctx, ctr)\n",
    "\n",
    "            # disciplined candidate set\n",
    "            cands = self._btree_candidates(contexts, back_tok)\n",
    "\n",
    "            # cap K by candidate count\n",
    "            if cands.size >= self.K:\n",
    "                # score & take best K\n",
    "                scores = self._score_candidates(cands, contexts)\n",
    "                order = np.argsort(-scores)[:self.K]\n",
    "                idx = cands[order]\n",
    "                sc  = scores[order]\n",
    "            else:\n",
    "                # we must fill with globally-most-common tokens (no randoms), excluding existing\n",
    "                scores = self._score_candidates(cands, contexts) if cands.size > 0 else np.array([], dtype=np.float64)\n",
    "                missing = self.K - cands.size\n",
    "                mask = np.ones(vocab_size, dtype=bool)\n",
    "                mask[cands] = False\n",
    "                fill = []\n",
    "                for t in self.global_order:\n",
    "                    if mask[t]:\n",
    "                        fill.append(int(t))\n",
    "                        if len(fill) == missing:\n",
    "                            break\n",
    "                if cands.size == 0:\n",
    "                    idx = np.array(fill, dtype=np.int64)\n",
    "                    sc  = np.full(len(fill), self.eps, dtype=np.float64)\n",
    "                else:\n",
    "                    idx = np.concatenate([cands, np.array(fill, dtype=np.int64)])\n",
    "                    sc  = np.concatenate([scores, np.full(missing, self.eps, dtype=np.float64)])\n",
    "\n",
    "            # normalize to prob\n",
    "            p = sc.astype(np.float64)\n",
    "            p = p / p.sum() if p.sum() > 0 else np.full_like(p, 1.0/len(p))\n",
    "            topk_idx[j, :] = idx\n",
    "            topk_p[j, :]   = p.astype(np.float32)\n",
    "        return topk_idx, topk_p\n",
    "\n",
    "discZ = DisciplinedZ(markov_models, bigram_db, p_global, vocab_size, top_k=32, epsilon=1e-6)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class GPUDataset(Dataset):\n",
    "    def __init__(self, mmap_file, block_size: int, batch_size: int, builder: DisciplinedZ, pad_len:int=0, jitter:int=63, p_aligned:float=0.5, seed:int=1337):\n",
    "        self.data = mmap_file\n",
    "        self.block_size = int(block_size)\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.pad_len    = int(pad_len)\n",
    "        self.sample_len = self.block_size + self.pad_len\n",
    "        self.total = len(self.data) - self.sample_len - 1\n",
    "        self.n_blocks = max(1, self.total // self.sample_len)\n",
    "        self.jitter = int(jitter)\n",
    "        self.p_aligned = float(p_aligned)\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.builder = builder\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total // self.batch_size\n",
    "\n",
    "    def _sample_block(self):\n",
    "        base_block = self.rng.integers(0, self.n_blocks)\n",
    "        start = base_block * self.sample_len\n",
    "        if self.rng.random() > self.p_aligned:\n",
    "            j = self.rng.integers(0, self.jitter + 1)\n",
    "            start = min(start + j, self.total)\n",
    "        return start\n",
    "\n",
    "    def __getitem__(self, _):\n",
    "        B, T = self.batch_size, self.block_size\n",
    "        X = np.empty((B, self.sample_len), dtype=np.int64)\n",
    "        Y = np.empty((B, T), dtype=np.int64)\n",
    "        Z_idx = np.empty((B, T, self.builder.K), dtype=np.int64)\n",
    "        Z_p   = np.empty((B, T, self.builder.K), dtype=np.float32)\n",
    "        for i in range(B):\n",
    "            start = self._sample_block()\n",
    "            xseq = self.data[start : start + self.sample_len].astype(np.int64)\n",
    "            yseq = self.data[start + 1 + self.pad_len : start + 1 + self.pad_len + T].astype(np.int64)\n",
    "            X[i] = xseq\n",
    "            Y[i] = yseq\n",
    "            idxs, probs = self.builder.build_Z_for_sequence(xseq[:T])\n",
    "            Z_idx[i] = idxs\n",
    "            Z_p[i]   = probs\n",
    "        # torch tensors\n",
    "        X = torch.from_numpy(X[:, :T]).to(device)\n",
    "        Y = torch.from_numpy(Y).to(device)\n",
    "        Z_idx = torch.from_numpy(Z_idx).to(device)\n",
    "        Z_p   = torch.from_numpy(Z_p).to(device)\n",
    "        return X, Y, (Z_idx, Z_p)\n",
    "\n",
    "def collate_identity(batch):\n",
    "    Xs, Ys, Zs = zip(*batch)\n",
    "    X = torch.cat(Xs, dim=0)\n",
    "    Y = torch.cat(Ys, dim=0)\n",
    "    Zi = torch.cat([z[0] for z in Zs], dim=0)\n",
    "    Zp = torch.cat([z[1] for z in Zs], dim=0)\n",
    "    return X, Y, (Zi, Zp)\n",
    "\n",
    "block_size = 1024\n",
    "batch_size = 8\n",
    "\n",
    "GPU_DATASET = GPUDataset(\n",
    "    np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r'),\n",
    "    block_size=block_size,\n",
    "    batch_size=batch_size,\n",
    "    builder=discZ,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    GPU_DATASET,\n",
    "    batch_size=1,            # keep outer loader at 1; inner dataset batches on GPU\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_identity\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "efacb560-8e61-4e4e-9399-3c1611b476ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# === Config ===\n",
    "data_dir = \"./babylm_char_tokenized\"  # <- char-tokenized data\n",
    "block_size = 1024\n",
    "batch_size = 8\n",
    "\n",
    "config =  GPTConfig(\n",
    "    block_size,\n",
    "    vocab_size,\n",
    "    n_layer=4,      \n",
    "    n_head = 8,\n",
    "    n_embd =128)\n",
    "\n",
    "model = GPT(config).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
    "losses = []\n",
    "model = torch.compile(model)\n",
    "model = model.to(device)\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for xb, yb, zb in train_loader:\n",
    "        # xb: (B, T), yb: (B, T), zb: (Z_idx, Z_p) with shapes (B,T,K)\n",
    "        logits, loss = model(xb, None,zb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        total += loss.item()\n",
    "        print(loss.item())\n",
    "        losses.append(loss.item())\n",
    "    return total / len(train_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c43d3e5c-ba7e-4a1e-9b59-1b593316e2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811212\n"
     ]
    }
   ],
   "source": [
    "print(sum(param.numel() for param in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742f12d-294f-4bcf-8b15-e447dffa45d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6451f-1367-40a2-9fb9-85a5085ef5bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.751903533935547\n",
      "15.427251815795898\n",
      "14.068900108337402\n",
      "13.427888870239258\n",
      "12.975508689880371\n",
      "12.600427627563477\n",
      "12.490686416625977\n",
      "12.136739730834961\n",
      "11.92075252532959\n",
      "11.78222370147705\n",
      "11.320815086364746\n",
      "11.095687866210938\n",
      "11.014076232910156\n",
      "10.883039474487305\n",
      "10.653100967407227\n",
      "10.643102645874023\n",
      "10.4619722366333\n",
      "10.374933242797852\n",
      "10.37786865234375\n",
      "10.32261848449707\n",
      "10.201536178588867\n",
      "10.108766555786133\n",
      "10.122957229614258\n",
      "9.888104438781738\n",
      "9.946167945861816\n",
      "9.88122272491455\n",
      "9.930109024047852\n",
      "9.78711223602295\n",
      "9.696771621704102\n",
      "9.931978225708008\n",
      "9.668447494506836\n",
      "9.717609405517578\n",
      "9.663592338562012\n",
      "9.770671844482422\n",
      "9.684490203857422\n",
      "9.553247451782227\n",
      "9.621692657470703\n",
      "9.493448257446289\n",
      "9.617898941040039\n",
      "9.682994842529297\n",
      "9.56370735168457\n",
      "9.494085311889648\n",
      "9.548089027404785\n",
      "9.50050163269043\n",
      "9.367088317871094\n",
      "9.31984806060791\n",
      "9.266105651855469\n",
      "9.271106719970703\n",
      "9.23609733581543\n",
      "9.241033554077148\n",
      "9.18505859375\n",
      "9.419581413269043\n",
      "9.302549362182617\n",
      "9.225534439086914\n",
      "9.363507270812988\n",
      "9.146930694580078\n",
      "9.231673240661621\n",
      "9.185839653015137\n",
      "9.130859375\n",
      "9.085780143737793\n",
      "8.973665237426758\n",
      "9.069913864135742\n",
      "8.931608200073242\n",
      "9.100814819335938\n",
      "9.099900245666504\n",
      "9.190759658813477\n",
      "9.117517471313477\n",
      "9.04768180847168\n",
      "9.067730903625488\n",
      "9.006037712097168\n",
      "8.938268661499023\n",
      "8.933296203613281\n",
      "8.980965614318848\n",
      "8.961933135986328\n",
      "8.810820579528809\n",
      "9.018301963806152\n",
      "8.775918960571289\n",
      "8.893324851989746\n",
      "8.849210739135742\n",
      "8.68810749053955\n",
      "8.991625785827637\n",
      "8.774184226989746\n",
      "8.624523162841797\n",
      "8.676777839660645\n",
      "8.741758346557617\n",
      "8.781990051269531\n",
      "8.874128341674805\n",
      "8.774169921875\n",
      "8.61635971069336\n",
      "8.715778350830078\n",
      "8.675521850585938\n",
      "8.626472473144531\n",
      "8.845396041870117\n",
      "8.756463050842285\n",
      "8.701478958129883\n",
      "8.690450668334961\n",
      "8.63751220703125\n",
      "8.709281921386719\n",
      "8.502286911010742\n",
      "8.496352195739746\n",
      "8.643693923950195\n",
      "8.568670272827148\n",
      "8.666276931762695\n",
      "8.630985260009766\n",
      "8.307161331176758\n",
      "8.506973266601562\n",
      "8.446083068847656\n",
      "8.45697021484375\n",
      "8.510077476501465\n",
      "8.649311065673828\n",
      "8.512393951416016\n",
      "8.591324806213379\n",
      "8.409599304199219\n",
      "8.362558364868164\n",
      "8.471946716308594\n",
      "8.320985794067383\n",
      "8.443258285522461\n",
      "8.439068794250488\n",
      "8.307060241699219\n",
      "8.620664596557617\n",
      "8.539379119873047\n",
      "8.34968090057373\n",
      "8.45163345336914\n",
      "8.350459098815918\n",
      "8.383832931518555\n",
      "8.296869277954102\n",
      "8.47370719909668\n",
      "8.392029762268066\n",
      "8.35545825958252\n",
      "8.422874450683594\n",
      "8.380439758300781\n",
      "8.413816452026367\n",
      "8.340241432189941\n",
      "8.190078735351562\n",
      "8.357677459716797\n",
      "8.201171875\n",
      "8.40429401397705\n",
      "8.298871994018555\n",
      "8.306896209716797\n",
      "8.243175506591797\n",
      "8.218459129333496\n",
      "8.015707969665527\n",
      "8.274280548095703\n",
      "7.975169658660889\n",
      "8.302671432495117\n",
      "8.365556716918945\n",
      "8.325933456420898\n",
      "8.199609756469727\n",
      "8.123472213745117\n",
      "8.130615234375\n",
      "8.234838485717773\n",
      "8.07278060913086\n",
      "8.352826118469238\n",
      "8.290590286254883\n",
      "8.17582893371582\n",
      "8.062955856323242\n",
      "8.224788665771484\n",
      "8.058073043823242\n",
      "8.127113342285156\n",
      "7.9671454429626465\n",
      "8.059673309326172\n",
      "8.172905921936035\n",
      "8.174428939819336\n",
      "8.159741401672363\n",
      "8.116388320922852\n",
      "8.027481079101562\n",
      "8.034891128540039\n",
      "8.160272598266602\n",
      "8.150397300720215\n",
      "8.111576080322266\n",
      "7.997274398803711\n",
      "8.043988227844238\n",
      "8.057414054870605\n",
      "8.059426307678223\n",
      "8.088079452514648\n",
      "8.199563980102539\n",
      "8.033477783203125\n",
      "7.890094757080078\n",
      "7.972328186035156\n",
      "7.879061222076416\n",
      "8.017681121826172\n",
      "8.023756980895996\n",
      "7.984936237335205\n",
      "8.057530403137207\n",
      "7.995242118835449\n",
      "8.064902305603027\n",
      "7.89833402633667\n",
      "8.026156425476074\n",
      "7.911445140838623\n",
      "8.197996139526367\n",
      "7.916244983673096\n",
      "7.980583190917969\n",
      "7.860099792480469\n",
      "7.658566951751709\n",
      "7.842308044433594\n",
      "8.046764373779297\n",
      "8.132302284240723\n",
      "7.911202430725098\n",
      "7.7717790603637695\n",
      "8.075122833251953\n",
      "7.762232780456543\n",
      "8.09312915802002\n",
      "7.749236106872559\n",
      "7.9404754638671875\n",
      "8.053681373596191\n",
      "7.748640060424805\n",
      "7.9930267333984375\n",
      "7.827201843261719\n",
      "7.906504154205322\n",
      "7.882577896118164\n",
      "7.825308322906494\n",
      "7.905113220214844\n",
      "7.91721248626709\n",
      "7.821318626403809\n",
      "7.924314022064209\n",
      "7.792922019958496\n",
      "7.9219841957092285\n",
      "7.710153579711914\n",
      "7.728601455688477\n",
      "7.672159194946289\n",
      "7.931849956512451\n",
      "8.0008544921875\n",
      "7.763243198394775\n",
      "7.893087387084961\n",
      "7.677543640136719\n",
      "7.7815093994140625\n",
      "7.75258731842041\n",
      "7.745744705200195\n",
      "7.896950721740723\n",
      "7.8983283042907715\n",
      "7.737575054168701\n",
      "7.741634845733643\n",
      "7.895406723022461\n",
      "7.677381992340088\n",
      "7.83544921875\n",
      "7.747158050537109\n",
      "7.727180004119873\n",
      "7.562259674072266\n",
      "7.862428665161133\n",
      "7.9050211906433105\n",
      "7.693724632263184\n",
      "7.554145812988281\n",
      "7.6926469802856445\n",
      "7.769218444824219\n",
      "7.687061309814453\n",
      "7.701067924499512\n",
      "7.706269264221191\n",
      "7.77008581161499\n",
      "7.697378635406494\n",
      "7.531283378601074\n",
      "7.638645172119141\n",
      "7.546501159667969\n",
      "7.722440242767334\n",
      "7.473789691925049\n",
      "7.722254276275635\n",
      "7.787453651428223\n",
      "7.855609893798828\n",
      "7.838632583618164\n",
      "7.401704788208008\n",
      "7.71028470993042\n",
      "7.577801704406738\n",
      "7.687063694000244\n",
      "7.777002811431885\n",
      "7.570672988891602\n",
      "7.581225395202637\n",
      "7.6612629890441895\n",
      "7.534083366394043\n",
      "7.543410778045654\n",
      "7.768092632293701\n",
      "7.713288307189941\n",
      "7.605097770690918\n",
      "7.692956447601318\n",
      "7.65776252746582\n",
      "7.58779239654541\n",
      "7.354600429534912\n",
      "7.81836462020874\n",
      "7.558250904083252\n",
      "7.650111198425293\n",
      "7.422374725341797\n",
      "7.319222927093506\n",
      "7.701566696166992\n",
      "7.401648998260498\n",
      "7.580307960510254\n"
     ]
    }
   ],
   "source": [
    "# === Run Training ===\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch()\n",
    "    print(f\"Epoch {epoch:2d} | Train loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36c6dd9b-dafc-4c7e-94e9-fde8dd10f186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x39d35d6a0>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe76faa0-3933-416d-b923-993c67cfcf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "Ay wichs!\n",
      "\n",
      "RIDY:\n",
      "Ay, infoup aman.\n",
      "\n",
      "KING ELLIUCANIETHENENS:\n",
      "Tee's thy on, not you thescy. VILAGHEULY:\n",
      "By stown\n",
      "Qdill starl kee prightand swell be ing-doubth Riever slofrient bespe'll her Kent unaboy,\n",
      "Thy lord\n",
      "Whe IV:\n",
      "If of tonst, a wide, not shall, too he lere ith scurs.\n",
      "\n",
      "DAPUEEN:\n",
      "Kon.et you of I honge's ay once upon will wastowgenmang, Rome ging be dive degooot and,\n",
      "To hen\n",
      "solm dettred, or love.\n",
      "\n",
      "KINCEO:\n",
      "But,\n",
      "I haven, on to and Vour daet but of they is heard, woen they, bisder, ponvy puse ther The the bene\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def decode_chars(token_ids, itos):\n",
    "    \"\"\"\n",
    "    Decodes a list of character token IDs into a string.\n",
    "    \"\"\"\n",
    "    return ''.join([itos[i] for i in token_ids])\n",
    "\n",
    "def encode_chars(text, stoi):\n",
    "    \"\"\"\n",
    "    Encodes a string into a list of token IDs, one per character.\n",
    "    \"\"\"\n",
    "    return [stoi.get(c, 0) for c in text]\n",
    "\n",
    "\n",
    "def decode_sequence_char(\n",
    "    model, stoi, itos, prompt, max_new_tokens=100, block_size=256,\n",
    "    use_fenchel=False, tau=1.0, fenchel_iters=3, temperature=1.0\n",
    "):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    max_ctx = int(block_size)\n",
    "\n",
    "    # ?1 assume space token exists; fallback to 0 if missing\n",
    "    space_id = stoi.get(' ', 0)\n",
    "\n",
    "    # encode prompt\n",
    "    start_ids = torch.tensor([encode_chars(prompt, stoi)], dtype=torch.long, device=device)\n",
    "\n",
    "    # prepend the pad once; from now on the window just slides\n",
    "\n",
    "    idx = start_ids\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        context = idx[:, -max_ctx:]  # rotating buffer: last pad_len+block_size tokens\n",
    "        logits, _ = model(context, None)\n",
    "        last_logits = logits[:, -1, :]\n",
    "        probs = torch.softmax(last_logits / temperature, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_token], dim=1)\n",
    "\n",
    "    # drop the initial pad when returning the string\n",
    "    out_tokens = idx[0].tolist()\n",
    "    return decode_chars(out_tokens, itos)\n",
    "with open(\"./babylm_char_tokenized/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi = meta[\"stoi\"]\n",
    "itos = meta[\"itos\"]\n",
    "\n",
    "prompt = \"ROMEO:\"\n",
    "generated = decode_sequence_char(\n",
    "    model=model,\n",
    "    stoi=stoi,\n",
    "    itos=itos,\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=512,\n",
    "    block_size=1024,\n",
    "    use_fenchel=False,\n",
    "    tau=1.5,\n",
    "    fenchel_iters=2,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b2490-4fda-4d68-9385-6df58b9d06d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5766b-6947-4fbe-8704-8ea7c19c5afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37109166-b414-4e08-964d-be55048c9d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef652df0-c07e-4e14-8180-0cc75de9863e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60132cb-cf65-49c7-a481-c7a29c0fdf60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc7743d-0569-49ca-a2eb-a0d971455f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa366c-2133-4865-a7a4-ebce14ac2533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e4eaa6-9fea-464f-92dc-0036a4ece7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89689e67-ff91-4fc0-a0e4-79e4330d4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"fuzzy.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72509ed-bff1-43e2-a08a-4aad880fb293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
