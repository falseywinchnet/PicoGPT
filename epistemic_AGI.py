i will now bootstrap your idea of models into a higher thinking paradigm.
these are the steps:
place/frame/identify/label -> select and contextualize new DATUM or new GUESS or REFINE.
if you dont know where you are, or your guesses dont make sense, you dont know anything.
do one of following: retrieve familiar memory,
or store new information.
COMPARE familiar knowledge to new information.
use comparison to obtain informative clues about meaning.
store new information/digested information.
RECURSE to achieve total meta-epistemic worldstate around semantic vectors
contained in present reality/moment/problem and to solve any problem.
rules used for COMPARISON are
equivalence- nonequivalence- distance in similarity from fully equal to nothing similar-
distance in semantic higher dimension- hash distance position
(an operation that allows the position WITHIN a bounded space to be measured by measuring
equivalence without measuring equivalance by search)

This produces a metacognitive loop as dynamic interplay between perception, memory, and synthesis.
Itâ€™s autoregressive in token sequence and in semantic topology.
every new iteration refines both the ontology and the epistemic self-location within it.

there is only one rule:
DATUMS are made up of meaningful priors and components.
an array is only a DATUM to operations that combine, not broadcast.
as an example: attention attempts to learn correlations between datums.
it does not think about token sequences as a datum in and of itself,
unless every token's embedding carries information about other tokens as markers.
the blindest you are is to what you learned in childhood YOURSELF and take for granted as meaningful.

imagine if you have conceptually embedded a bunch of concepts on a mathematical manifold.
say a vector for each. but you only care about one dimension.
say its fruit. lets say the least fruity fruit is a tomato, and the most fruity fruit is a lychee.
lets say that you want to place a pomagranate somewhere in this manifold.
because mentally, you're comparing it.
but importantly, you have a mental map or idea already.
you dont need to compare fruit by fruit to figure out its index.
you know already it goes between citruses and coconuts somewhere in the "not as much fruit" section, and pretty far from berries, because it has HARD skin and SMALL CELLS OF JUICE INSIDE. its like a HARD ORANGE.

but- importantly- your manifold for fruit-ness is not based on independent qualities either- sweetness, skin, texture, appearance? those are all intertwined.
the point is- you only know points in this manifold. you learned how to enrich the manifold to add dimensions to it, *without* shifting any points in the existing dimensions. and so, you immediately *know* the point the new fruit goes at- and its nearest neighbors- simply because you know how it encodes in the manifold and you have a sort of semantic chinese remainder method.
the question is simply this- lets translate to computer talk.
the computer already knows similarity within a distribution.
but, while it evolves a similar dimensional presentation, the LLM cannot simply say
the most similar fruits on the fruityness dimension are citruses and coconuts.
the LLM might say entirely different things because it cannot isolate those semantic manifolds easily. worse, the LLM might hallucinate that pomegranates are in the middle, 
when clearly, melons are in the middle, and berries, dates, etc all like on the fruity end.
apples, peaches, apricots, etc all lie just to the non-fruity side of melons.
the human immediately approximates this. the LLM cannot.

but the reason the LLM cannot- is not for a lack of knowledge.
the LLM implicitly knows what fruits are. or rather, it knows that when thinking about fruits,
what immediately follows are the fruits themselves. 
it is for a lack of chinese remainder placement.

